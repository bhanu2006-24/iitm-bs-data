{
    "component": "Quizpractise/PractiseQuestionPaper",
    "props": {
        "errors": {},
        "auth": {
            "user": null
        },
        "flash": {
            "error": []
        },
        "banner": null,
        "file_url": "https://saram.blr1.cdn.digitaloceanspaces.com",
        "file_do_url": "https://saram.blr1.cdn.digitaloceanspaces.com",
        "question_paper": {
            "id": 247,
            "group_id": 27,
            "exam_id": 3,
            "total_score": "1.00",
            "duration": 4,
            "created_at": "2025-04-17T15:51:37.000000Z",
            "updated_at": "2025-04-17T15:51:37.000000Z",
            "question_paper_name": "IIT M DEGREE AN EXAM QDB3 13 Apr 2025",
            "question_paper_description": "2025 Apr13: IIT M AN EXAM QDB3",
            "uuid": "42ef11a8-88a",
            "year": 2025,
            "is_new": 0,
            "exam": {
                "id": 3,
                "exam_name": "End Term Quiz",
                "created_at": "2024-10-16T08:08:51.000000Z",
                "updated_at": "2024-10-16T08:08:51.000000Z",
                "uuid": "7a6ff569-f50c-40e7-a08b-f5c334392600",
                "en_id": "eyJpdiI6IjBvdERzMVpNT1JwcEpFbGF0ck9FbHc9PSIsInZhbHVlIjoiejVDR3Q1NUo1dnIvYnlpcHFIMUNpZz09IiwibWFjIjoiOTc4NmY3NjkxM2VhYmVlZWUzY2Q5MGZjNGJiYmI4NGE1YTMwNTExODZlMjc5NGI0OGE0NmJkYWIxMTc2MGFkMCIsInRhZyI6IiJ9"
            },
            "questions": [
                {
                    "id": 77247,
                    "exam_id": 3,
                    "question_paper_id": 247,
                    "question_number": 194,
                    "question_text_1": "THIS IS QUESTION PAPER FOR THE SUBJECT <b>\"DEGREE LEVEL : INTRODUCTION TO NATURAL </b><b>LANGUAGE PROCESSING (COMPUTER BASED EXAM)\"</b><b> </b><b> </b><b>ARE YOU SURE YOU HAVE TO WRITE EXAM FOR THIS SUBJECT? </b><b>CROSS CHECK YOUR HALL TICKET TO CONFIRM THE SUBJECTS TO BE WRITTEN. </b><b> </b><b>(IF IT IS NOT THE CORRECT SUBJECT, PLS CHECK THE SECTION AT THE TOP FOR THE SUBJECTS </b><b>REGISTERED BY YOU)</b>",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "0.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:39.000000Z",
                    "updated_at": "2025-04-17T15:51:39.000000Z",
                    "question_num_long": 6406531251254,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "63bd292845dc0cb1da69c85e35e6c8db",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "38ee1b84-4a34-4d7c-a61b-f545dad3eb50",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "THIS IS QUESTION PAPER FOR THE SUBJECT <b>\"DEGREE LEVEL : INTRODUCTION TO NATURAL </b><b>LANGUAGE PROCESSING (COMPUTER BASED EXAM)\"</b><b> </b><b> </b><b>ARE YOU SURE YOU HAVE TO WRITE EXAM FOR THIS SUBJECT? </b><b>CROSS CHECK YOUR HALL TICKET TO CONFIRM THE SUBJECTS TO BE WRITTEN. </b><b> </b><b>(IF IT IS NOT THE CORRECT SUBJECT, PLS CHECK THE SECTION AT THE TOP FOR THE SUBJECTS </b><b>REGISTERED BY YOU)</b>"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 207225,
                            "question_id": 77247,
                            "option_text": "YES",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215650,
                            "option_image_url": null
                        },
                        {
                            "id": 207226,
                            "question_id": 77247,
                            "option_text": "NO",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215651,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 77248,
                    "exam_id": 3,
                    "question_paper_id": 247,
                    "question_number": 195,
                    "question_text_1": "Why might accuracy be a misleading metric for evaluating POS tagging systems in cases of class imbalance?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:39.000000Z",
                    "updated_at": "2025-04-17T15:51:39.000000Z",
                    "question_num_long": 6406531251255,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "1ecbb57bc9b0604f973a0a01d49ac786",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "d3417f41-cbcf-4ec6-8f79-9e7d32ca4d1a",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Why might accuracy be a misleading metric for evaluating POS tagging systems in cases of class imbalance?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 207227,
                            "question_id": 77248,
                            "option_text": "Because accuracy does not account for the number of true negatives.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215652,
                            "option_image_url": null
                        },
                        {
                            "id": 207228,
                            "question_id": 77248,
                            "option_text": "Because accuracy gives equal weight to all classes, even if some tags are muchrarer than others.",
                            "option_image": "",
                            "score": "3.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215653,
                            "option_image_url": null
                        },
                        {
                            "id": 207229,
                            "question_id": 77248,
                            "option_text": "Because accuracy only measures the precision of the system, ignoring recall.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215654,
                            "option_image_url": null
                        },
                        {
                            "id": 207230,
                            "question_id": 77248,
                            "option_text": "Because accuracy is not affected by the number of false positives and falsenegatives.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215655,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 77249,
                    "exam_id": 3,
                    "question_paper_id": 247,
                    "question_number": 196,
                    "question_text_1": "In stochastic POS tagging, why is it necessary to calculate both individual word probabilities and tag sequence probabilities?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:39.000000Z",
                    "updated_at": "2025-04-17T15:51:39.000000Z",
                    "question_num_long": 6406531251256,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "936bb3754993a7d3bc3f08be4b11fe32",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "13f22c05-77fd-44df-a710-7fb1dcc76a74",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "In stochastic POS tagging, why is it necessary to calculate both individual word probabilities and tag sequence probabilities?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 207231,
                            "question_id": 77249,
                            "option_text": "Individual word probabilities are sufficient for accurate tagging, and tagsequence probabilities are redundant.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215656,
                            "option_image_url": null
                        },
                        {
                            "id": 207232,
                            "question_id": 77249,
                            "option_text": "Individual word probabilities are only used for rare words, while tag sequenceprobabilities are used for common words.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215657,
                            "option_image_url": null
                        },
                        {
                            "id": 207233,
                            "question_id": 77249,
                            "option_text": "Tag sequence probabilities help in determining the most likely sequence oftags, while individual word probabilities provide local context.",
                            "option_image": "",
                            "score": "3.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215658,
                            "option_image_url": null
                        },
                        {
                            "id": 207234,
                            "question_id": 77249,
                            "option_text": "Both probabilities are used to reduce the computational complexity of thetagging process.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215659,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 77250,
                    "exam_id": 3,
                    "question_paper_id": 247,
                    "question_number": 197,
                    "question_text_1": "How does Retrieval-Augmented Generation (RAG) differ from standard parametric models like GPT-3?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:39.000000Z",
                    "updated_at": "2025-04-17T15:51:39.000000Z",
                    "question_num_long": 6406531251259,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "226d656bb3fe25313683d10c9537ddf4",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "58f46c5a-4b4e-4fa0-85d8-db4013142718",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "How does Retrieval-Augmented Generation (RAG) differ from standard parametric models like GPT-3?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 207235,
                            "question_id": 77250,
                            "option_text": "RAG eliminates the need for transformer-based token generation.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215668,
                            "option_image_url": null
                        },
                        {
                            "id": 207236,
                            "question_id": 77250,
                            "option_text": "RAG uses retrieval but does not update its knowledge dynamically over time.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215669,
                            "option_image_url": null
                        },
                        {
                            "id": 207237,
                            "question_id": 77250,
                            "option_text": "RAG only works when trained on labeled question-answer datasets.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215670,
                            "option_image_url": null
                        },
                        {
                            "id": 207238,
                            "question_id": 77250,
                            "option_text": "RAG retrieves external documents dynamically, reducing reliance on pre-trained knowledge.",
                            "option_image": "",
                            "score": "3.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215671,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 77251,
                    "exam_id": 3,
                    "question_paper_id": 247,
                    "question_number": 198,
                    "question_text_1": "Which of the following architectures is most commonly used as the generator in RAG models?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:39.000000Z",
                    "updated_at": "2025-04-17T15:51:39.000000Z",
                    "question_num_long": 6406531251260,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "3576c5b15d76d7f9129ebcb2f14c6312",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "07fada93-72c8-4a11-89f5-96e0bd094d06",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following architectures is most commonly used as the generator in RAG models?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 207239,
                            "question_id": 77251,
                            "option_text": "GPT-3",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215672,
                            "option_image_url": null
                        },
                        {
                            "id": 207240,
                            "question_id": 77251,
                            "option_text": "BART",
                            "option_image": "",
                            "score": "3.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215673,
                            "option_image_url": null
                        },
                        {
                            "id": 207241,
                            "question_id": 77251,
                            "option_text": "BERT",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215674,
                            "option_image_url": null
                        },
                        {
                            "id": 207242,
                            "question_id": 77251,
                            "option_text": "RoBERTa",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215675,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 77252,
                    "exam_id": 3,
                    "question_paper_id": 247,
                    "question_number": 199,
                    "question_text_1": "A company wants to optimize an LLM for programming tasks. Which approach is the most efficient if they have limited labeled data?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:39.000000Z",
                    "updated_at": "2025-04-17T15:51:39.000000Z",
                    "question_num_long": 6406531251261,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "1469b132562419f5073e1c65bc2f5e4c",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "57ad0635-3c73-49aa-a0e5-da71aea30b78",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "A company wants to optimize an LLM for programming tasks. Which approach is the most efficient if they have limited labeled data?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 207243,
                            "question_id": 77252,
                            "option_text": "Train a new model from scratch using a large programming dataset.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215676,
                            "option_image_url": null
                        },
                        {
                            "id": 207244,
                            "question_id": 77252,
                            "option_text": "Fine-tune a transformer model with instruction tuning.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215677,
                            "option_image_url": null
                        },
                        {
                            "id": 207245,
                            "question_id": 77252,
                            "option_text": "Use Few-shot prompting with an existing LLM.",
                            "option_image": "",
                            "score": "3.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215678,
                            "option_image_url": null
                        },
                        {
                            "id": 207246,
                            "question_id": 77252,
                            "option_text": "Apply a BERT-based model instead of transformers.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215679,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 77253,
                    "exam_id": 3,
                    "question_paper_id": 247,
                    "question_number": 200,
                    "question_text_1": "Which of the following statements about Attention Flow in Transformer models is TRUE?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:39.000000Z",
                    "updated_at": "2025-04-17T15:51:39.000000Z",
                    "question_num_long": 6406531251263,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "8c94e4e0ce384782e11044f0a9fd7443",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "8b4d58cd-4b00-46fc-a16f-b366efc9ad74",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following statements about Attention Flow in Transformer models is TRUE?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 207247,
                            "question_id": 77253,
                            "option_text": "Attention flow computes the contribution of each token independently withoutconsidering other tokens.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215684,
                            "option_image_url": null
                        },
                        {
                            "id": 207248,
                            "question_id": 77253,
                            "option_text": "Attention flow assigns higher scores to tokens that appear earlier in thesequence by default.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215685,
                            "option_image_url": null
                        },
                        {
                            "id": 207249,
                            "question_id": 77253,
                            "option_text": "Attention flow combines attention scores across multiple layers to determineoverall token influence.",
                            "option_image": "",
                            "score": "3.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215686,
                            "option_image_url": null
                        },
                        {
                            "id": 207250,
                            "question_id": 77253,
                            "option_text": "Attention flow values are always normalized across all tokens in the sequenceto sum to 1.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215687,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 77254,
                    "exam_id": 3,
                    "question_paper_id": 247,
                    "question_number": 201,
                    "question_text_1": "Which of the following scenarios represents an ethical concern with LLM deployment?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:39.000000Z",
                    "updated_at": "2025-04-17T15:51:39.000000Z",
                    "question_num_long": 6406531251264,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "3e7aed1dfed49fa222ae5f81cd38f1fe",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "98cf31e9-6a19-406e-beb8-f48fec909773",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following scenarios represents an ethical concern with LLM deployment?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 207251,
                            "question_id": 77254,
                            "option_text": "A summarization model shortening news articles while maintaining factualaccuracy.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215688,
                            "option_image_url": null
                        },
                        {
                            "id": 207252,
                            "question_id": 77254,
                            "option_text": "A question-answering system providing different answers for differentdemographics when asked about salary negotiations.",
                            "option_image": "",
                            "score": "3.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215689,
                            "option_image_url": null
                        },
                        {
                            "id": 207253,
                            "question_id": 77254,
                            "option_text": "A chatbot refusing to generate offensive or harmful content.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215690,
                            "option_image_url": null
                        },
                        {
                            "id": 207254,
                            "question_id": 77254,
                            "option_text": "A translation model translating medical terms with higher accuracy thangeneral terms.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215691,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 77255,
                    "exam_id": 3,
                    "question_paper_id": 247,
                    "question_number": 202,
                    "question_text_1": "How does an LSTM differ from a standard RNN in terms of remembering information?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "4.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:39.000000Z",
                    "updated_at": "2025-04-17T15:51:39.000000Z",
                    "question_num_long": 6406531251257,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "e88a2ccbef9ac551ece1e8b750d77675",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "df79351f-dcce-44e0-ba6c-30cec8eb638d",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "How does an LSTM differ from a standard RNN in terms of remembering information?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 207255,
                            "question_id": 77255,
                            "option_text": "It uses a larger hidden state.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215660,
                            "option_image_url": null
                        },
                        {
                            "id": 207256,
                            "question_id": 77255,
                            "option_text": "It stores all past hidden states explicitly.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215661,
                            "option_image_url": null
                        },
                        {
                            "id": 207257,
                            "question_id": 77255,
                            "option_text": "It introduces gates to control the flow of information.",
                            "option_image": "",
                            "score": "4.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215662,
                            "option_image_url": null
                        },
                        {
                            "id": 207258,
                            "question_id": 77255,
                            "option_text": "It completely replaces hidden states with attention mechanisms.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215663,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 77256,
                    "exam_id": 3,
                    "question_paper_id": 247,
                    "question_number": 203,
                    "question_text_1": "In the context of speculative decoding, a draft model predicts three tokens: \"a\", \"quick\", \"fox\". The main model assigns probabilities 0.8, 0.6, and 0.8 respectively.The draft model's probabilities for these words were 0.7, 0.9, and 0.9. \nWhich tokens are most likely to be accepted?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "5.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:39.000000Z",
                    "updated_at": "2025-04-17T15:51:39.000000Z",
                    "question_num_long": 6406531251258,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "2f323e42f1a58e9e2d09de97265624da",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "6625a8d0-9f86-4b85-b09c-44b784ae67a2",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "In the context of speculative decoding, a draft model predicts three tokens: \"a\", \"quick\", \"fox\". The main model assigns probabilities 0.8, 0.6, and 0.8 respectively.The draft model's probabilities for these words were 0.7, 0.9, and 0.9. \nWhich tokens are most likely to be accepted?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 207259,
                            "question_id": 77256,
                            "option_text": "All three tokens",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215664,
                            "option_image_url": null
                        },
                        {
                            "id": 207260,
                            "question_id": 77256,
                            "option_text": "Only \"a\" and \"fox\"",
                            "option_image": "",
                            "score": "5.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215665,
                            "option_image_url": null
                        },
                        {
                            "id": 207261,
                            "question_id": 77256,
                            "option_text": "Only \"a\"",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215666,
                            "option_image_url": null
                        },
                        {
                            "id": 207262,
                            "question_id": 77256,
                            "option_text": "None of the tokens",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215667,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 77257,
                    "exam_id": 3,
                    "question_paper_id": 247,
                    "question_number": 204,
                    "question_text_1": "Consider the following attention matrices for two layers (corresponding to tokens 1 and 2) in a transformer model: \nLayer 1 Attention Matrix: \n",
                    "question_image_1": "vynBZTMoHHhheFSQdo9x6XLFNTGZQoOV5x4AoUFYVSpsuEWtbQ.png",
                    "question_type": "MCQ",
                    "total_mark": "5.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:39.000000Z",
                    "updated_at": "2025-04-17T15:51:39.000000Z",
                    "question_num_long": 6406531251262,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "c17ef9083558d453a289532c97ce2f7c",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": "Consider the following attention matrices for two layers (corresponding to tokens 1 and 2) in a transformer model: \nLayer 1 Attention Matrix: \n  Layer 2 Attention Matrix: \n",
                    "question_image_2": "Kb1JrIxvjKibh9tiOJe88bgrpqBqDR881Saj2yHw5OW3wY6nlY.png",
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": "Consider the following attention matrices for two layers (corresponding to tokens 1 and 2) in a transformer model: \nLayer 1 Attention Matrix: \n  Layer 2 Attention Matrix: \n  What is the total attention from token 2 to token 1 after performing attention rollout?",
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "c962e5b1-c378-4f26-b3e9-d6be68d20642",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/vynBZTMoHHhheFSQdo9x6XLFNTGZQoOV5x4AoUFYVSpsuEWtbQ.png",
                        "/question_images/Kb1JrIxvjKibh9tiOJe88bgrpqBqDR881Saj2yHw5OW3wY6nlY.png"
                    ],
                    "question_texts": [
                        "Consider the following attention matrices for two layers (corresponding to tokens 1 and 2) in a transformer model: \nLayer 1 Attention Matrix: \n",
                        "Consider the following attention matrices for two layers (corresponding to tokens 1 and 2) in a transformer model: \nLayer 1 Attention Matrix: \n  Layer 2 Attention Matrix: \n",
                        "Consider the following attention matrices for two layers (corresponding to tokens 1 and 2) in a transformer model: \nLayer 1 Attention Matrix: \n  Layer 2 Attention Matrix: \n  What is the total attention from token 2 to token 1 after performing attention rollout?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 207263,
                            "question_id": 77257,
                            "option_text": "0.57",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215680,
                            "option_image_url": null
                        },
                        {
                            "id": 207264,
                            "question_id": 77257,
                            "option_text": "0.33",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215681,
                            "option_image_url": null
                        },
                        {
                            "id": 207265,
                            "question_id": 77257,
                            "option_text": "0.39",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215682,
                            "option_image_url": null
                        },
                        {
                            "id": 207266,
                            "question_id": 77257,
                            "option_text": "0.26",
                            "option_image": "",
                            "score": "5.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215683,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 77258,
                    "exam_id": 3,
                    "question_paper_id": 247,
                    "question_number": 205,
                    "question_text_1": "Which of the following sentences contain pragmatic ambiguity due to potential sarcasm or irony?",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "6.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:39.000000Z",
                    "updated_at": "2025-04-17T15:51:39.000000Z",
                    "question_num_long": 6406531251265,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "d1ba5e62be2f127f1afae898106c5b62",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "9ed37d3f-a8fc-4ed0-9e2c-399d1d220329",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following sentences contain pragmatic ambiguity due to potential sarcasm or irony?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 207267,
                            "question_id": 77258,
                            "option_text": "\"Wow, another Monday! Just what I needed.\"",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215692,
                            "option_image_url": null
                        },
                        {
                            "id": 207268,
                            "question_id": 77258,
                            "option_text": "\"The meeting was only three hours long. So productive!\"",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215693,
                            "option_image_url": null
                        },
                        {
                            "id": 207269,
                            "question_id": 77258,
                            "option_text": "\"I love spending hours in traffic. It\u2019s my favorite part of the day.\"",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215694,
                            "option_image_url": null
                        },
                        {
                            "id": 207270,
                            "question_id": 77258,
                            "option_text": "\"The weather is perfect for a picnic today.\"",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215695,
                            "option_image_url": null
                        },
                        {
                            "id": 207271,
                            "question_id": 77258,
                            "option_text": "\"She always arrives on time, unlike some people.\"",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215696,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 77259,
                    "exam_id": 3,
                    "question_paper_id": 247,
                    "question_number": 206,
                    "question_text_1": "Which of the following statements correctly describe how BERT differs from GPT and standard transformer models?",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "4.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:39.000000Z",
                    "updated_at": "2025-04-17T15:51:39.000000Z",
                    "question_num_long": 6406531251266,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "2343e41795b00957616d9c42ce51959e",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "42338714-42c8-4243-bfd8-43e27173d33b",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following statements correctly describe how BERT differs from GPT and standard transformer models?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 207272,
                            "question_id": 77259,
                            "option_text": "BERT is a bidirectional model, while GPT is autoregressive.",
                            "option_image": "",
                            "score": "1.333",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215697,
                            "option_image_url": null
                        },
                        {
                            "id": 207273,
                            "question_id": 77259,
                            "option_text": "BERT uses masked language modeling (MLM), while GPT uses causal languagemodeling (CLM).",
                            "option_image": "",
                            "score": "1.333",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215698,
                            "option_image_url": null
                        },
                        {
                            "id": 207274,
                            "question_id": 77259,
                            "option_text": "Standard transformers use encoder-only architectures, whereas BERT and GPTboth use decoder-only architectures.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215699,
                            "option_image_url": null
                        },
                        {
                            "id": 207275,
                            "question_id": 77259,
                            "option_text": "BERT is trained for sentence embeddings, while GPT is trained for next-tokenprediction.",
                            "option_image": "",
                            "score": "1.333",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215700,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 77260,
                    "exam_id": 3,
                    "question_paper_id": 247,
                    "question_number": 207,
                    "question_text_1": "Which of the following statements is/are incorrect regarding Reinforcement Learning from Human Feedback (RLHF), Supervised Instruction Fine-Tuning, LoRA, and QLoRA?",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "4.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:39.000000Z",
                    "updated_at": "2025-04-17T15:51:39.000000Z",
                    "question_num_long": 6406531251267,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "d8012b4ecb9803334aec6cc854730f9a",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "af96c830-f722-4e9f-8a2d-0e7d4d582a27",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following statements is/are incorrect regarding Reinforcement Learning from Human Feedback (RLHF), Supervised Instruction Fine-Tuning, LoRA, and QLoRA?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 207276,
                            "question_id": 77260,
                            "option_text": "RLHF helps improve model behavior by learning from human preferencerankings.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215701,
                            "option_image_url": null
                        },
                        {
                            "id": 207277,
                            "question_id": 77260,
                            "option_text": "LoRA (Low-Rank Adaptation) reduces the number of trainable parameters byusing low-rank matrices.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215702,
                            "option_image_url": null
                        },
                        {
                            "id": 207278,
                            "question_id": 77260,
                            "option_text": "Supervised Instruction Fine-Tuning involves reinforcement learning forgenerating human-like responses.",
                            "option_image": "",
                            "score": "4.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215703,
                            "option_image_url": null
                        },
                        {
                            "id": 207279,
                            "question_id": 77260,
                            "option_text": "QLoRA applies quantization to reduce memory consumption during fine-tuning.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215704,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 77261,
                    "exam_id": 3,
                    "question_paper_id": 247,
                    "question_number": 208,
                    "question_text_1": "During sequence-to-sequence model training, which of the following statements is/are correct regarding Teacher Forcing and Student Forcing?",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "4.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:39.000000Z",
                    "updated_at": "2025-04-17T15:51:39.000000Z",
                    "question_num_long": 6406531251268,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "cba87551b561b26c190320db4a12eb84",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "54172edf-7e20-48b6-b632-c73148db1703",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "During sequence-to-sequence model training, which of the following statements is/are correct regarding Teacher Forcing and Student Forcing?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 207280,
                            "question_id": 77261,
                            "option_text": "Teacher Forcing is used during inference, while Student Forcing is used duringtraining.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215705,
                            "option_image_url": null
                        },
                        {
                            "id": 207281,
                            "question_id": 77261,
                            "option_text": "Teacher Forcing provides the correct previous output as input during training,whereas Student Forcing generates outputs based on its own previous predictions.",
                            "option_image": "",
                            "score": "4.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215706,
                            "option_image_url": null
                        },
                        {
                            "id": 207282,
                            "question_id": 77261,
                            "option_text": "Student Forcing helps the model converge faster than Teacher Forcing.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215707,
                            "option_image_url": null
                        },
                        {
                            "id": 207283,
                            "question_id": 77261,
                            "option_text": "Teacher Forcing is mainly used in reinforcement learning settings.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215708,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 77262,
                    "exam_id": 3,
                    "question_paper_id": 247,
                    "question_number": 209,
                    "question_text_1": "Which of the following statements about beam search is/are <b>incorrect</b> ?",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "4.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:39.000000Z",
                    "updated_at": "2025-04-17T15:51:39.000000Z",
                    "question_num_long": 6406531251269,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "3222cb312ba51fcc2fc184ede582e32c",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "fe18ddfa-0f93-4b3b-b655-4e8404f2bc9c",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following statements about beam search is/are <b>incorrect</b> ?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 207284,
                            "question_id": 77262,
                            "option_text": "Beam search balances exploration and exploitation by considering multiplesequences at each step.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215709,
                            "option_image_url": null
                        },
                        {
                            "id": 207285,
                            "question_id": 77262,
                            "option_text": "A larger beam width increases computational cost but improves searchquality.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215710,
                            "option_image_url": null
                        },
                        {
                            "id": 207286,
                            "question_id": 77262,
                            "option_text": "Greedy search is equivalent to beam search with beam size B = 1.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215711,
                            "option_image_url": null
                        },
                        {
                            "id": 207287,
                            "question_id": 77262,
                            "option_text": "Unlike greedy search, beam search guarantees finding the globally optimalsequence.",
                            "option_image": "",
                            "score": "4.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215712,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 77263,
                    "exam_id": 3,
                    "question_paper_id": 247,
                    "question_number": 210,
                    "question_text_1": "Which components are essential in a RAG pipeline?",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "4.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:39.000000Z",
                    "updated_at": "2025-04-17T15:51:39.000000Z",
                    "question_num_long": 6406531251271,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "13f4a2a9228c7f37f1d392faf00aa4b4",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "98c5bee7-7c85-4d72-abd6-3d98738e98e2",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which components are essential in a RAG pipeline?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 207288,
                            "question_id": 77263,
                            "option_text": "retriever model (e.g., DPR) that fetches relevant documents.",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215718,
                            "option_image_url": null
                        },
                        {
                            "id": 207289,
                            "question_id": 77263,
                            "option_text": "decoder-only transformer for sequence generation.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215719,
                            "option_image_url": null
                        },
                        {
                            "id": 207290,
                            "question_id": 77263,
                            "option_text": "BM25-based sparse retrieval method as the primary retriever.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215720,
                            "option_image_url": null
                        },
                        {
                            "id": 207291,
                            "question_id": 77263,
                            "option_text": "BERT-based query encoder for document ranking.",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215721,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 77264,
                    "exam_id": 3,
                    "question_paper_id": 247,
                    "question_number": 211,
                    "question_text_1": "Which of the following are the examples of unintended bias in an NLP model?",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "4.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:39.000000Z",
                    "updated_at": "2025-04-17T15:51:39.000000Z",
                    "question_num_long": 6406531251272,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "7c3a7e52912d0d032f2364f91fc3e596",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "8fbb10d0-89e1-442e-a896-a324aac2e4ba",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following are the examples of unintended bias in an NLP model?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 207292,
                            "question_id": 77264,
                            "option_text": "A sentiment analysis model rating all political tweets as \"negative\".",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215722,
                            "option_image_url": null
                        },
                        {
                            "id": 207293,
                            "question_id": 77264,
                            "option_text": "A chatbot trained specifically for medical consultations failing on legal queries.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215723,
                            "option_image_url": null
                        },
                        {
                            "id": 207294,
                            "question_id": 77264,
                            "option_text": "A text summarization model producing longer summaries for academicpapers.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215724,
                            "option_image_url": null
                        },
                        {
                            "id": 207295,
                            "question_id": 77264,
                            "option_text": "A machine translation system translating \"doctor\" to \"he\" and \"nurse\" to \"she\"in a gender-neutral language.",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215725,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 77265,
                    "exam_id": 3,
                    "question_paper_id": 247,
                    "question_number": 212,
                    "question_text_1": "Which of the following factors contribute to bias amplification in NLP models?",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "4.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:39.000000Z",
                    "updated_at": "2025-04-17T15:51:39.000000Z",
                    "question_num_long": 6406531251273,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "07b52ca4f6eef46b9b2e31a2c0e0805e",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "540a6c80-4f2e-4fee-b31b-ebd31eb861b4",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following factors contribute to bias amplification in NLP models?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 207296,
                            "question_id": 77265,
                            "option_text": "Reinforcement learning from biased human feedback.",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215726,
                            "option_image_url": null
                        },
                        {
                            "id": 207297,
                            "question_id": 77265,
                            "option_text": "Training on unbalanced datasets where stereotypes exist.",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215727,
                            "option_image_url": null
                        },
                        {
                            "id": 207298,
                            "question_id": 77265,
                            "option_text": "Applying debiasing techniques such as zeroing out gender-related wordembeddings.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215728,
                            "option_image_url": null
                        },
                        {
                            "id": 207299,
                            "question_id": 77265,
                            "option_text": "Using a larger model size to improve performance.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215729,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 77266,
                    "exam_id": 3,
                    "question_paper_id": 247,
                    "question_number": 213,
                    "question_text_1": null,
                    "question_image_1": "G5njCbEz3iq8iQW6Cvcbz6uEZk5zFqxKl6yk5KrymbcqCldYb0.png",
                    "question_type": "MSQ",
                    "total_mark": "5.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:39.000000Z",
                    "updated_at": "2025-04-17T15:51:39.000000Z",
                    "question_num_long": 6406531251270,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "feaca48bbaf68bda8bf2d68359b3ef0e",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "a0698748-72ed-43c4-8e5e-20fbe30b2566",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/G5njCbEz3iq8iQW6Cvcbz6uEZk5zFqxKl6yk5KrymbcqCldYb0.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 207300,
                            "question_id": 77266,
                            "option_text": "The probability of \"apple\" increases further.",
                            "option_image": "",
                            "score": "5.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215713,
                            "option_image_url": null
                        },
                        {
                            "id": 207301,
                            "question_id": 77266,
                            "option_text": "The probabilities of \"banana\" and \"cherry\" become closer to \"apple\".",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215714,
                            "option_image_url": null
                        },
                        {
                            "id": 207302,
                            "question_id": 77266,
                            "option_text": "The probabilities remain unchanged.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215715,
                            "option_image_url": null
                        },
                        {
                            "id": 207303,
                            "question_id": 77266,
                            "option_text": "The model always picks \"banana\".",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215716,
                            "option_image_url": null
                        },
                        {
                            "id": 207304,
                            "question_id": 77266,
                            "option_text": "The model always picks \"cherry\".",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:39.000000Z",
                            "updated_at": "2025-04-17T15:51:39.000000Z",
                            "option_number": 6406534215717,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 77267,
                    "exam_id": 3,
                    "question_paper_id": 247,
                    "question_number": 214,
                    "question_text_1": "In a transition-based parser using SHIFT, LEFTARC, and RIGHTARC operations, what is the minimum number of operations needed to parse the sentence \"I love coding\" (excluding the ROOT node)?",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "4",
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:39.000000Z",
                    "updated_at": "2025-04-17T15:51:39.000000Z",
                    "question_num_long": 6406531251274,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "c42e061fa196673e2b7926a38fb481f8",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "099422d7-0cc5-445e-ba1f-0490245e4055",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "In a transition-based parser using SHIFT, LEFTARC, and RIGHTARC operations, what is the minimum number of operations needed to parse the sentence \"I love coding\" (excluding the ROOT node)?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 77268,
                    "exam_id": 3,
                    "question_paper_id": 247,
                    "question_number": 215,
                    "question_text_1": "A TF-IDF model is applied to a document corpus of 50,000 documents. The term \"optimization\" appears in 750 documents. In a specific document, \"optimization\" appears 8 times, and the total number of words in that document is 1200. Using log base 10 ( log10), compute the TF-IDF score for \"optimization\" in this document. Enter your answer correct to three decimal places.",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "0.01",
                    "value_end": "0.02",
                    "created_at": "2025-04-17T15:51:39.000000Z",
                    "updated_at": "2025-04-17T15:51:39.000000Z",
                    "question_num_long": 6406531251275,
                    "answer_type": "Range",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "543739031a2e749bac83729c604cbb2b",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "6e17a95b-cf80-481d-a786-63f14059dff1",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "A TF-IDF model is applied to a document corpus of 50,000 documents. The term \"optimization\" appears in 750 documents. In a specific document, \"optimization\" appears 8 times, and the total number of words in that document is 1200. Using log base 10 ( log10), compute the TF-IDF score for \"optimization\" in this document. Enter your answer correct to three decimal places."
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 77269,
                    "exam_id": 3,
                    "question_paper_id": 247,
                    "question_number": 216,
                    "question_text_1": "A beam search with beam width = 4 and vocabulary size = 8 is run for 3 decoding steps. How many sequences will remain at the end of 3 steps after pruning?",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "4",
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:39.000000Z",
                    "updated_at": "2025-04-17T15:51:39.000000Z",
                    "question_num_long": 6406531251276,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "c42e061fa196673e2b7926a38fb481f8",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "7e17b486-f125-420d-af6d-0d26f7e1a3be",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "A beam search with beam width = 4 and vocabulary size = 8 is run for 3 decoding steps. How many sequences will remain at the end of 3 steps after pruning?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 77270,
                    "exam_id": 3,
                    "question_paper_id": 247,
                    "question_number": 217,
                    "question_text_1": "A transformer-based Retrieval-Augmented Generation (RAG) system retrieves the top-10 most relevant passages, where each passage contains 512 tokens. However, a portion of the model's 4096-token context length is reserved for the input query and special tokens (e.g., separators, instructions). If the model reserves 1024 tokens for the input query, how many full retrieved passages can fit within the remaining context window?",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "6",
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:39.000000Z",
                    "updated_at": "2025-04-17T15:51:39.000000Z",
                    "question_num_long": 6406531251277,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "5cf4d6da8aaac9aba83ab6069f95efad",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "d766e30c-0f18-4a00-b447-e1cb3b6af293",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "A transformer-based Retrieval-Augmented Generation (RAG) system retrieves the top-10 most relevant passages, where each passage contains 512 tokens. However, a portion of the model's 4096-token context length is reserved for the input query and special tokens (e.g., separators, instructions). If the model reserves 1024 tokens for the input query, how many full retrieved passages can fit within the remaining context window?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 77271,
                    "exam_id": 3,
                    "question_paper_id": 247,
                    "question_number": 218,
                    "question_text_1": "Consider the following regression model: \nF(x) = 500 * Age + 1000 * Income + 20000 \nFor an input with: \nAge = 30 Income = 50 \n<b>Baseline Input:</b>\n\nAge = 0 Income = 0 \nWhat is the Integrated Gradient for the feature Income?",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "50000",
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:39.000000Z",
                    "updated_at": "2025-04-17T15:51:39.000000Z",
                    "question_num_long": 6406531251278,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "95e0cd9df1bce0bb68829f80b2cc96aa",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "f75e770a-bcc6-42cc-8c5a-c008f43bf633",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Consider the following regression model: \nF(x) = 500 * Age + 1000 * Income + 20000 \nFor an input with: \nAge = 30 Income = 50 \n<b>Baseline Input:</b>\n\nAge = 0 Income = 0 \nWhat is the Integrated Gradient for the feature Income?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 77272,
                    "exam_id": 3,
                    "question_paper_id": 247,
                    "question_number": 219,
                    "question_text_1": null,
                    "question_image_1": "55OH6m7MM3vr7CTyBBPfJ9hmdBSm6rmG4ocGkWGgnwlpKIFpv4.png",
                    "question_type": "SA",
                    "total_mark": "6.00",
                    "value_start": "162",
                    "value_end": "163",
                    "created_at": "2025-04-17T15:51:39.000000Z",
                    "updated_at": "2025-04-17T15:51:39.000000Z",
                    "question_num_long": 6406531251279,
                    "answer_type": "Range",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "07269589e9325fb496ab6b21170e0819",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "9589a398-dd84-42b7-8dae-fa4be7a70731",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/55OH6m7MM3vr7CTyBBPfJ9hmdBSm6rmG4ocGkWGgnwlpKIFpv4.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [],
                    "parent_question": null
                }
            ]
        },
        "summary": "Here\u2019s a structured **summary of core topics, concepts, principles, and equations** for the **Introduction to Natural Language Processing (NLP)** exam, along with **Mermaid knowledge graphs** to visualize relationships.\n\n---\n\n## **1. Core Topics & Key Concepts**\n### **A. Evaluation Metrics & Class Imbalance**\n- **Accuracy Pitfalls**:\n  - Misleading in **class imbalance** (e.g., rare POS tags).\n  - **Better metrics**: Precision, Recall, F1-score, or **weighted accuracy**.\n- **Key Idea**:\n  - Accuracy treats all classes equally, ignoring **tag frequency distribution** (Q2).\n\n### **B. Part-of-Speech (POS) Tagging**\n- **Stochastic POS Tagging**:\n  - Uses **probabilistic models** (e.g., HMMs, CRFs).\n  - Requires:\n    1. **Individual word probabilities** (lexical likelihood).\n    2. **Tag sequence probabilities** (transition probabilities) (Q3).\n  - **Viterbi Algorithm**: Finds the most likely tag sequence.\n\n### **C. Retrieval-Augmented Generation (RAG)**\n- **Difference from Parametric Models (e.g., GPT-3)**:\n  - **RAG** dynamically retrieves **external knowledge** (e.g., documents) during inference (Q4).\n  - **Generator Architecture**: Typically **BART** (Bidirectional + Autoregressive) (Q5).\n- **RAG Pipeline Components** (Q17):\n  1. **Retriever** (e.g., DPR, BM25, BERT-based encoder).\n  2. **Generator** (e.g., BART, T5).\n\n### **D. Model Optimization with Limited Data**\n- **Few-Shot Prompting** > Fine-tuning when labeled data is scarce (Q6).\n- **Alternatives**:\n  - **Instruction Tuning** (supervised fine-tuning on instructions).\n  - **LoRA/QLoRA** (parameter-efficient fine-tuning) (Q14).\n\n### **E. Transformer Models & Attention**\n- **Attention Flow** (Q7, Q11):\n  - **Multi-layer attention** combines scores across layers to determine **token influence**.\n  - **Attention Rollout**: Propagates attention weights through layers (e.g., `A_total = A1 * A2`).\n- **BERT vs. GPT vs. Standard Transformers** (Q13):\n  | Model       | Training Objective       | Directionality       | Use Case                     |\n  |-------------|--------------------------|----------------------|------------------------------|\n  | **BERT**    | Masked LM (MLM)          | Bidirectional        | Sentence embeddings, NLI     |\n  | **GPT**     | Causal LM (CLM)          | Left-to-right        | Text generation              |\n  | **Standard**| Depends on task          | Varies               | Encoder/Decoder architectures|\n\n### **F. Ethical Concerns in NLP**\n- **Bias & Fairness** (Q8, Q18, Q19):\n  - **Unintended Bias**: Stereotypical associations (e.g., \"doctor\" \u2192 \"he\").\n  - **Bias Amplification Causes**:\n    - **Biased training data** (e.g., underrepresented groups).\n    - **Reinforcement Learning from Human Feedback (RLHF)** (if feedback is biased).\n  - **Mitigation**:\n    - **Debiasing techniques** (e.g., adversarial training, reweighting).\n    - **Diverse datasets**.\n\n### **G. Sequence Models: RNNs vs. LSTMs**\n- **LSTMs** improve RNNs by:\n  - **Gating mechanisms** (input, forget, output gates) to control information flow (Q9).\n  - **Long-term dependency handling**.\n\n### **H. Decoding Strategies**\n- **Speculative Decoding** (Q10):\n  - A **draft model** proposes tokens; the **main model** verifies them.\n  - **Acceptance Rule**: Token accepted if `P_main(token) > P_draft(token)`.\n- **Beam Search** (Q16, Q23):\n  - **Beam Width (B)**: Number of sequences kept at each step.\n  - **Trade-off**: Higher B \u2192 better quality but more computation.\n  - **Not guaranteed to find the global optimum** (unlike exhaustive search).\n- **Teacher vs. Student Forcing** (Q15):\n  | Strategy          | Training Input          | Use Case               |\n  |-------------------|-------------------------|------------------------|\n  | **Teacher Forcing**| Ground truth tokens     | Training (faster convergence) |\n  | **Student Forcing**| Model\u2019s own predictions | Inference (real-world use)     |\n\n### **I. Pragmatic Ambiguity & Sarcasm**\n- **Pragmatic Ambiguity** (Q12):\n  - Arises from **context-dependent meaning** (e.g., sarcasm, irony).\n  - Examples:\n    - *\"Wow, another Monday! Just what I needed.\"* (sarcastic)\n    - *\"The meeting was so productive.\"* (ironic if it was long but unproductive).\n\n### **J. Efficiency Techniques**\n- **LoRA (Low-Rank Adaptation)** (Q14):\n  - Freezes pre-trained weights; adds **low-rank trainable matrices**.\n  - Reduces **memory and compute** for fine-tuning.\n- **QLoRA**:\n  - Adds **quantization** (e.g., 4-bit) to LoRA for further efficiency.\n\n### **K. Information Retrieval (TF-IDF, BM25)**\n- **TF-IDF Formula** (Q22):\n  \\[\n  \\text{TF-IDF}(t, d) = \\text{TF}(t, d) \\times \\log\\left(\\frac{N}{\\text{DF}(t)}\\right)\n  \\]\n  - **TF(t, d)**: Term frequency in document `d`.\n  - **DF(t)**: Document frequency (number of docs containing `t`).\n  - **N**: Total documents in corpus.\n- **Example Calculation** (Q22):\n  - `TF = 8 / 1200 \u2248 0.0067`\n  - `IDF = log10(50000 / 750) \u2248 1.822`\n  - `TF-IDF \u2248 0.0067 * 1.822 \u2248 0.012`\n\n### **L. Explainability (Integrated Gradients, Shapley Values)**\n- **Integrated Gradients** (Q25):\n  - Attributes prediction to features by **integrating gradients** from a baseline.\n  - For linear model `F(x) = 500*Age + 1000*Income + 20000`:\n    - **Baseline**: `Age=0, Income=0` \u2192 `F(x)=20000`.\n    - **Input**: `Age=30, Income=50` \u2192 `F(x)=500*30 + 1000*50 + 20000 = 75000`.\n    - **Integrated Gradient for Income**:\n      \\[\n      \\text{IG} = (F(x)_{\\text{input}} - F(x)_{\\text{baseline}}) \\times \\text{Feature Contribution}\n      \\]\n      - `Income` contributes `1000 * 50 = 50000`.\n- **Shapley Values** (Q26):\n  - **Fair feature attribution** based on marginal contributions.\n  - For the \"Discount\" feature:\n    - Average contribution across all feature subsets \u2248 **162.5**.\n\n### **M. Parsing (Transition-Based)**\n- **Operations**: `SHIFT`, `LEFT-ARC`, `RIGHT-ARC`.\n- **Example** (Q21):\n  - Sentence: *\"I love coding\"* \u2192 **4 operations** (excluding ROOT).\n\n### **N. Temperature in Language Models**\n- **Effect of Low Temperature (t \u2192 0)** (Q20):\n  - **Sharpens probability distribution** (high-prob tokens dominate).\n  - Example:\n    - Original: `P(apple)=0.5, P(banana)=0.3, P(cherry)=0.2`.\n    - After `t=0.1`: `P(apple) \u2248 1.0`, others `\u2248 0`.\n\n---\n\n## **2. Key Equations**\n| **Concept**               | **Equation**                                                                 |\n|---------------------------|-----------------------------------------------------------------------------|\n| **TF-IDF**                | `TF-IDF(t, d) = (Count(t, d) / |d|) * log(N / DF(t))`                       |\n| **Attention Rollout**     | `A_total = A1 * A2 * ... * An` (element-wise multiplication across layers) |\n| **Beam Search Pruning**   | `Sequences kept = Beam Width (B)`                                          |\n| **Integrated Gradients**  | `IG_i = (x_i - x'_i) * \u222b(\u2202F/\u2202x_i) dx` from baseline `x'` to input `x`       |\n| **Shapley Value**         | `\u03c6_i = \u03a3 [f(S \u222a {i}) - f(S)] / C` for all subsets `S` not containing `i`     |\n| **Temperature Scaling**   | `P'(x) = softmax(log(P(x)) / t)`                                           |\n\n---\n\n## **3. Mermaid Knowledge Graphs**\n### **Graph 1: Core NLP Concepts**\n```mermaid\ngraph TD\n    A[NLP Fundamentals] --> B[POS Tagging]\n    A --> C[Transformers]\n    A --> D[Ethics & Bias]\n    A --> E[Information Retrieval]\n    A --> F[Decoding Strategies]\n\n    B --> B1[Stochastic Models]\n    B --> B2[HMMs/CRFs]\n    B --> B3[Viterbi Algorithm]\n\n    C --> C1[Attention Mechanisms]\n    C --> C2[BERT vs GPT]\n    C --> C3[RAG]\n\n    D --> D1[Bias Sources]\n    D --> D2[Debiasing Techniques]\n    D --> D3[Fairness Metrics]\n\n    E --> E1[TF-IDF]\n    E --> E2[BM25]\n    E --> E3[Dense Retrieval]\n\n    F --> F1[Beam Search]\n    F --> F2[Teacher Forcing]\n    F --> F3[Speculative Decoding]\n```\n\n### **Graph 2: Transformer & Attention Flow**\n```mermaid\ngraph LR\n    T[Transformer] --> A[Multi-Head Attention]\n    T --> B[Positional Encoding]\n    T --> C[Layer Normalization]\n\n    A --> A1[Self-Attention]\n    A --> A2[Cross-Attention]\n    A --> A3[Attention Rollout]\n\n    A3 --> A3a[Layer 1 Attention]\n    A3 --> A3b[Layer 2 Attention]\n    A3 --> A3c[Combined Influence]\n```\n\n### **Graph 3: RAG Pipeline**\n```mermaid\ngraph TD\n    R[RAG] --> R1[Retriever]\n    R --> R2[Generator]\n\n    R1 --> R1a[Dense: DPR/BERT]\n    R1 --> R1b[Sparse: BM25/TF-IDF]\n\n    R2 --> R2a[BART]\n    R2 --> R2b[T5]\n    R2 --> R2c[Instruction-Tuned LLM]\n```\n\n### **Graph 4: Bias in NLP**\n```mermaid\ngraph TD\n    Bias[NLP Bias] --> Source[Sources]\n    Bias --> Impact[Impacts]\n    Bias --> Mitigation[Mitigation]\n\n    Source --> S1[Training Data]\n    Source --> S2[Human Feedback]\n    Source --> S3[Model Architecture]\n\n    Impact --> I1[Stereotype Reinforcement]\n    Impact --> I2[Unfair Outcomes]\n    Impact --> I3[Legal Risks]\n\n    Mitigation --> M1[Debiasing Embeddings]\n    Mitigation --> M2[Balanced Datasets]\n    Mitigation --> M3[Fairness Constraints]\n```\n\n### **Graph 5: Decoding Strategies**\n```mermaid\ngraph LR\n    Decoding[Decoding] --> Greedy[Greedy Search]\n    Decoding --> Beam[Beam Search]\n    Decoding --> Speculative[Speculative Decoding]\n\n    Beam --> B1[Beam Width]\n    Beam --> B2[Pruning]\n\n    Speculative --> S1[Draft Model]\n    Speculative --> S2[Main Model]\n    Speculative --> S3[Acceptance Rule]\n```\n\n---\n## **4. Exam Preparation Checklist**\n### **Must-Know Topics**\n1. **POS Tagging**: Stochastic methods, Viterbi, class imbalance issues.\n2. **Transformers**: Attention flow, BERT vs. GPT, RAG architecture.\n3. **Ethics**: Bias sources, Shapley values, fairness metrics.\n4. **Decoding**: Beam search, teacher forcing, speculative decoding.\n5. **Efficiency**: LoRA, QLoRA, few-shot prompting.\n6. **IR**: TF-IDF, BM25, dense retrieval (DPR).\n7. **Explainability**: Integrated gradients, Shapley values.\n\n### **Key Equations to Memorize**\n- TF-IDF\n- Attention Rollout\n- Beam Search Pruning\n- Temperature Scaling\n- Shapley Value Formula\n\n### **Problem-Solving Tips**\n- **TF-IDF/BM25**: Always check if log is base 10 or natural log.\n- **Attention Rollout**: Multiply attention matrices layer-wise.\n- **Beam Search**: Final sequences = beam width (regardless of steps).\n- **Shapley Values**: Calculate marginal contributions systematically.\n- **Speculative Decoding**: Compare `P_main` vs. `P_draft` for acceptance.",
        "total_score": "100.00"
    },
    "url": "/question-paper/practise/83/42ef11a8-88a",
    "version": "ee3d5d44299e610bd137ea6200db5ac2"
}