{
    "component": "Quizpractise/PractiseQuestionPaper",
    "props": {
        "errors": {},
        "auth": {
            "user": null
        },
        "flash": {
            "error": []
        },
        "banner": null,
        "file_url": "https://saram.blr1.cdn.digitaloceanspaces.com",
        "file_do_url": "https://saram.blr1.cdn.digitaloceanspaces.com",
        "question_paper": {
            "id": 261,
            "group_id": 27,
            "exam_id": 3,
            "total_score": "1.00",
            "duration": 4,
            "created_at": "2025-04-17T15:54:45.000000Z",
            "updated_at": "2025-04-17T15:54:45.000000Z",
            "question_paper_name": "IIT M FOUNDATION AN EXAM QDF3 13 Apr",
            "question_paper_description": "2025 Apr13: IIT M AN EXAM QDF3",
            "uuid": "3eff3f7d-82c",
            "year": 2025,
            "is_new": 0,
            "exam": {
                "id": 3,
                "exam_name": "End Term Quiz",
                "created_at": "2024-10-16T08:08:51.000000Z",
                "updated_at": "2024-10-16T08:08:51.000000Z",
                "uuid": "7a6ff569-f50c-40e7-a08b-f5c334392600",
                "en_id": "eyJpdiI6Im1OczZ1c0xNeTJUY0lWMnRFTkc3WlE9PSIsInZhbHVlIjoiQk9heDBUT3UxbFlKa3VQTDlCUEYrdz09IiwibWFjIjoiYWZkMjVlNzMyYTEzMmY2MTJmZTEwOWQ5ZTczOWFkZjBkMGYwODJiYzQ5ZjBlZjJkOTNkODlkZTY3NDlmZGY0NyIsInRhZyI6IiJ9"
            },
            "questions": [
                {
                    "id": 82439,
                    "exam_id": 3,
                    "question_paper_id": 261,
                    "question_number": 141,
                    "question_text_1": "THIS IS QUESTION PAPER FOR THE SUBJECT <b>\"DEGREE LEVEL : INTRODUCTION TO NATURAL </b><b>LANGUAGE PROCESSING (COMPUTER BASED EXAM)\"</b><b> </b><b> </b><b>ARE YOU SURE YOU HAVE TO WRITE EXAM FOR THIS SUBJECT? </b><b>CROSS CHECK YOUR HALL TICKET TO CONFIRM THE SUBJECTS TO BE WRITTEN. </b><b> </b><b>(IF IT IS NOT THE CORRECT SUBJECT, PLS CHECK THE SECTION AT THE TOP FOR THE SUBJECTS </b><b>REGISTERED BY YOU)</b>",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "0.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:54:46.000000Z",
                    "updated_at": "2025-04-17T15:54:46.000000Z",
                    "question_num_long": 6406531246119,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "de1530d735a56c402434ccdda358f52d",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "4f443ab6-4d41-49f8-9fd2-709b7f0dadea",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "THIS IS QUESTION PAPER FOR THE SUBJECT <b>\"DEGREE LEVEL : INTRODUCTION TO NATURAL </b><b>LANGUAGE PROCESSING (COMPUTER BASED EXAM)\"</b><b> </b><b> </b><b>ARE YOU SURE YOU HAVE TO WRITE EXAM FOR THIS SUBJECT? </b><b>CROSS CHECK YOUR HALL TICKET TO CONFIRM THE SUBJECTS TO BE WRITTEN. </b><b> </b><b>(IF IT IS NOT THE CORRECT SUBJECT, PLS CHECK THE SECTION AT THE TOP FOR THE SUBJECTS </b><b>REGISTERED BY YOU)</b>"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 220702,
                            "question_id": 82439,
                            "option_text": "YES",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201300,
                            "option_image_url": null
                        },
                        {
                            "id": 220703,
                            "question_id": 82439,
                            "option_text": "NO",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201301,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 82440,
                    "exam_id": 3,
                    "question_paper_id": 261,
                    "question_number": 142,
                    "question_text_1": "Why might accuracy be a misleading metric for evaluating POS tagging systems in cases of class imbalance?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:54:46.000000Z",
                    "updated_at": "2025-04-17T15:54:46.000000Z",
                    "question_num_long": 6406531246120,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "115a26477aa2dd1b6e11baf335c0bfb0",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "3446c637-e5f6-455c-b70b-5765a7cdc301",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Why might accuracy be a misleading metric for evaluating POS tagging systems in cases of class imbalance?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 220704,
                            "question_id": 82440,
                            "option_text": "Because accuracy does not account for the number of true negatives.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201302,
                            "option_image_url": null
                        },
                        {
                            "id": 220705,
                            "question_id": 82440,
                            "option_text": "Because accuracy gives equal weight to all classes, even if some tags are muchrarer than others.",
                            "option_image": "",
                            "score": "3.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201303,
                            "option_image_url": null
                        },
                        {
                            "id": 220706,
                            "question_id": 82440,
                            "option_text": "Because accuracy only measures the precision of the system, ignoring recall.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201304,
                            "option_image_url": null
                        },
                        {
                            "id": 220707,
                            "question_id": 82440,
                            "option_text": "Because accuracy is not affected by the number of false positives and falsenegatives.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201305,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 82441,
                    "exam_id": 3,
                    "question_paper_id": 261,
                    "question_number": 143,
                    "question_text_1": "In stochastic POS tagging, why is it necessary to calculate both individual word probabilities and tag sequence probabilities?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:54:46.000000Z",
                    "updated_at": "2025-04-17T15:54:46.000000Z",
                    "question_num_long": 6406531246121,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "908e0b283e8621a9a34ef60b6bd0fd20",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "199e90d7-4024-4860-b06c-fd992caf981e",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "In stochastic POS tagging, why is it necessary to calculate both individual word probabilities and tag sequence probabilities?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 220708,
                            "question_id": 82441,
                            "option_text": "Individual word probabilities are sufficient for accurate tagging, and tagsequence probabilities are redundant.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201306,
                            "option_image_url": null
                        },
                        {
                            "id": 220709,
                            "question_id": 82441,
                            "option_text": "Individual word probabilities are only used for rare words, while tag sequenceprobabilities are used for common words.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201307,
                            "option_image_url": null
                        },
                        {
                            "id": 220710,
                            "question_id": 82441,
                            "option_text": "Tag sequence probabilities help in determining the most likely sequence oftags, while individual word probabilities provide local context.",
                            "option_image": "",
                            "score": "3.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201308,
                            "option_image_url": null
                        },
                        {
                            "id": 220711,
                            "question_id": 82441,
                            "option_text": "Both probabilities are used to reduce the computational complexity of thetagging process.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201309,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 82442,
                    "exam_id": 3,
                    "question_paper_id": 261,
                    "question_number": 144,
                    "question_text_1": "How does Retrieval-Augmented Generation (RAG) differ from standard parametric models like GPT-3?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:54:46.000000Z",
                    "updated_at": "2025-04-17T15:54:46.000000Z",
                    "question_num_long": 6406531246124,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "93e358abb91f6594c0f9703844cbe08c",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "a785cc6d-699c-44c2-8d27-941eb681e836",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "How does Retrieval-Augmented Generation (RAG) differ from standard parametric models like GPT-3?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 220712,
                            "question_id": 82442,
                            "option_text": "RAG eliminates the need for transformer-based token generation.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201318,
                            "option_image_url": null
                        },
                        {
                            "id": 220713,
                            "question_id": 82442,
                            "option_text": "RAG uses retrieval but does not update its knowledge dynamically over time.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201319,
                            "option_image_url": null
                        },
                        {
                            "id": 220714,
                            "question_id": 82442,
                            "option_text": "RAG only works when trained on labeled question-answer datasets.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201320,
                            "option_image_url": null
                        },
                        {
                            "id": 220715,
                            "question_id": 82442,
                            "option_text": "RAG retrieves external documents dynamically, reducing reliance on pre-trained knowledge.",
                            "option_image": "",
                            "score": "3.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201321,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 82443,
                    "exam_id": 3,
                    "question_paper_id": 261,
                    "question_number": 145,
                    "question_text_1": "Which of the following architectures is most commonly used as the generator in RAG models?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:54:46.000000Z",
                    "updated_at": "2025-04-17T15:54:46.000000Z",
                    "question_num_long": 6406531246125,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "8cf15668091ba56d4fc2620b87c93487",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "76cd5e59-cf4c-4a60-a338-06d89d5b769e",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following architectures is most commonly used as the generator in RAG models?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 220716,
                            "question_id": 82443,
                            "option_text": "GPT-3",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201322,
                            "option_image_url": null
                        },
                        {
                            "id": 220717,
                            "question_id": 82443,
                            "option_text": "BART",
                            "option_image": "",
                            "score": "3.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201323,
                            "option_image_url": null
                        },
                        {
                            "id": 220718,
                            "question_id": 82443,
                            "option_text": "BERT",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201324,
                            "option_image_url": null
                        },
                        {
                            "id": 220719,
                            "question_id": 82443,
                            "option_text": "RoBERTa",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201325,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 82444,
                    "exam_id": 3,
                    "question_paper_id": 261,
                    "question_number": 146,
                    "question_text_1": "A company wants to optimize an LLM for programming tasks. Which approach is the most efficient if they have limited labeled data?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:54:46.000000Z",
                    "updated_at": "2025-04-17T15:54:46.000000Z",
                    "question_num_long": 6406531246126,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "aa3502a115f29173d83a9aa93e1095b5",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "2e0affa3-1309-4949-be0a-f0c87bd72e33",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "A company wants to optimize an LLM for programming tasks. Which approach is the most efficient if they have limited labeled data?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 220720,
                            "question_id": 82444,
                            "option_text": "Train a new model from scratch using a large programming dataset.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201326,
                            "option_image_url": null
                        },
                        {
                            "id": 220721,
                            "question_id": 82444,
                            "option_text": "Fine-tune a transformer model with instruction tuning.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201327,
                            "option_image_url": null
                        },
                        {
                            "id": 220722,
                            "question_id": 82444,
                            "option_text": "Use Few-shot prompting with an existing LLM.",
                            "option_image": "",
                            "score": "3.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201328,
                            "option_image_url": null
                        },
                        {
                            "id": 220723,
                            "question_id": 82444,
                            "option_text": "Apply a BERT-based model instead of transformers.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201329,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 82445,
                    "exam_id": 3,
                    "question_paper_id": 261,
                    "question_number": 147,
                    "question_text_1": "Which of the following statements about Attention Flow in Transformer models is TRUE?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:54:46.000000Z",
                    "updated_at": "2025-04-17T15:54:46.000000Z",
                    "question_num_long": 6406531246128,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "077b8154b4852c3b386ec32ea36c4aee",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "2cb302a9-413a-4771-a597-a7ed55b99213",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following statements about Attention Flow in Transformer models is TRUE?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 220724,
                            "question_id": 82445,
                            "option_text": "Attention flow computes the contribution of each token independently withoutconsidering other tokens.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201334,
                            "option_image_url": null
                        },
                        {
                            "id": 220725,
                            "question_id": 82445,
                            "option_text": "Attention flow assigns higher scores to tokens that appear earlier in thesequence by default.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201335,
                            "option_image_url": null
                        },
                        {
                            "id": 220726,
                            "question_id": 82445,
                            "option_text": "Attention flow combines attention scores across multiple layers to determineoverall token influence.",
                            "option_image": "",
                            "score": "3.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201336,
                            "option_image_url": null
                        },
                        {
                            "id": 220727,
                            "question_id": 82445,
                            "option_text": "Attention flow values are always normalized across all tokens in the sequenceto sum to 1.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201337,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 82446,
                    "exam_id": 3,
                    "question_paper_id": 261,
                    "question_number": 148,
                    "question_text_1": "Which of the following scenarios represents an ethical concern with LLM deployment?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:54:46.000000Z",
                    "updated_at": "2025-04-17T15:54:46.000000Z",
                    "question_num_long": 6406531246129,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "35ddfb6a4675459205e21bef9bdb4cd7",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "4520a48a-ba1c-42bb-985a-27be20cd6842",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following scenarios represents an ethical concern with LLM deployment?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 220728,
                            "question_id": 82446,
                            "option_text": "A summarization model shortening news articles while maintaining factualaccuracy.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201338,
                            "option_image_url": null
                        },
                        {
                            "id": 220729,
                            "question_id": 82446,
                            "option_text": "A question-answering system providing different answers for differentdemographics when asked about salary negotiations.",
                            "option_image": "",
                            "score": "3.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201339,
                            "option_image_url": null
                        },
                        {
                            "id": 220730,
                            "question_id": 82446,
                            "option_text": "A chatbot refusing to generate offensive or harmful content.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201340,
                            "option_image_url": null
                        },
                        {
                            "id": 220731,
                            "question_id": 82446,
                            "option_text": "A translation model translating medical terms with higher accuracy thangeneral terms.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201341,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 82447,
                    "exam_id": 3,
                    "question_paper_id": 261,
                    "question_number": 149,
                    "question_text_1": "How does an LSTM differ from a standard RNN in terms of remembering information?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "4.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:54:46.000000Z",
                    "updated_at": "2025-04-17T15:54:46.000000Z",
                    "question_num_long": 6406531246122,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "cc205b70e33f321beec8245768dfd75b",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "d5f79275-1a4e-45b2-acb0-71b60f51d5ff",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "How does an LSTM differ from a standard RNN in terms of remembering information?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 220732,
                            "question_id": 82447,
                            "option_text": "It uses a larger hidden state.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201310,
                            "option_image_url": null
                        },
                        {
                            "id": 220733,
                            "question_id": 82447,
                            "option_text": "It stores all past hidden states explicitly.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201311,
                            "option_image_url": null
                        },
                        {
                            "id": 220734,
                            "question_id": 82447,
                            "option_text": "It introduces gates to control the flow of information.",
                            "option_image": "",
                            "score": "4.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201312,
                            "option_image_url": null
                        },
                        {
                            "id": 220735,
                            "question_id": 82447,
                            "option_text": "It completely replaces hidden states with attention mechanisms.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201313,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 82448,
                    "exam_id": 3,
                    "question_paper_id": 261,
                    "question_number": 150,
                    "question_text_1": "In the context of speculative decoding, a draft model predicts three tokens: \"a\", \"quick\", \"fox\". The main model assigns probabilities 0.8, 0.6, and 0.8 respectively.The draft model's probabilities for these words were 0.7, 0.9, and 0.9. \nWhich tokens are most likely to be accepted?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "5.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:54:46.000000Z",
                    "updated_at": "2025-04-17T15:54:46.000000Z",
                    "question_num_long": 6406531246123,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "6e37e5061098404822fdeec4b7675e3f",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "5ea6d627-b5be-40bd-a363-c05d2806af17",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "In the context of speculative decoding, a draft model predicts three tokens: \"a\", \"quick\", \"fox\". The main model assigns probabilities 0.8, 0.6, and 0.8 respectively.The draft model's probabilities for these words were 0.7, 0.9, and 0.9. \nWhich tokens are most likely to be accepted?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 220736,
                            "question_id": 82448,
                            "option_text": "All three tokens",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201314,
                            "option_image_url": null
                        },
                        {
                            "id": 220737,
                            "question_id": 82448,
                            "option_text": "Only \"a\" and \"fox\"",
                            "option_image": "",
                            "score": "5.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201315,
                            "option_image_url": null
                        },
                        {
                            "id": 220738,
                            "question_id": 82448,
                            "option_text": "Only \"a\"",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201316,
                            "option_image_url": null
                        },
                        {
                            "id": 220739,
                            "question_id": 82448,
                            "option_text": "None of the tokens",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201317,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 82449,
                    "exam_id": 3,
                    "question_paper_id": 261,
                    "question_number": 151,
                    "question_text_1": "Consider the following attention matrices for two layers (corresponding to tokens 1 and 2) in a transformer model: \nLayer 1 Attention Matrix: \n",
                    "question_image_1": "hAMqzIevAcBR9LmjDxy4WhUvHwp0DjkqCmNROC98rQmjUsY9fA.png",
                    "question_type": "MCQ",
                    "total_mark": "5.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:54:46.000000Z",
                    "updated_at": "2025-04-17T15:54:46.000000Z",
                    "question_num_long": 6406531246127,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "dd305f16e821c3075c08ee678f75a3f0",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": "Consider the following attention matrices for two layers (corresponding to tokens 1 and 2) in a transformer model: \nLayer 1 Attention Matrix: \n  Layer 2 Attention Matrix: \n",
                    "question_image_2": "BclPD1XBUtizb0gWM4EBYspBPIUEvordPeLSqbucMO5nsxaDjp.png",
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": "Consider the following attention matrices for two layers (corresponding to tokens 1 and 2) in a transformer model: \nLayer 1 Attention Matrix: \n  Layer 2 Attention Matrix: \n  What is the total attention from token 2 to token 1 after performing attention rollout?",
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "88018592-436a-4dee-95fc-c624aea690a5",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/hAMqzIevAcBR9LmjDxy4WhUvHwp0DjkqCmNROC98rQmjUsY9fA.png",
                        "/question_images/BclPD1XBUtizb0gWM4EBYspBPIUEvordPeLSqbucMO5nsxaDjp.png"
                    ],
                    "question_texts": [
                        "Consider the following attention matrices for two layers (corresponding to tokens 1 and 2) in a transformer model: \nLayer 1 Attention Matrix: \n",
                        "Consider the following attention matrices for two layers (corresponding to tokens 1 and 2) in a transformer model: \nLayer 1 Attention Matrix: \n  Layer 2 Attention Matrix: \n",
                        "Consider the following attention matrices for two layers (corresponding to tokens 1 and 2) in a transformer model: \nLayer 1 Attention Matrix: \n  Layer 2 Attention Matrix: \n  What is the total attention from token 2 to token 1 after performing attention rollout?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 220740,
                            "question_id": 82449,
                            "option_text": "0.57",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201330,
                            "option_image_url": null
                        },
                        {
                            "id": 220741,
                            "question_id": 82449,
                            "option_text": "0.33",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201331,
                            "option_image_url": null
                        },
                        {
                            "id": 220742,
                            "question_id": 82449,
                            "option_text": "0.39",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201332,
                            "option_image_url": null
                        },
                        {
                            "id": 220743,
                            "question_id": 82449,
                            "option_text": "0.26",
                            "option_image": "",
                            "score": "5.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201333,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 82450,
                    "exam_id": 3,
                    "question_paper_id": 261,
                    "question_number": 152,
                    "question_text_1": "Which of the following sentences contain pragmatic ambiguity due to potential sarcasm or irony?",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "6.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:54:46.000000Z",
                    "updated_at": "2025-04-17T15:54:46.000000Z",
                    "question_num_long": 6406531246130,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "c8cbeeeeb35e4c5ed4d1a297d00d38d4",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "48597f1a-283f-4cfd-b053-7a726e6a7200",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following sentences contain pragmatic ambiguity due to potential sarcasm or irony?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 220744,
                            "question_id": 82450,
                            "option_text": "\"Wow, another Monday! Just what I needed.\"",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201342,
                            "option_image_url": null
                        },
                        {
                            "id": 220745,
                            "question_id": 82450,
                            "option_text": "\"The meeting was only three hours long. So productive!\"",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201343,
                            "option_image_url": null
                        },
                        {
                            "id": 220746,
                            "question_id": 82450,
                            "option_text": "\"I love spending hours in traffic. It\u2019s my favorite part of the day.\"",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201344,
                            "option_image_url": null
                        },
                        {
                            "id": 220747,
                            "question_id": 82450,
                            "option_text": "\"The weather is perfect for a picnic today.\"",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201345,
                            "option_image_url": null
                        },
                        {
                            "id": 220748,
                            "question_id": 82450,
                            "option_text": "\"She always arrives on time, unlike some people.\"",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201346,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 82451,
                    "exam_id": 3,
                    "question_paper_id": 261,
                    "question_number": 153,
                    "question_text_1": "Which of the following statements correctly describe how BERT differs from GPT and standard transformer models?",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "4.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:54:46.000000Z",
                    "updated_at": "2025-04-17T15:54:46.000000Z",
                    "question_num_long": 6406531246131,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "4c6be50b19afdbf32ec1cbf9d20a0e44",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "f17890b5-da84-42a7-8471-e27ae6e7f766",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following statements correctly describe how BERT differs from GPT and standard transformer models?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 220749,
                            "question_id": 82451,
                            "option_text": "BERT is a bidirectional model, while GPT is autoregressive.",
                            "option_image": "",
                            "score": "1.333",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201347,
                            "option_image_url": null
                        },
                        {
                            "id": 220750,
                            "question_id": 82451,
                            "option_text": "BERT uses masked language modeling (MLM), while GPT uses causal languagemodeling (CLM).",
                            "option_image": "",
                            "score": "1.333",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201348,
                            "option_image_url": null
                        },
                        {
                            "id": 220751,
                            "question_id": 82451,
                            "option_text": "Standard transformers use encoder-only architectures, whereas BERT and GPTboth use decoder-only architectures.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201349,
                            "option_image_url": null
                        },
                        {
                            "id": 220752,
                            "question_id": 82451,
                            "option_text": "BERT is trained for sentence embeddings, while GPT is trained for next-tokenprediction.",
                            "option_image": "",
                            "score": "1.333",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201350,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 82452,
                    "exam_id": 3,
                    "question_paper_id": 261,
                    "question_number": 154,
                    "question_text_1": "Which of the following statements is/are incorrect regarding Reinforcement Learning from Human Feedback (RLHF), Supervised Instruction Fine-Tuning, LoRA, and QLoRA?",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "4.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:54:46.000000Z",
                    "updated_at": "2025-04-17T15:54:46.000000Z",
                    "question_num_long": 6406531246132,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "2873d631553fc3ff61377671df8991ef",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "d8bb24ef-ff2b-46dc-8fb1-60bd0b92952b",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following statements is/are incorrect regarding Reinforcement Learning from Human Feedback (RLHF), Supervised Instruction Fine-Tuning, LoRA, and QLoRA?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 220753,
                            "question_id": 82452,
                            "option_text": "RLHF helps improve model behavior by learning from human preferencerankings.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201351,
                            "option_image_url": null
                        },
                        {
                            "id": 220754,
                            "question_id": 82452,
                            "option_text": "LoRA (Low-Rank Adaptation) reduces the number of trainable parameters byusing low-rank matrices.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201352,
                            "option_image_url": null
                        },
                        {
                            "id": 220755,
                            "question_id": 82452,
                            "option_text": "Supervised Instruction Fine-Tuning involves reinforcement learning forgenerating human-like responses.",
                            "option_image": "",
                            "score": "4.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201353,
                            "option_image_url": null
                        },
                        {
                            "id": 220756,
                            "question_id": 82452,
                            "option_text": "QLoRA applies quantization to reduce memory consumption during fine-tuning.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201354,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 82453,
                    "exam_id": 3,
                    "question_paper_id": 261,
                    "question_number": 155,
                    "question_text_1": "During sequence-to-sequence model training, which of the following statements is/are correct regarding Teacher Forcing and Student Forcing?",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "4.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:54:46.000000Z",
                    "updated_at": "2025-04-17T15:54:46.000000Z",
                    "question_num_long": 6406531246133,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "7057fa09cae8c6cc3d96067494209c10",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "9c580146-db19-44f9-a45b-a594855da617",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "During sequence-to-sequence model training, which of the following statements is/are correct regarding Teacher Forcing and Student Forcing?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 220757,
                            "question_id": 82453,
                            "option_text": "Teacher Forcing is used during inference, while Student Forcing is used duringtraining.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201355,
                            "option_image_url": null
                        },
                        {
                            "id": 220758,
                            "question_id": 82453,
                            "option_text": "Teacher Forcing provides the correct previous output as input during training,whereas Student Forcing generates outputs based on its own previous predictions.",
                            "option_image": "",
                            "score": "4.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201356,
                            "option_image_url": null
                        },
                        {
                            "id": 220759,
                            "question_id": 82453,
                            "option_text": "Student Forcing helps the model converge faster than Teacher Forcing.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201357,
                            "option_image_url": null
                        },
                        {
                            "id": 220760,
                            "question_id": 82453,
                            "option_text": "Teacher Forcing is mainly used in reinforcement learning settings.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201358,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 82454,
                    "exam_id": 3,
                    "question_paper_id": 261,
                    "question_number": 156,
                    "question_text_1": "Which of the following statements about beam search is/are <b>incorrect</b> ?",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "4.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:54:46.000000Z",
                    "updated_at": "2025-04-17T15:54:46.000000Z",
                    "question_num_long": 6406531246134,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "3f608659a5c581c41e6d3cc9c4f2a8d2",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "261e1f73-5dd6-41db-92d6-a85ec199504d",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following statements about beam search is/are <b>incorrect</b> ?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 220761,
                            "question_id": 82454,
                            "option_text": "Beam search balances exploration and exploitation by considering multiplesequences at each step.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201359,
                            "option_image_url": null
                        },
                        {
                            "id": 220762,
                            "question_id": 82454,
                            "option_text": "A larger beam width increases computational cost but improves searchquality.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201360,
                            "option_image_url": null
                        },
                        {
                            "id": 220763,
                            "question_id": 82454,
                            "option_text": "Greedy search is equivalent to beam search with beam size B = 1.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201361,
                            "option_image_url": null
                        },
                        {
                            "id": 220764,
                            "question_id": 82454,
                            "option_text": "Unlike greedy search, beam search guarantees finding the globally optimalsequence.",
                            "option_image": "",
                            "score": "4.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201362,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 82455,
                    "exam_id": 3,
                    "question_paper_id": 261,
                    "question_number": 157,
                    "question_text_1": "Which components are essential in a RAG pipeline?",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "4.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:54:46.000000Z",
                    "updated_at": "2025-04-17T15:54:46.000000Z",
                    "question_num_long": 6406531246136,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "d2e45a2223e0c71f49a3756f86c0fe99",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "3197f7d4-ad25-40fe-bdda-d78a5a3338e8",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which components are essential in a RAG pipeline?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 220765,
                            "question_id": 82455,
                            "option_text": "retriever model (e.g., DPR) that fetches relevant documents.",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201368,
                            "option_image_url": null
                        },
                        {
                            "id": 220766,
                            "question_id": 82455,
                            "option_text": "decoder-only transformer for sequence generation.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201369,
                            "option_image_url": null
                        },
                        {
                            "id": 220767,
                            "question_id": 82455,
                            "option_text": "BM25-based sparse retrieval method as the primary retriever.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201370,
                            "option_image_url": null
                        },
                        {
                            "id": 220768,
                            "question_id": 82455,
                            "option_text": "BERT-based query encoder for document ranking.",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201371,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 82456,
                    "exam_id": 3,
                    "question_paper_id": 261,
                    "question_number": 158,
                    "question_text_1": "Which of the following are the examples of unintended bias in an NLP model?",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "4.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:54:46.000000Z",
                    "updated_at": "2025-04-17T15:54:46.000000Z",
                    "question_num_long": 6406531246137,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "34bc5059f954eb8ed04afe9065577a9a",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "47e57b31-ea2e-4eac-bd3c-8f684e3577be",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following are the examples of unintended bias in an NLP model?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 220769,
                            "question_id": 82456,
                            "option_text": "A sentiment analysis model rating all political tweets as \"negative\".",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201372,
                            "option_image_url": null
                        },
                        {
                            "id": 220770,
                            "question_id": 82456,
                            "option_text": "A chatbot trained specifically for medical consultations failing on legal queries.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201373,
                            "option_image_url": null
                        },
                        {
                            "id": 220771,
                            "question_id": 82456,
                            "option_text": "A text summarization model producing longer summaries for academicpapers.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201374,
                            "option_image_url": null
                        },
                        {
                            "id": 220772,
                            "question_id": 82456,
                            "option_text": "A machine translation system translating \"doctor\" to \"he\" and \"nurse\" to \"she\"in a gender-neutral language.",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201375,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 82457,
                    "exam_id": 3,
                    "question_paper_id": 261,
                    "question_number": 159,
                    "question_text_1": "Which of the following factors contribute to bias amplification in NLP models?",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "4.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:54:46.000000Z",
                    "updated_at": "2025-04-17T15:54:46.000000Z",
                    "question_num_long": 6406531246138,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "ed8ba3a4b93963531798e3f42d75e57f",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "ab234a9a-c2bc-4ae3-99cb-7e0ca1e474be",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following factors contribute to bias amplification in NLP models?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 220773,
                            "question_id": 82457,
                            "option_text": "Reinforcement learning from biased human feedback.",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201376,
                            "option_image_url": null
                        },
                        {
                            "id": 220774,
                            "question_id": 82457,
                            "option_text": "Training on unbalanced datasets where stereotypes exist.",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201377,
                            "option_image_url": null
                        },
                        {
                            "id": 220775,
                            "question_id": 82457,
                            "option_text": "Applying debiasing techniques such as zeroing out gender-related wordembeddings.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201378,
                            "option_image_url": null
                        },
                        {
                            "id": 220776,
                            "question_id": 82457,
                            "option_text": "Using a larger model size to improve performance.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201379,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 82458,
                    "exam_id": 3,
                    "question_paper_id": 261,
                    "question_number": 160,
                    "question_text_1": null,
                    "question_image_1": "HFuWlGKjfEXaSLP0j4FdZIOPlQMAuXSuBHblMfFaXI3ouko68w.png",
                    "question_type": "MSQ",
                    "total_mark": "5.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:54:46.000000Z",
                    "updated_at": "2025-04-17T15:54:46.000000Z",
                    "question_num_long": 6406531246135,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "0b4b9de6b821712be26ea86b1910f5b7",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "f47f9cf9-61c8-493a-b04f-cc3732883796",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/HFuWlGKjfEXaSLP0j4FdZIOPlQMAuXSuBHblMfFaXI3ouko68w.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 220777,
                            "question_id": 82458,
                            "option_text": "The probability of \"apple\" increases further.",
                            "option_image": "",
                            "score": "5.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201363,
                            "option_image_url": null
                        },
                        {
                            "id": 220778,
                            "question_id": 82458,
                            "option_text": "The probabilities of \"banana\" and \"cherry\" become closer to \"apple\".",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201364,
                            "option_image_url": null
                        },
                        {
                            "id": 220779,
                            "question_id": 82458,
                            "option_text": "The probabilities remain unchanged.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201365,
                            "option_image_url": null
                        },
                        {
                            "id": 220780,
                            "question_id": 82458,
                            "option_text": "The model always picks \"banana\".",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201366,
                            "option_image_url": null
                        },
                        {
                            "id": 220781,
                            "question_id": 82458,
                            "option_text": "The model always picks \"cherry\".",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:54:46.000000Z",
                            "updated_at": "2025-04-17T15:54:46.000000Z",
                            "option_number": 6406534201367,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 82459,
                    "exam_id": 3,
                    "question_paper_id": 261,
                    "question_number": 161,
                    "question_text_1": "In a transition-based parser using SHIFT, LEFTARC, and RIGHTARC operations, what is the minimum number of operations needed to parse the sentence \"I love coding\" (excluding the ROOT node)?",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "4",
                    "value_end": null,
                    "created_at": "2025-04-17T15:54:46.000000Z",
                    "updated_at": "2025-04-17T15:54:46.000000Z",
                    "question_num_long": 6406531246139,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "c42e061fa196673e2b7926a38fb481f8",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "61670cb9-57d8-4cce-8e42-41d3040f86e9",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "In a transition-based parser using SHIFT, LEFTARC, and RIGHTARC operations, what is the minimum number of operations needed to parse the sentence \"I love coding\" (excluding the ROOT node)?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 82460,
                    "exam_id": 3,
                    "question_paper_id": 261,
                    "question_number": 162,
                    "question_text_1": "A TF-IDF model is applied to a document corpus of 50,000 documents. The term \"optimization\" appears in 750 documents. In a specific document, \"optimization\" appears 8 times, and the total number of words in that document is 1200. Using log base 10 ( log10), compute the TF-IDF score for \"optimization\" in this document. Enter your answer correct to three decimal places.",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "0.01",
                    "value_end": "0.02",
                    "created_at": "2025-04-17T15:54:46.000000Z",
                    "updated_at": "2025-04-17T15:54:46.000000Z",
                    "question_num_long": 6406531246140,
                    "answer_type": "Range",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "543739031a2e749bac83729c604cbb2b",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "858f842b-4daf-4d2f-9fa4-a0ba54391aa6",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "A TF-IDF model is applied to a document corpus of 50,000 documents. The term \"optimization\" appears in 750 documents. In a specific document, \"optimization\" appears 8 times, and the total number of words in that document is 1200. Using log base 10 ( log10), compute the TF-IDF score for \"optimization\" in this document. Enter your answer correct to three decimal places."
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 82461,
                    "exam_id": 3,
                    "question_paper_id": 261,
                    "question_number": 163,
                    "question_text_1": "A beam search with beam width = 4 and vocabulary size = 8 is run for 3 decoding steps. How many sequences will remain at the end of 3 steps after pruning?",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "4",
                    "value_end": null,
                    "created_at": "2025-04-17T15:54:46.000000Z",
                    "updated_at": "2025-04-17T15:54:46.000000Z",
                    "question_num_long": 6406531246141,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "c42e061fa196673e2b7926a38fb481f8",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "9a9f5228-470c-4ba6-985a-8433197a5fa3",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "A beam search with beam width = 4 and vocabulary size = 8 is run for 3 decoding steps. How many sequences will remain at the end of 3 steps after pruning?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 82462,
                    "exam_id": 3,
                    "question_paper_id": 261,
                    "question_number": 164,
                    "question_text_1": "A transformer-based Retrieval-Augmented Generation (RAG) system retrieves the top-10 most relevant passages, where each passage contains 512 tokens. However, a portion of the model's 4096-token context length is reserved for the input query and special tokens (e.g., separators, instructions). If the model reserves 1024 tokens for the input query, how many full retrieved passages can fit within the remaining context window?",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "6",
                    "value_end": null,
                    "created_at": "2025-04-17T15:54:46.000000Z",
                    "updated_at": "2025-04-17T15:54:46.000000Z",
                    "question_num_long": 6406531246142,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "5cf4d6da8aaac9aba83ab6069f95efad",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "5ab80bfb-9e65-443f-b9b4-fce32a949390",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "A transformer-based Retrieval-Augmented Generation (RAG) system retrieves the top-10 most relevant passages, where each passage contains 512 tokens. However, a portion of the model's 4096-token context length is reserved for the input query and special tokens (e.g., separators, instructions). If the model reserves 1024 tokens for the input query, how many full retrieved passages can fit within the remaining context window?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 82463,
                    "exam_id": 3,
                    "question_paper_id": 261,
                    "question_number": 165,
                    "question_text_1": "Consider the following regression model: \nF(x) = 500 * Age + 1000 * Income + 20000 \nFor an input with:  Age = 30 Income = 50 \n<b>Baseline Input:</b>\n\nAge = 0 Income = 0 \nWhat is the Integrated Gradient for the feature Income?",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "50000",
                    "value_end": null,
                    "created_at": "2025-04-17T15:54:46.000000Z",
                    "updated_at": "2025-04-17T15:54:46.000000Z",
                    "question_num_long": 6406531246143,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "95e0cd9df1bce0bb68829f80b2cc96aa",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "ebcb0a90-f65e-4373-ab04-56845a130f3b",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Consider the following regression model: \nF(x) = 500 * Age + 1000 * Income + 20000 \nFor an input with:  Age = 30 Income = 50 \n<b>Baseline Input:</b>\n\nAge = 0 Income = 0 \nWhat is the Integrated Gradient for the feature Income?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 82464,
                    "exam_id": 3,
                    "question_paper_id": 261,
                    "question_number": 166,
                    "question_text_1": null,
                    "question_image_1": "SCfkfDXWI8ImW5wUU0frU1x6SknIR4rjMhXHxIRf9GOxK48YF6.png",
                    "question_type": "SA",
                    "total_mark": "6.00",
                    "value_start": "162",
                    "value_end": "163",
                    "created_at": "2025-04-17T15:54:46.000000Z",
                    "updated_at": "2025-04-17T15:54:46.000000Z",
                    "question_num_long": 6406531246144,
                    "answer_type": "Range",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "07269589e9325fb496ab6b21170e0819",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "e328d809-ad7a-4f7b-93da-ee4b499e8909",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/SCfkfDXWI8ImW5wUU0frU1x6SknIR4rjMhXHxIRf9GOxK48YF6.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [],
                    "parent_question": null
                }
            ]
        },
        "summary": "Here\u2019s a structured **summary of core topics, concepts, principles, and equations** essential for the **Introduction to Natural Language Processing (NLP)** exam, along with **Mermaid knowledge graphs** to visualize relationships.\n\n---\n\n---\n\n### **1. Core Topics & Concepts**\n#### **A. Evaluation Metrics & Class Imbalance**\n- **Accuracy Pitfalls**:\n  - Misleading in **class imbalance** (e.g., rare POS tags).\n  - **Better metrics**: Precision, Recall, F1-score, or **weighted accuracy**.\n- **Key Idea**:\n  - Accuracy treats all classes equally, ignoring **class distribution** (Q2).\n\n#### **B. Part-of-Speech (POS) Tagging**\n- **Stochastic POS Tagging**:\n  - Combines:\n    1. **Individual word probabilities** (lexical likelihood, e.g., P(tag|word)).\n    2. **Tag sequence probabilities** (transition probabilities, e.g., P(tag_i|tag_{i-1})).\n  - **Purpose**: Resolve ambiguity (e.g., \"run\" as verb vs. noun) (Q3).\n- **Algorithms**:\n  - **Hidden Markov Models (HMMs)**, **Viterbi algorithm**, **CRF (Conditional Random Fields)**.\n\n#### **C. Retrieval-Augmented Generation (RAG)**\n- **Difference from Parametric Models (e.g., GPT-3)**:\n  - **Dynamic retrieval**: Fetches external documents at inference time (Q4).\n  - **Reduces hallucination** by grounding responses in retrieved knowledge.\n- **Generator Architecture**:\n  - Typically **BART** (Bidirectional and AutoRegressive Transformer) (Q5).\n- **Pipeline Components** (Q17):\n  1. **Retriever**: Dense (e.g., **DPR**) or sparse (e.g., **BM25**).\n  2. **Ranker**: BERT-based encoder to re-rank documents.\n  3. **Generator**: Transformer (e.g., BART) to synthesize responses.\n\n#### **D. Model Optimization for Low-Resource Scenarios**\n- **Few-Shot Prompting**:\n  - Efficient for **limited labeled data** (e.g., programming tasks) (Q6).\n  - Leverages pre-trained LLMs (e.g., GPT-3) with **in-context examples**.\n- **Alternatives**:\n  - **Instruction tuning** (fine-tuning on task-specific prompts).\n  - **LoRA/QLoRA**: Low-rank adaptation for parameter-efficient fine-tuning (Q14).\n\n#### **E. Transformer Architectures**\n- **Attention Flow** (Q7):\n  - **Multi-layer attention**: Combines attention scores across layers to measure **token influence**.\n  - **Not normalized** to sum to 1 (unlike softmax over a single layer).\n- **BERT vs. GPT vs. Standard Transformers** (Q13):\n  | Model       | Training Objective       | Directionality       | Use Case                     |\n  |-------------|--------------------------|----------------------|------------------------------|\n  | **BERT**    | Masked Language Modeling (MLM) | Bidirectional        | Sentence embeddings, QA      |\n  | **GPT**     | Causal Language Modeling (CLM) | Autoregressive (left-to-right) | Text generation              |\n  | **Standard**| Varies (e.g., encoder-decoder) | Depends on task      | Machine translation, summarization |\n\n#### **F. Ethical Concerns in NLP**\n- **Bias & Fairness** (Q8, Q18, Q19):\n  - **Unintended bias**: Stereotypical associations (e.g., \"doctor\" \u2192 \"he\").\n  - **Bias amplification**: Reinforcement learning from biased feedback (Q19).\n  - **Mitigation**: Debiasing embeddings, balanced datasets, fairness-aware training.\n- **Pragmatic Ambiguity** (Q12):\n  - **Sarcasm/irony detection**: Contextual cues (e.g., \"Wow, another Monday!\").\n\n#### **G. Sequence Modeling**\n- **LSTM vs. RNN** (Q9):\n  - **LSTM**: Uses **gates** (input, forget, output) to control information flow.\n  - **RNN**: Suffers from **vanishing gradients**; LSTM mitigates this.\n- **Teacher vs. Student Forcing** (Q15):\n  | Method           | Training Input          | Use Case               |\n  |------------------|-------------------------|------------------------|\n  | **Teacher Forcing** | Ground-truth previous token | Faster convergence     |\n  | **Student Forcing** | Model\u2019s own prediction  | Robustness to errors   |\n\n#### **H. Decoding Strategies**\n- **Beam Search** (Q16, Q23):\n  - **Beam width (B)**: Number of sequences retained at each step.\n  - **Trade-off**: Higher B \u2192 better quality but higher cost.\n  - **Not guaranteed** to find the global optimum (unlike exhaustive search).\n- **Speculative Decoding** (Q10):\n  - **Draft model** proposes tokens; **main model** verifies.\n  - **Acceptance rule**: Token accepted if P_main \u2265 P_draft (or threshold).\n- **Temperature Scaling** (Q20):\n  - **Low temperature (t \u2192 0)**: Sharpens probabilities (favors high-prob tokens).\n  - **High temperature (t \u2192 \u221e)**: Flattens distribution (more randomness).\n\n#### **I. Parsing & Syntax**\n- **Transition-Based Parsing** (Q21):\n  - **Operations**: SHIFT, LEFT-ARC, RIGHT-ARC.\n  - **Example**: \"I love coding\" \u2192 4 operations (SHIFT, SHIFT, LEFT-ARC, RIGHT-ARC).\n\n#### **J. Information Retrieval**\n- **TF-IDF** (Q22):\n  - **Term Frequency (TF)**: log(1 + count_of_term_in_doc).\n  - **Inverse Document Frequency (IDF)**: log(total_docs / docs_with_term).\n  - **Formula**:\n    \\[\n    \\text{TF-IDF}(t, d) = \\text{TF}(t, d) \\times \\text{IDF}(t)\n    \\]\n  - **Example**: For \"optimization\" (Q22):\n    \\[\n    \\text{TF} = \\log_{10}(8) \\approx 0.903, \\quad \\text{IDF} = \\log_{10}(50000/750) \\approx 1.82 \\implies \\text{TF-IDF} \\approx 0.903 \\times 1.82 \\approx 0.0164\n    \\]\n\n#### **K. Explainability**\n- **Integrated Gradients** (Q25):\n  - **Purpose**: Attribute model output to input features.\n  - **Formula**: Integral of gradients from baseline to input.\n  - **Example**: For feature \"Income\" (coefficient = 1000):\n    \\[\n    \\text{Integrated Gradient} = 1000 \\times (\\text{Income} - \\text{Baseline Income}) = 1000 \\times 50 = 50000\n    \\]\n- **Shapley Values** (Q26):\n  - **Fair attribution**: Average marginal contribution across all feature orderings.\n  - **Example**: For \"Discount\" (Q26), compute across all coalitions (answer ~162.5).\n\n---\n\n---\n\n### **2. Key Equations**\n| **Concept**               | **Equation**                                                                 |\n|---------------------------|-----------------------------------------------------------------------------|\n| **TF-IDF**                | \\(\\text{TF-IDF}(t, d) = \\log(1 + \\text{count}(t, d)) \\times \\log(\\frac{N}{\\text{df}(t)})\\) |\n| **Attention Score**       | \\(\\text{Attention}(Q, K) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\\) |\n| **Beam Search Probability** | \\(P(y_1, \\dots, y_T) = \\prod_{t=1}^T P(y_t | y_{<t}, x)\\) (top-B sequences retained) |\n| **Temperature Scaling**   | \\(P_{\\text{scaled}}(x) = \\frac{\\exp(\\log P(x) / t)}{\\sum_i \\exp(\\log P(x_i) / t)}\\) |\n| **Shapley Value**         | \\(\\phi_i = \\sum_{S \\subseteq F \\setminus \\{i\\}} \\frac{|S|! (|F|-|S|-1)!}{|F|!} [v(S \\cup \\{i\\}) - v(S)]\\) |\n| **Integrated Gradients**  | \\(\\text{IG}(x) = (x - x_{\\text{baseline}}) \\times \\int_{\\alpha=0}^1 \\frac{\\partial F(x_{\\text{baseline}} + \\alpha (x - x_{\\text{baseline}}))}{\\partial x} d\\alpha\\) |\n\n---\n\n---\n\n### **3. Mermaid Knowledge Graphs**\n#### **Graph 1: Core NLP Tasks & Models**\n```mermaid\ngraph TD\n    A[NLP Tasks] --> B[Text Classification]\n    A --> C[POS Tagging]\n    A --> D[Machine Translation]\n    A --> E[Question Answering]\n    A --> F[Summarization]\n\n    B --> G[BERT]\n    B --> H[Logistic Regression]\n    C --> I[HMM]\n    C --> J[CRF]\n    D --> K[Transformer]\n    D --> L[LSTM]\n    E --> M[RAG]\n    E --> N[BART]\n    F --> O[Beam Search]\n\n    M --> P[Retriever: DPR/BM25]\n    M --> Q[Generator: BART]\n    K --> R[Attention Mechanism]\n    R --> S[Multi-Head Attention]\n    R --> T[Attention Flow]\n```\n\n#### **Graph 2: Evaluation & Ethics**\n```mermaid\ngraph TD\n    A[Evaluation Metrics] --> B[Accuracy]\n    A --> C[Precision/Recall]\n    A --> D[F1-Score]\n    B --> E[Misleading for Imbalance]\n    E --> F[Use Weighted F1]\n\n    G[Ethical Concerns] --> H[Bias]\n    G --> I[Fairness]\n    G --> J[Pragmatic Ambiguity]\n    H --> K[Stereotypical Associations]\n    H --> L[Bias Amplification]\n    L --> M[RLHF]\n    L --> N[Unbalanced Datasets]\n    J --> O[Sarcasm Detection]\n```\n\n#### **Graph 3: Decoding Strategies**\n```mermaid\ngraph TD\n    A[Decoding] --> B[Greedy Search]\n    A --> C[Beam Search]\n    A --> D[Speculative Decoding]\n    B --> E[Picks Highest Prob Token]\n    C --> F[Keeps Top-B Sequences]\n    C --> G[Not Guaranteed Optimal]\n    D --> H[Draft Model Proposes]\n    D --> I[Main Model Verifies]\n    I --> J[Accept if P_main \u2265 P_draft]\n```\n\n#### **Graph 4: Transformer Variants**\n```mermaid\ngraph LR\n    A[Transformer] --> B[Encoder-Decoder]\n    A --> C[Encoder-Only]\n    A --> D[Decoder-Only]\n    B --> E[T5]\n    C --> F[BERT]\n    D --> G[GPT-3]\n    F --> H[Masked LM]\n    G --> I[Causal LM]\n    H --> J[Bidirectional]\n    I --> K[Autoregressive]\n```\n\n#### **Graph 5: Optimization Techniques**\n```mermaid\ngraph TD\n    A[Low-Resource Scenarios] --> B[Few-Shot Prompting]\n    A --> C[Parameter-Efficient Fine-Tuning]\n    B --> D[In-Context Learning]\n    C --> E[LoRA]\n    C --> F[QLoRA]\n    E --> G[Low-Rank Matrices]\n    F --> H[Quantization]\n    F --> I[4-bit Precision]\n```\n\n---\n\n---\n### **4. Exam Tips**\n1. **Focus Areas**:\n   - **POS Tagging**: Stochastic methods (HMM/CRF), evaluation metrics.\n   - **Transformers**: Attention flow, BERT vs. GPT, RAG pipelines.\n   - **Decoding**: Beam search, temperature, speculative decoding.\n   - **Ethics**: Bias sources (data, feedback loops), mitigation strategies.\n   - **Math**: TF-IDF, Shapley values, integrated gradients.\n\n2. **Common Pitfalls**:\n   - Confusing **teacher forcing** (training) vs. **student forcing** (inference).\n   - Assuming **beam search** finds the global optimum (it doesn\u2019t).\n   - Misapplying **temperature**: Low t \u2192 more deterministic, not random.\n\n3. **Problem-Solving**:\n   - For **TF-IDF**: Always use log base 10 and check document frequency.\n   - For **Shapley values**: Enumerate all feature coalitions systematically.\n   - For **parsing**: Count operations (SHIFT for words, ARC for dependencies).",
        "total_score": "100.00"
    },
    "url": "/question-paper/practise/83/3eff3f7d-82c",
    "version": "ee3d5d44299e610bd137ea6200db5ac2"
}