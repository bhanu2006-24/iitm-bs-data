{
    "component": "Quizpractise/PractiseQuestionPaper",
    "props": {
        "errors": {},
        "auth": {
            "user": null
        },
        "flash": {
            "error": []
        },
        "banner": null,
        "file_url": "https://saram.blr1.cdn.digitaloceanspaces.com",
        "file_do_url": "https://saram.blr1.cdn.digitaloceanspaces.com",
        "question_paper": {
            "id": 248,
            "group_id": 27,
            "exam_id": 3,
            "total_score": "1.00",
            "duration": 4,
            "created_at": "2025-04-17T15:51:51.000000Z",
            "updated_at": "2025-04-17T15:51:51.000000Z",
            "question_paper_name": "IIT M DEGREE AN EXAM QDB4 13 Apr 2025",
            "question_paper_description": "2025 Apr13: IIT M AN EXAM QDB4",
            "uuid": "fb4337ae-d12",
            "year": 2025,
            "is_new": 0,
            "exam": {
                "id": 3,
                "exam_name": "End Term Quiz",
                "created_at": "2024-10-16T08:08:51.000000Z",
                "updated_at": "2024-10-16T08:08:51.000000Z",
                "uuid": "7a6ff569-f50c-40e7-a08b-f5c334392600",
                "en_id": "eyJpdiI6ImtuQTBTNWtkejJqKzZRTWRWemowVlE9PSIsInZhbHVlIjoicDU3NkRnYXREK2N3eTF4cjZlaU96Zz09IiwibWFjIjoiOGRkYzhjMWM0YmZmZDc2NjdlMDk2NTJmNjJlMjdkMTFlMWUzMzBjNmYyMGNiZTY1MWU1MDY2NzkxZmU5YmM4NiIsInRhZyI6IiJ9"
            },
            "questions": [
                {
                    "id": 77704,
                    "exam_id": 3,
                    "question_paper_id": 248,
                    "question_number": 194,
                    "question_text_1": "THIS IS QUESTION PAPER FOR THE SUBJECT <b>\"DEGREE LEVEL : INTRODUCTION TO NATURAL </b><b>LANGUAGE PROCESSING (COMPUTER BASED EXAM)\"</b><b> </b><b> </b><b>ARE YOU SURE YOU HAVE TO WRITE EXAM FOR THIS SUBJECT? </b><b>CROSS CHECK YOUR HALL TICKET TO CONFIRM THE SUBJECTS TO BE WRITTEN. </b><b> </b><b>(IF IT IS NOT THE CORRECT SUBJECT, PLS CHECK THE SECTION AT THE TOP FOR THE SUBJECTS </b><b>REGISTERED BY YOU)</b>",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "0.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:53.000000Z",
                    "updated_at": "2025-04-17T15:51:53.000000Z",
                    "question_num_long": 6406531251711,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "441b5f2b3fe4c315122422d5f0aa59ae",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "6379b7f7-e550-4069-a916-073b9a662771",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "THIS IS QUESTION PAPER FOR THE SUBJECT <b>\"DEGREE LEVEL : INTRODUCTION TO NATURAL </b><b>LANGUAGE PROCESSING (COMPUTER BASED EXAM)\"</b><b> </b><b> </b><b>ARE YOU SURE YOU HAVE TO WRITE EXAM FOR THIS SUBJECT? </b><b>CROSS CHECK YOUR HALL TICKET TO CONFIRM THE SUBJECTS TO BE WRITTEN. </b><b> </b><b>(IF IT IS NOT THE CORRECT SUBJECT, PLS CHECK THE SECTION AT THE TOP FOR THE SUBJECTS </b><b>REGISTERED BY YOU)</b>"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 208467,
                            "question_id": 77704,
                            "option_text": "YES",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534216988,
                            "option_image_url": null
                        },
                        {
                            "id": 208468,
                            "question_id": 77704,
                            "option_text": "NO",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534216989,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 77705,
                    "exam_id": 3,
                    "question_paper_id": 248,
                    "question_number": 195,
                    "question_text_1": "Why might accuracy be a misleading metric for evaluating POS tagging systems in cases of class imbalance?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:53.000000Z",
                    "updated_at": "2025-04-17T15:51:53.000000Z",
                    "question_num_long": 6406531251712,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "ad052c6f0a49f23ab6904d7f01e753a1",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "d8770316-e27c-45ca-aa56-5a71f0bab3ec",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Why might accuracy be a misleading metric for evaluating POS tagging systems in cases of class imbalance?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 208469,
                            "question_id": 77705,
                            "option_text": "Because accuracy does not account for the number of true negatives.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534216990,
                            "option_image_url": null
                        },
                        {
                            "id": 208470,
                            "question_id": 77705,
                            "option_text": "Because accuracy gives equal weight to all classes, even if some tags are muchrarer than others.",
                            "option_image": "",
                            "score": "3.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534216991,
                            "option_image_url": null
                        },
                        {
                            "id": 208471,
                            "question_id": 77705,
                            "option_text": "Because accuracy only measures the precision of the system, ignoring recall.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534216992,
                            "option_image_url": null
                        },
                        {
                            "id": 208472,
                            "question_id": 77705,
                            "option_text": "Because accuracy is not affected by the number of false positives and falsenegatives.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534216993,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 77706,
                    "exam_id": 3,
                    "question_paper_id": 248,
                    "question_number": 196,
                    "question_text_1": "In stochastic POS tagging, why is it necessary to calculate both individual word probabilities and tag sequence probabilities?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:53.000000Z",
                    "updated_at": "2025-04-17T15:51:53.000000Z",
                    "question_num_long": 6406531251713,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "6dc09850b4c80bd25ff3acb6abfdb703",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "f55defc9-544a-492b-9cdf-67d61811e680",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "In stochastic POS tagging, why is it necessary to calculate both individual word probabilities and tag sequence probabilities?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 208473,
                            "question_id": 77706,
                            "option_text": "Individual word probabilities are sufficient for accurate tagging, and tagsequence probabilities are redundant.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534216994,
                            "option_image_url": null
                        },
                        {
                            "id": 208474,
                            "question_id": 77706,
                            "option_text": "Individual word probabilities are only used for rare words, while tag sequenceprobabilities are used for common words.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534216995,
                            "option_image_url": null
                        },
                        {
                            "id": 208475,
                            "question_id": 77706,
                            "option_text": "Tag sequence probabilities help in determining the most likely sequence oftags, while individual word probabilities provide local context.",
                            "option_image": "",
                            "score": "3.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534216996,
                            "option_image_url": null
                        },
                        {
                            "id": 208476,
                            "question_id": 77706,
                            "option_text": "Both probabilities are used to reduce the computational complexity of thetagging process.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534216997,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 77707,
                    "exam_id": 3,
                    "question_paper_id": 248,
                    "question_number": 197,
                    "question_text_1": "How does Retrieval-Augmented Generation (RAG) differ from standard parametric models like GPT-3?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:53.000000Z",
                    "updated_at": "2025-04-17T15:51:53.000000Z",
                    "question_num_long": 6406531251716,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "5dd17c285a872f8d74cee3c6f73d1a4f",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "5b5a35d1-9667-4ae7-9f81-63e3c02b3cf6",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "How does Retrieval-Augmented Generation (RAG) differ from standard parametric models like GPT-3?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 208477,
                            "question_id": 77707,
                            "option_text": "RAG eliminates the need for transformer-based token generation.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217006,
                            "option_image_url": null
                        },
                        {
                            "id": 208478,
                            "question_id": 77707,
                            "option_text": "RAG uses retrieval but does not update its knowledge dynamically over time.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217007,
                            "option_image_url": null
                        },
                        {
                            "id": 208479,
                            "question_id": 77707,
                            "option_text": "RAG only works when trained on labeled question-answer datasets.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217008,
                            "option_image_url": null
                        },
                        {
                            "id": 208480,
                            "question_id": 77707,
                            "option_text": "RAG retrieves external documents dynamically, reducing reliance on pre-trained knowledge.",
                            "option_image": "",
                            "score": "3.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217009,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 77708,
                    "exam_id": 3,
                    "question_paper_id": 248,
                    "question_number": 198,
                    "question_text_1": "Which of the following architectures is most commonly used as the generator in RAG models?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:53.000000Z",
                    "updated_at": "2025-04-17T15:51:53.000000Z",
                    "question_num_long": 6406531251717,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "7dd8524be915af36c313309920ef82c9",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "62a49b86-27f3-4db1-9b0e-7d74c68ce3ed",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following architectures is most commonly used as the generator in RAG models?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 208481,
                            "question_id": 77708,
                            "option_text": "GPT-3",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217010,
                            "option_image_url": null
                        },
                        {
                            "id": 208482,
                            "question_id": 77708,
                            "option_text": "BART",
                            "option_image": "",
                            "score": "3.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217011,
                            "option_image_url": null
                        },
                        {
                            "id": 208483,
                            "question_id": 77708,
                            "option_text": "BERT",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217012,
                            "option_image_url": null
                        },
                        {
                            "id": 208484,
                            "question_id": 77708,
                            "option_text": "RoBERTa",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217013,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 77709,
                    "exam_id": 3,
                    "question_paper_id": 248,
                    "question_number": 199,
                    "question_text_1": "A company wants to optimize an LLM for programming tasks. Which approach is the most efficient if they have limited labeled data?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:53.000000Z",
                    "updated_at": "2025-04-17T15:51:53.000000Z",
                    "question_num_long": 6406531251718,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "4f92a1b1a4e8f2d25b0b64cf77f38229",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "ef9fc05a-532e-458b-bd50-b9cec792afe4",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "A company wants to optimize an LLM for programming tasks. Which approach is the most efficient if they have limited labeled data?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 208485,
                            "question_id": 77709,
                            "option_text": "Train a new model from scratch using a large programming dataset.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217014,
                            "option_image_url": null
                        },
                        {
                            "id": 208486,
                            "question_id": 77709,
                            "option_text": "Fine-tune a transformer model with instruction tuning.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217015,
                            "option_image_url": null
                        },
                        {
                            "id": 208487,
                            "question_id": 77709,
                            "option_text": "Use Few-shot prompting with an existing LLM.",
                            "option_image": "",
                            "score": "3.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217016,
                            "option_image_url": null
                        },
                        {
                            "id": 208488,
                            "question_id": 77709,
                            "option_text": "Apply a BERT-based model instead of transformers.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217017,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 77710,
                    "exam_id": 3,
                    "question_paper_id": 248,
                    "question_number": 200,
                    "question_text_1": "Which of the following statements about Attention Flow in Transformer models is TRUE?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:53.000000Z",
                    "updated_at": "2025-04-17T15:51:53.000000Z",
                    "question_num_long": 6406531251720,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "1b87b15e49c4affc001d417f1caab0f3",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "f474f8b3-6d0b-4459-892a-e74084b35d1d",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following statements about Attention Flow in Transformer models is TRUE?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 208489,
                            "question_id": 77710,
                            "option_text": "Attention flow computes the contribution of each token independently withoutconsidering other tokens.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217022,
                            "option_image_url": null
                        },
                        {
                            "id": 208490,
                            "question_id": 77710,
                            "option_text": "Attention flow assigns higher scores to tokens that appear earlier in thesequence by default.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217023,
                            "option_image_url": null
                        },
                        {
                            "id": 208491,
                            "question_id": 77710,
                            "option_text": "Attention flow combines attention scores across multiple layers to determineoverall token influence.",
                            "option_image": "",
                            "score": "3.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217024,
                            "option_image_url": null
                        },
                        {
                            "id": 208492,
                            "question_id": 77710,
                            "option_text": "Attention flow values are always normalized across all tokens in the sequenceto sum to 1.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217025,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 77711,
                    "exam_id": 3,
                    "question_paper_id": 248,
                    "question_number": 201,
                    "question_text_1": "Which of the following scenarios represents an ethical concern with LLM deployment?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:53.000000Z",
                    "updated_at": "2025-04-17T15:51:53.000000Z",
                    "question_num_long": 6406531251721,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "45df934beecb4353f6917d90ef6c63a9",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "67dc05b8-9ecd-4525-a33e-f3dca8569fda",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following scenarios represents an ethical concern with LLM deployment?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 208493,
                            "question_id": 77711,
                            "option_text": "A summarization model shortening news articles while maintaining factualaccuracy.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217026,
                            "option_image_url": null
                        },
                        {
                            "id": 208494,
                            "question_id": 77711,
                            "option_text": "A question-answering system providing different answers for differentdemographics when asked about salary negotiations.",
                            "option_image": "",
                            "score": "3.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217027,
                            "option_image_url": null
                        },
                        {
                            "id": 208495,
                            "question_id": 77711,
                            "option_text": "A chatbot refusing to generate offensive or harmful content.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217028,
                            "option_image_url": null
                        },
                        {
                            "id": 208496,
                            "question_id": 77711,
                            "option_text": "A translation model translating medical terms with higher accuracy thangeneral terms.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217029,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 77712,
                    "exam_id": 3,
                    "question_paper_id": 248,
                    "question_number": 202,
                    "question_text_1": "How does an LSTM differ from a standard RNN in terms of remembering information?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "4.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:53.000000Z",
                    "updated_at": "2025-04-17T15:51:53.000000Z",
                    "question_num_long": 6406531251714,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "3b83b8878df91d41298de7b2ed36bdeb",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "83da56be-bf1c-48d1-bb98-2c05bdd6a1ff",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "How does an LSTM differ from a standard RNN in terms of remembering information?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 208497,
                            "question_id": 77712,
                            "option_text": "It uses a larger hidden state.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534216998,
                            "option_image_url": null
                        },
                        {
                            "id": 208498,
                            "question_id": 77712,
                            "option_text": "It stores all past hidden states explicitly.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534216999,
                            "option_image_url": null
                        },
                        {
                            "id": 208499,
                            "question_id": 77712,
                            "option_text": "It introduces gates to control the flow of information.",
                            "option_image": "",
                            "score": "4.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217000,
                            "option_image_url": null
                        },
                        {
                            "id": 208500,
                            "question_id": 77712,
                            "option_text": "It completely replaces hidden states with attention mechanisms.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217001,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 77713,
                    "exam_id": 3,
                    "question_paper_id": 248,
                    "question_number": 203,
                    "question_text_1": "In the context of speculative decoding, a draft model predicts three tokens: \"a\", \"quick\", \"fox\". The main model assigns probabilities 0.8, 0.6, and 0.8 respectively.The draft model's probabilities for these words were 0.7, 0.9, and 0.9. \nWhich tokens are most likely to be accepted?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "5.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:53.000000Z",
                    "updated_at": "2025-04-17T15:51:53.000000Z",
                    "question_num_long": 6406531251715,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "48c39605ef94604c3ac594dd0ac42b61",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "7a61d1e6-590b-4d72-b9e3-2e67f53f9021",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "In the context of speculative decoding, a draft model predicts three tokens: \"a\", \"quick\", \"fox\". The main model assigns probabilities 0.8, 0.6, and 0.8 respectively.The draft model's probabilities for these words were 0.7, 0.9, and 0.9. \nWhich tokens are most likely to be accepted?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 208501,
                            "question_id": 77713,
                            "option_text": "All three tokens",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217002,
                            "option_image_url": null
                        },
                        {
                            "id": 208502,
                            "question_id": 77713,
                            "option_text": "Only \"a\" and \"fox\"",
                            "option_image": "",
                            "score": "5.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217003,
                            "option_image_url": null
                        },
                        {
                            "id": 208503,
                            "question_id": 77713,
                            "option_text": "Only \"a\"",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217004,
                            "option_image_url": null
                        },
                        {
                            "id": 208504,
                            "question_id": 77713,
                            "option_text": "None of the tokens",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217005,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 77714,
                    "exam_id": 3,
                    "question_paper_id": 248,
                    "question_number": 204,
                    "question_text_1": "Consider the following attention matrices for two layers (corresponding to tokens 1 and 2) in a transformer model: \nLayer 1 Attention Matrix: \n",
                    "question_image_1": "WjlsEqQ66kEYqvjYy87pzCtUlhEXb7D43xwqxNzwFicn6e1195.png",
                    "question_type": "MCQ",
                    "total_mark": "5.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:53.000000Z",
                    "updated_at": "2025-04-17T15:51:53.000000Z",
                    "question_num_long": 6406531251719,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "3c7b963e351016da969e4029256741f8",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": "Consider the following attention matrices for two layers (corresponding to tokens 1 and 2) in a transformer model: \nLayer 1 Attention Matrix: \n  Layer 2 Attention Matrix: \n",
                    "question_image_2": "MWVOK6OYzXmctLYRMbCnEmKw0RfXjMvuAI4GJrokqS2JqM61Eo.png",
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": "Consider the following attention matrices for two layers (corresponding to tokens 1 and 2) in a transformer model: \nLayer 1 Attention Matrix: \n  Layer 2 Attention Matrix: \n  What is the total attention from token 2 to token 1 after performing attention rollout?",
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "69673823-3129-4e05-a51c-1f1c62606104",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/WjlsEqQ66kEYqvjYy87pzCtUlhEXb7D43xwqxNzwFicn6e1195.png",
                        "/question_images/MWVOK6OYzXmctLYRMbCnEmKw0RfXjMvuAI4GJrokqS2JqM61Eo.png"
                    ],
                    "question_texts": [
                        "Consider the following attention matrices for two layers (corresponding to tokens 1 and 2) in a transformer model: \nLayer 1 Attention Matrix: \n",
                        "Consider the following attention matrices for two layers (corresponding to tokens 1 and 2) in a transformer model: \nLayer 1 Attention Matrix: \n  Layer 2 Attention Matrix: \n",
                        "Consider the following attention matrices for two layers (corresponding to tokens 1 and 2) in a transformer model: \nLayer 1 Attention Matrix: \n  Layer 2 Attention Matrix: \n  What is the total attention from token 2 to token 1 after performing attention rollout?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 208505,
                            "question_id": 77714,
                            "option_text": "0.57",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217018,
                            "option_image_url": null
                        },
                        {
                            "id": 208506,
                            "question_id": 77714,
                            "option_text": "0.33",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217019,
                            "option_image_url": null
                        },
                        {
                            "id": 208507,
                            "question_id": 77714,
                            "option_text": "0.39",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217020,
                            "option_image_url": null
                        },
                        {
                            "id": 208508,
                            "question_id": 77714,
                            "option_text": "0.26",
                            "option_image": "",
                            "score": "5.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217021,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 77715,
                    "exam_id": 3,
                    "question_paper_id": 248,
                    "question_number": 205,
                    "question_text_1": "Which of the following sentences contain pragmatic ambiguity due to potential sarcasm or irony?",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "6.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:53.000000Z",
                    "updated_at": "2025-04-17T15:51:53.000000Z",
                    "question_num_long": 6406531251722,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "81432be22a70e07403c005c196675d6f",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "d87c9026-da73-49ed-afa2-552664da7d5a",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following sentences contain pragmatic ambiguity due to potential sarcasm or irony?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 208509,
                            "question_id": 77715,
                            "option_text": "\"Wow, another Monday! Just what I needed.\"",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217030,
                            "option_image_url": null
                        },
                        {
                            "id": 208510,
                            "question_id": 77715,
                            "option_text": "\"The meeting was only three hours long. So productive!\"",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217031,
                            "option_image_url": null
                        },
                        {
                            "id": 208511,
                            "question_id": 77715,
                            "option_text": "\"I love spending hours in traffic. It\u2019s my favorite part of the day.\"",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217032,
                            "option_image_url": null
                        },
                        {
                            "id": 208512,
                            "question_id": 77715,
                            "option_text": "\"The weather is perfect for a picnic today.\"",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217033,
                            "option_image_url": null
                        },
                        {
                            "id": 208513,
                            "question_id": 77715,
                            "option_text": "\"She always arrives on time, unlike some people.\"",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217034,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 77716,
                    "exam_id": 3,
                    "question_paper_id": 248,
                    "question_number": 206,
                    "question_text_1": "Which of the following statements correctly describe how BERT differs from GPT and standard transformer models?",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "4.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:53.000000Z",
                    "updated_at": "2025-04-17T15:51:53.000000Z",
                    "question_num_long": 6406531251723,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "1804a19c9f2a81146ca20660f89e193c",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "ce627e34-e618-4d52-8762-a980e53bb019",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following statements correctly describe how BERT differs from GPT and standard transformer models?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 208514,
                            "question_id": 77716,
                            "option_text": "BERT is a bidirectional model, while GPT is autoregressive.",
                            "option_image": "",
                            "score": "1.333",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217035,
                            "option_image_url": null
                        },
                        {
                            "id": 208515,
                            "question_id": 77716,
                            "option_text": "BERT uses masked language modeling (MLM), while GPT uses causal languagemodeling (CLM).",
                            "option_image": "",
                            "score": "1.333",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217036,
                            "option_image_url": null
                        },
                        {
                            "id": 208516,
                            "question_id": 77716,
                            "option_text": "Standard transformers use encoder-only architectures, whereas BERT and GPTboth use decoder-only architectures.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217037,
                            "option_image_url": null
                        },
                        {
                            "id": 208517,
                            "question_id": 77716,
                            "option_text": "BERT is trained for sentence embeddings, while GPT is trained for next-tokenprediction.",
                            "option_image": "",
                            "score": "1.333",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217038,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 77717,
                    "exam_id": 3,
                    "question_paper_id": 248,
                    "question_number": 207,
                    "question_text_1": "Which of the following statements is/are incorrect regarding Reinforcement Learning from Human Feedback (RLHF), Supervised Instruction Fine-Tuning, LoRA, and QLoRA?",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "4.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:53.000000Z",
                    "updated_at": "2025-04-17T15:51:53.000000Z",
                    "question_num_long": 6406531251724,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "4c78183907140728d4744cbaeb0c80dd",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "233a4029-5bbf-4bfd-8656-616ad009a730",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following statements is/are incorrect regarding Reinforcement Learning from Human Feedback (RLHF), Supervised Instruction Fine-Tuning, LoRA, and QLoRA?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 208518,
                            "question_id": 77717,
                            "option_text": "RLHF helps improve model behavior by learning from human preferencerankings.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217039,
                            "option_image_url": null
                        },
                        {
                            "id": 208519,
                            "question_id": 77717,
                            "option_text": "LoRA (Low-Rank Adaptation) reduces the number of trainable parameters byusing low-rank matrices.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217040,
                            "option_image_url": null
                        },
                        {
                            "id": 208520,
                            "question_id": 77717,
                            "option_text": "Supervised Instruction Fine-Tuning involves reinforcement learning forgenerating human-like responses.",
                            "option_image": "",
                            "score": "4.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217041,
                            "option_image_url": null
                        },
                        {
                            "id": 208521,
                            "question_id": 77717,
                            "option_text": "QLoRA applies quantization to reduce memory consumption during fine-tuning.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217042,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 77718,
                    "exam_id": 3,
                    "question_paper_id": 248,
                    "question_number": 208,
                    "question_text_1": "During sequence-to-sequence model training, which of the following statements is/are correct regarding Teacher Forcing and Student Forcing?",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "4.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:53.000000Z",
                    "updated_at": "2025-04-17T15:51:53.000000Z",
                    "question_num_long": 6406531251725,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "395e8e384e18e98477ad737a66e5f566",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "91a270a6-aff4-4a56-98e4-f68a8fa3b962",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "During sequence-to-sequence model training, which of the following statements is/are correct regarding Teacher Forcing and Student Forcing?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 208522,
                            "question_id": 77718,
                            "option_text": "Teacher Forcing is used during inference, while Student Forcing is used duringtraining.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217043,
                            "option_image_url": null
                        },
                        {
                            "id": 208523,
                            "question_id": 77718,
                            "option_text": "Teacher Forcing provides the correct previous output as input during training,whereas Student Forcing generates outputs based on its own previous predictions.",
                            "option_image": "",
                            "score": "4.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217044,
                            "option_image_url": null
                        },
                        {
                            "id": 208524,
                            "question_id": 77718,
                            "option_text": "Student Forcing helps the model converge faster than Teacher Forcing.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217045,
                            "option_image_url": null
                        },
                        {
                            "id": 208525,
                            "question_id": 77718,
                            "option_text": "Teacher Forcing is mainly used in reinforcement learning settings.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217046,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 77719,
                    "exam_id": 3,
                    "question_paper_id": 248,
                    "question_number": 209,
                    "question_text_1": "Which of the following statements about beam search is/are <b>incorrect</b> ?",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "4.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:53.000000Z",
                    "updated_at": "2025-04-17T15:51:53.000000Z",
                    "question_num_long": 6406531251726,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "1ef4eee823d3dd304c4a6fcb1babdb26",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "7bf2ab40-1052-4849-87f4-d15cf1d68a4b",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following statements about beam search is/are <b>incorrect</b> ?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 208526,
                            "question_id": 77719,
                            "option_text": "Beam search balances exploration and exploitation by considering multiplesequences at each step.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217047,
                            "option_image_url": null
                        },
                        {
                            "id": 208527,
                            "question_id": 77719,
                            "option_text": "A larger beam width increases computational cost but improves searchquality.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217048,
                            "option_image_url": null
                        },
                        {
                            "id": 208528,
                            "question_id": 77719,
                            "option_text": "Greedy search is equivalent to beam search with beam size B = 1.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217049,
                            "option_image_url": null
                        },
                        {
                            "id": 208529,
                            "question_id": 77719,
                            "option_text": "Unlike greedy search, beam search guarantees finding the globally optimalsequence.",
                            "option_image": "",
                            "score": "4.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217050,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 77720,
                    "exam_id": 3,
                    "question_paper_id": 248,
                    "question_number": 210,
                    "question_text_1": "Which components are essential in a RAG pipeline?",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "4.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:53.000000Z",
                    "updated_at": "2025-04-17T15:51:53.000000Z",
                    "question_num_long": 6406531251728,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "8afd05510ed42f1d3c587304713fa323",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "5bc5a679-b4f9-4b61-89a3-0a801e7d28a4",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which components are essential in a RAG pipeline?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 208530,
                            "question_id": 77720,
                            "option_text": "retriever model (e.g., DPR) that fetches relevant documents.",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217056,
                            "option_image_url": null
                        },
                        {
                            "id": 208531,
                            "question_id": 77720,
                            "option_text": "decoder-only transformer for sequence generation.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217057,
                            "option_image_url": null
                        },
                        {
                            "id": 208532,
                            "question_id": 77720,
                            "option_text": "BM25-based sparse retrieval method as the primary retriever.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217058,
                            "option_image_url": null
                        },
                        {
                            "id": 208533,
                            "question_id": 77720,
                            "option_text": "BERT-based query encoder for document ranking.",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217059,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 77721,
                    "exam_id": 3,
                    "question_paper_id": 248,
                    "question_number": 211,
                    "question_text_1": "Which of the following are the examples of unintended bias in an NLP model?",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "4.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:53.000000Z",
                    "updated_at": "2025-04-17T15:51:53.000000Z",
                    "question_num_long": 6406531251729,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "53d05ae8bb3012f9ba36a1db46d882b4",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "d573278a-1910-4799-ac57-18b055476ada",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following are the examples of unintended bias in an NLP model?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 208534,
                            "question_id": 77721,
                            "option_text": "A sentiment analysis model rating all political tweets as \"negative\".",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217060,
                            "option_image_url": null
                        },
                        {
                            "id": 208535,
                            "question_id": 77721,
                            "option_text": "A chatbot trained specifically for medical consultations failing on legal queries.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217061,
                            "option_image_url": null
                        },
                        {
                            "id": 208536,
                            "question_id": 77721,
                            "option_text": "A text summarization model producing longer summaries for academicpapers.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217062,
                            "option_image_url": null
                        },
                        {
                            "id": 208537,
                            "question_id": 77721,
                            "option_text": "A machine translation system translating \"doctor\" to \"he\" and \"nurse\" to \"she\"in a gender-neutral language.",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217063,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 77722,
                    "exam_id": 3,
                    "question_paper_id": 248,
                    "question_number": 212,
                    "question_text_1": "Which of the following factors contribute to bias amplification in NLP models?",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "4.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:53.000000Z",
                    "updated_at": "2025-04-17T15:51:53.000000Z",
                    "question_num_long": 6406531251730,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "2d328b2559d82a0d69e8c2e973f55398",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "8cbae687-1cae-4d7c-abcf-a57e7433a78e",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following factors contribute to bias amplification in NLP models?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 208538,
                            "question_id": 77722,
                            "option_text": "Reinforcement learning from biased human feedback.",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217064,
                            "option_image_url": null
                        },
                        {
                            "id": 208539,
                            "question_id": 77722,
                            "option_text": "Training on unbalanced datasets where stereotypes exist.",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217065,
                            "option_image_url": null
                        },
                        {
                            "id": 208540,
                            "question_id": 77722,
                            "option_text": "Applying debiasing techniques such as zeroing out gender-related wordembeddings.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217066,
                            "option_image_url": null
                        },
                        {
                            "id": 208541,
                            "question_id": 77722,
                            "option_text": "Using a larger model size to improve performance.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217067,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 77723,
                    "exam_id": 3,
                    "question_paper_id": 248,
                    "question_number": 213,
                    "question_text_1": null,
                    "question_image_1": "DJzK0AnwH6YzNX4INGhT46coWuOHq9EcQ2uS12nquSU0ySR29w.png",
                    "question_type": "MSQ",
                    "total_mark": "5.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:53.000000Z",
                    "updated_at": "2025-04-17T15:51:53.000000Z",
                    "question_num_long": 6406531251727,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "b6e5d679c96b7bf65d0cf4d054a43fb2",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "1215b2c6-30ed-4d92-b7d9-2d5b902894e7",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/DJzK0AnwH6YzNX4INGhT46coWuOHq9EcQ2uS12nquSU0ySR29w.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [
                        {
                            "id": 208542,
                            "question_id": 77723,
                            "option_text": "The probability of \"apple\" increases further.",
                            "option_image": "",
                            "score": "5.000",
                            "is_correct": 1,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217051,
                            "option_image_url": null
                        },
                        {
                            "id": 208543,
                            "question_id": 77723,
                            "option_text": "The probabilities of \"banana\" and \"cherry\" become closer to \"apple\".",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217052,
                            "option_image_url": null
                        },
                        {
                            "id": 208544,
                            "question_id": 77723,
                            "option_text": "The probabilities remain unchanged.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217053,
                            "option_image_url": null
                        },
                        {
                            "id": 208545,
                            "question_id": 77723,
                            "option_text": "The model always picks \"banana\".",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217054,
                            "option_image_url": null
                        },
                        {
                            "id": 208546,
                            "question_id": 77723,
                            "option_text": "The model always picks \"cherry\".",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-04-17T15:51:53.000000Z",
                            "updated_at": "2025-04-17T15:51:53.000000Z",
                            "option_number": 6406534217055,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 77724,
                    "exam_id": 3,
                    "question_paper_id": 248,
                    "question_number": 214,
                    "question_text_1": "In a transition-based parser using SHIFT, LEFTARC, and RIGHTARC operations, what is the minimum number of operations needed to parse the sentence \"I love coding\" (excluding the ROOT node)?",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "4",
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:53.000000Z",
                    "updated_at": "2025-04-17T15:51:53.000000Z",
                    "question_num_long": 6406531251731,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "c42e061fa196673e2b7926a38fb481f8",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "9f27e999-d338-4bc4-9e81-1a926966a4fa",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "In a transition-based parser using SHIFT, LEFTARC, and RIGHTARC operations, what is the minimum number of operations needed to parse the sentence \"I love coding\" (excluding the ROOT node)?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 77725,
                    "exam_id": 3,
                    "question_paper_id": 248,
                    "question_number": 215,
                    "question_text_1": "A TF-IDF model is applied to a document corpus of 50,000 documents. The term \"optimization\" appears in 750 documents. In a specific document, \"optimization\" appears 8 times, and the total number of words in that document is 1200. Using log base 10 ( log10), compute the TF-IDF score for \"optimization\" in this document. Enter your answer correct to three decimal places.",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "0.01",
                    "value_end": "0.02",
                    "created_at": "2025-04-17T15:51:53.000000Z",
                    "updated_at": "2025-04-17T15:51:53.000000Z",
                    "question_num_long": 6406531251732,
                    "answer_type": "Range",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "543739031a2e749bac83729c604cbb2b",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "8584043a-a9e9-4cac-821c-31f10e3d443f",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "A TF-IDF model is applied to a document corpus of 50,000 documents. The term \"optimization\" appears in 750 documents. In a specific document, \"optimization\" appears 8 times, and the total number of words in that document is 1200. Using log base 10 ( log10), compute the TF-IDF score for \"optimization\" in this document. Enter your answer correct to three decimal places."
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 77726,
                    "exam_id": 3,
                    "question_paper_id": 248,
                    "question_number": 216,
                    "question_text_1": "A beam search with beam width = 4 and vocabulary size = 8 is run for 3 decoding steps. How many sequences will remain at the end of 3 steps after pruning?",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "4",
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:53.000000Z",
                    "updated_at": "2025-04-17T15:51:53.000000Z",
                    "question_num_long": 6406531251733,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "c42e061fa196673e2b7926a38fb481f8",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "65fba471-2ebf-4c3f-996f-1333d3999361",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "A beam search with beam width = 4 and vocabulary size = 8 is run for 3 decoding steps. How many sequences will remain at the end of 3 steps after pruning?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 77727,
                    "exam_id": 3,
                    "question_paper_id": 248,
                    "question_number": 217,
                    "question_text_1": "A transformer-based Retrieval-Augmented Generation (RAG) system retrieves the top-10 most relevant passages, where each passage contains 512 tokens. However, a portion of the model's 4096-token context length is reserved for the input query and special tokens (e.g., separators, instructions). If the model reserves 1024 tokens for the input query, how many full retrieved passages can fit within the remaining context window?",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "6",
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:53.000000Z",
                    "updated_at": "2025-04-17T15:51:53.000000Z",
                    "question_num_long": 6406531251734,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "5cf4d6da8aaac9aba83ab6069f95efad",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "a0732834-9c96-4173-b505-76a1170c11de",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "A transformer-based Retrieval-Augmented Generation (RAG) system retrieves the top-10 most relevant passages, where each passage contains 512 tokens. However, a portion of the model's 4096-token context length is reserved for the input query and special tokens (e.g., separators, instructions). If the model reserves 1024 tokens for the input query, how many full retrieved passages can fit within the remaining context window?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 77728,
                    "exam_id": 3,
                    "question_paper_id": 248,
                    "question_number": 218,
                    "question_text_1": "Consider the following regression model: \nF(x) = 500 * Age + 1000 * Income + 20000 \nFor an input with: \nAge = 30 Income = 50 \n<b>Baseline Input:</b>\n\nAge = 0 Income = 0 \nWhat is the Integrated Gradient for the feature Income?",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "50000",
                    "value_end": null,
                    "created_at": "2025-04-17T15:51:53.000000Z",
                    "updated_at": "2025-04-17T15:51:53.000000Z",
                    "question_num_long": 6406531251735,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "95e0cd9df1bce0bb68829f80b2cc96aa",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "ee61660c-47e6-48fb-8a7a-00eca62b6195",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Consider the following regression model: \nF(x) = 500 * Age + 1000 * Income + 20000 \nFor an input with: \nAge = 30 Income = 50 \n<b>Baseline Input:</b>\n\nAge = 0 Income = 0 \nWhat is the Integrated Gradient for the feature Income?"
                    ],
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 77729,
                    "exam_id": 3,
                    "question_paper_id": 248,
                    "question_number": 219,
                    "question_text_1": null,
                    "question_image_1": "lmGHAOOdYKi8q64W1ncTbJ3aLDh4gbgwqb84EZ4zkz4mPSh1Ln.png",
                    "question_type": "SA",
                    "total_mark": "6.00",
                    "value_start": "162",
                    "value_end": "163",
                    "created_at": "2025-04-17T15:51:53.000000Z",
                    "updated_at": "2025-04-17T15:51:53.000000Z",
                    "question_num_long": 6406531251736,
                    "answer_type": "Range",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "07269589e9325fb496ab6b21170e0819",
                    "course_id": 83,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "d1840a92-9ce2-4ab7-a316-f47c9f64e442",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/lmGHAOOdYKi8q64W1ncTbJ3aLDh4gbgwqb84EZ4zkz4mPSh1Ln.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 83,
                        "course_name": "i-NLP",
                        "course_code": "i-NLP",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5bc514b1-5ed2-43b8-8c16-2d219ee3bb02"
                    },
                    "options": [],
                    "parent_question": null
                }
            ]
        },
        "summary": "Here\u2019s a structured **summary of core topics, concepts, principles, and equations** for the **Introduction to Natural Language Processing (NLP) exam**, along with **Mermaid knowledge graphs** to visualize relationships.\n\n---\n\n---\n\n### **1. Core Topics & Concepts**\n#### **A. Part-of-Speech (POS) Tagging**\n- **Key Concepts**:\n  - **Class Imbalance**: Accuracy is misleading when some tags are rare (e.g., \"DT\" vs. \"NN\"). Use **precision/recall/F1-score** per class instead.\n  - **Stochastic POS Tagging**:\n    - **Individual Word Probabilities**: \\( P(\\text{tag}|\\text{word}) \\) (lexical probability).\n    - **Tag Sequence Probabilities**: \\( P(\\text{tag}_i|\\text{tag}_{i-1}) \\) (transition probability, e.g., HMMs, CRFs).\n    - **Combined Objective**: Maximize \\( P(\\text{tags}|\\text{words}) \\propto P(\\text{words}|\\text{tags}) \\cdot P(\\text{tags}) \\).\n\n- **Equations**:\n  - **Viterbi Algorithm** (for HMMs):\n    \\[\n    v_t(k) = \\max_{1 \\leq s \\leq N} v_{t-1}(s) \\cdot a_{s,k} \\cdot b_k(o_t)\n    \\]\n    where \\( a_{s,k} \\) = transition probability, \\( b_k(o_t) \\) = emission probability.\n\n---\n\n#### **B. Transformer Models & Attention**\n- **Key Concepts**:\n  - **Self-Attention**: Computes token relationships via **query-key-value** matrices.\n    - **Attention Score**: \\( \\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V \\).\n  - **Multi-Head Attention**: Concatenates heads to capture diverse patterns.\n  - **Attention Flow**: Aggregates attention across layers to trace token influence (e.g., **Attention Rollout**).\n  - **BERT vs. GPT**:\n    - **BERT**: Bidirectional (Masked Language Modeling, MLM).\n    - **GPT**: Autoregressive (Causal Language Modeling, CLM).\n  - **BART**: Denoising autoencoder (used in RAG for generation).\n\n- **Equations**:\n  - **Scaled Dot-Product Attention**:\n    \\[\n    \\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\n    \\]\n  - **Attention Rollout** (for token \\( j \\) to \\( i \\)):\n    \\[\n    \\text{Rollout}(i, j) = \\sum_{l=1}^{L} \\prod_{k=1}^{l} A^{(k)}_{i,j}\n    \\]\n    where \\( A^{(k)} \\) = attention matrix at layer \\( k \\).\n\n---\n\n#### **C. Language Model (LM) Decoding**\n- **Key Concepts**:\n  - **Temperature (\\( \\tau \\))**: Controls randomness in sampling.\n    - Low \\( \\tau \\): Sharpens probabilities (favors high-probability tokens).\n    - High \\( \\tau \\): Flattens probabilities (more randomness).\n  - **Speculative Decoding**: Draft model proposes tokens; main model verifies.\n    - **Acceptance Rule**: Token accepted if \\( P_{\\text{main}}(w) \\geq P_{\\text{draft}}(w) \\).\n  - **Beam Search**:\n    - Keeps top-\\( B \\) sequences at each step (beam width \\( B \\)).\n    - **Not guaranteed to find global optimum** (unlike exhaustive search).\n\n- **Equations**:\n  - **Temperature Scaling**:\n    \\[\n    P_{\\tau}(w) = \\frac{\\exp(\\log P(w) / \\tau)}{\\sum_{w'} \\exp(\\log P(w') / \\tau)}\n    \\]\n  - **Beam Search Pruning**: Retain \\( B \\) sequences with highest \\( \\log P \\).\n\n---\n\n#### **D. Retrieval-Augmented Generation (RAG)**\n- **Key Concepts**:\n  - **Pipeline**:\n    1. **Retriever**: Fetches relevant documents (e.g., DPR, BM25).\n    2. **Generator**: Conditionally generates text (e.g., BART, T5).\n  - **Advantages**: Reduces hallucination; dynamically updates knowledge.\n  - **Context Window**: Limits number of retrieved passages (e.g., 4096 tokens).\n\n- **Components**:\n  - **Dense Passage Retrieval (DPR)**: Dual-encoder (query/document).\n  - **BM25**: Sparse retrieval (TF-IDF variant).\n\n---\n\n#### **E. Bias & Ethics in NLP**\n- **Key Concepts**:\n  - **Unintended Bias**: Models reflect training data biases (e.g., gender stereotypes).\n  - **Bias Amplification**: Occurs with:\n    - Imbalanced datasets.\n    - Reinforcement Learning from Human Feedback (RLHF) if feedback is biased.\n  - **Mitigation**:\n    - Debiasing embeddings (e.g., zeroing gender directions).\n    - Balanced datasets (e.g., **WinoBias**, **StereoSet**).\n\n- **Examples**:\n  - Gender bias: \"doctor\" \u2192 \"he\", \"nurse\" \u2192 \"she\".\n  - Demographic bias: Different answers for salary negotiation queries.\n\n---\n\n#### **F. Model Training & Fine-Tuning**\n- **Key Concepts**:\n  - **Teacher Forcing**: Feeds ground truth during training (faster convergence).\n  - **Student Forcing**: Uses model\u2019s own predictions (more realistic but unstable).\n  - **Instruction Tuning**: Fine-tunes on (instruction, response) pairs.\n  - **Parameter-Efficient Fine-Tuning**:\n    - **LoRA**: Low-rank adaptation (freezes pre-trained weights, adds trainable matrices).\n    - **QLoRA**: Quantized LoRA (reduces memory usage).\n\n- **Equations**:\n  - **LoRA Update**:\n    \\[\n    W = W_0 + \\Delta W = W_0 + BA\n    \\]\n    where \\( B \\in \\mathbb{R}^{d \\times r} \\), \\( A \\in \\mathbb{R}^{r \\times k} \\), \\( r \\ll d \\).\n\n---\n\n#### **G. Evaluation Metrics**\n- **Key Concepts**:\n  - **Pragmatic Ambiguity**: Sarcasm/irony (e.g., \"Wow, another Monday!\").\n  - **Shapley Values**: Fair feature attribution in cooperative games.\n    - **Formula**:\n      \\[\n      \\phi_i = \\frac{1}{n!} \\sum_{S \\subseteq N \\setminus \\{i\\}} |S|! (n - |S| - 1)! [v(S \\cup \\{i\\}) - v(S)]\n      \\]\n  - **Integrated Gradients**: Attributes prediction to input features via path integral.\n\n- **Example (Shapley Value)**:\n  - For \"Discount\" feature in sales prediction (see Q26):\n    \\[\n    \\text{Shapley Value} = \\frac{100 + 170 + 150 + 230}{4} = 162.5\n    \\]\n\n---\n\n#### **H. Parsing & Sequence Labeling**\n- **Key Concepts**:\n  - **Transition-Based Parsing**: Uses **SHIFT**, **LEFT-ARC**, **RIGHT-ARC** operations.\n    - Example: \"I love coding\" \u2192 4 operations (SHIFT, SHIFT, SHIFT, LEFT-ARC, RIGHT-ARC).\n  - **TF-IDF**: Term importance = \\( \\text{TF} \\times \\text{IDF} \\).\n    - **TF**: \\( \\frac{\\text{count}(w)}{\\text{total words}} \\).\n    - **IDF**: \\( \\log\\left(\\frac{\\text{total docs}}{\\text{docs with } w}\\right) \\).\n\n- **Equations**:\n  - **TF-IDF**:\n    \\[\n    \\text{TF-IDF}(w, d) = \\left(\\frac{f_{w,d}}{\\sum_{w' \\in d} f_{w',d}}\\right) \\times \\log\\left(\\frac{N}{|\\{d' \\in D : w \\in d'\\}|}\\right)\n    \\]\n\n---\n\n---\n\n### **2. Mermaid Knowledge Graphs**\n#### **Graph 1: Core NLP Tasks & Models**\n```mermaid\ngraph TD\n    A[NLP] --> B[POS Tagging]\n    A --> C[Transformers]\n    A --> D[Language Models]\n    A --> E[RAG]\n    A --> F[Bias & Ethics]\n\n    B --> B1[HMMs/CRFs]\n    B --> B2[Class Imbalance]\n\n    C --> C1[Self-Attention]\n    C --> C2[BERT/GPT/BART]\n    C --> C3[Attention Flow]\n\n    D --> D1[Decoding Strategies]\n    D --> D2[Temperature]\n    D --> D3[Beam Search]\n\n    E --> E1[Retriever]\n    E --> E2[Generator]\n    E --> E3[Context Window]\n\n    F --> F1[Unintended Bias]\n    F --> F2[Debiasing]\n    F --> F3[RLHF]\n```\n\n#### **Graph 2: Transformer Attention Mechanisms**\n```mermaid\ngraph LR\n    A[Input Tokens] --> B[Embeddings]\n    B --> C[Multi-Head Attention]\n    C --> D1[Query]\n    C --> D2[Key]\n    C --> D3[Value]\n    D1 & D2 --> E[Attention Scores]\n    E --> F[Softmax]\n    F --> G[Weighted Values]\n    G --> H[Feed-Forward NN]\n    H --> I[Output]\n```\n\n#### **Graph 3: RAG Pipeline**\n```mermaid\ngraph TD\n    A[User Query] --> B[Retriever]\n    B --> C1[DPR]\n    B --> C2[BM25]\n    C1 & C2 --> D[Top-K Documents]\n    D --> E[Generator]\n    E --> F[BART/T5]\n    F --> G[Final Response]\n```\n\n#### **Graph 4: Bias in NLP**\n```mermaid\ngraph TD\n    A[Bias Sources] --> B[Training Data]\n    A --> C[Human Feedback]\n    B --> D[Stereotypes]\n    C --> E[RLHF]\n    D --> F[Model Outputs]\n    E --> F\n    F --> G[Unintended Harm]\n    G --> H[Debiasing Techniques]\n    H --> H1[Embedding Adjustment]\n    H --> H2[Balanced Datasets]\n```\n\n#### **Graph 5: Decoding Strategies**\n```mermaid\ngraph LR\n    A[Language Model] --> B[Decoding]\n    B --> C1[Greedy Search]\n    B --> C2[Beam Search]\n    B --> C3[Sampling]\n    B --> C4[Speculative Decoding]\n    C2 --> D[Beam Width]\n    C3 --> E[Temperature]\n    C4 --> F[Draft Model]\n    C4 --> G[Main Model]\n```\n\n---\n\n---\n\n### **3. Key Equations Summary**\n| **Topic**               | **Equation**                                                                                     | **Description**                                  |\n|-------------------------|-------------------------------------------------------------------------------------------------|-------------------------------------------------|\n| **POS Tagging (HMM)**   | \\( v_t(k) = \\max_{s} v_{t-1}(s) \\cdot a_{s,k} \\cdot b_k(o_t) \\)                                | Viterbi algorithm for tag sequence.             |\n| **Attention**           | \\( \\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V \\)          | Scaled dot-product attention.                   |\n| **Temperature Scaling** | \\( P_{\\tau}(w) = \\frac{\\exp(\\log P(w) / \\tau)}{\\sum_{w'} \\exp(\\log P(w') / \\tau)} \\)            | Controls randomness in sampling.               |\n| **TF-IDF**              | \\( \\text{TF-IDF}(w, d) = \\text{TF}(w, d) \\times \\log\\left(\\frac{N}{\\text{DF}(w)}\\right) \\)      | Term importance in documents.                   |\n| **Shapley Value**       | \\( \\phi_i = \\frac{1}{n!} \\sum_{S} |S|! (n-|S|-1)! [v(S \\cup \\{i\\}) - v(S)] \\)       | Fair feature attribution.                       |\n| **LoRA**                | \\( W = W_0 + BA \\)                                                                              | Low-rank adaptation for fine-tuning.            |\n| **Integrated Gradients**| \\( \\text{IG}_i(x) = (x_i - x'_i) \\times \\int_{\\alpha=0}^{1} \\frac{\\partial F(x' + \\alpha(x - x'))}{\\partial x_i} d\\alpha \\) | Feature attribution via path integral.          |\n\n---\n\n---\n\n### **4. Exam Tips**\n1. **POS Tagging**: Focus on **class imbalance** and **Viterbi/HMMs**.\n2. **Transformers**: Master **attention mechanisms**, **BERT vs. GPT**, and **attention rollout**.\n3. **Decoding**: Understand **beam search vs. greedy**, **temperature**, and **speculative decoding**.\n4. **RAG**: Know the **retriever-generator pipeline** and **context window limits**.\n5. **Bias**: Recognize **sources of bias** (data, feedback) and **mitigation techniques**.\n6. **Math-Heavy**: Practice **TF-IDF**, **Shapley values**, and **probability scaling** (temperature).\n7. **Parsing**: Learn **transition-based parsing operations** (SHIFT, LEFT-ARC, RIGHT-ARC).",
        "total_score": "100.00"
    },
    "url": "/question-paper/practise/83/fb4337ae-d12",
    "version": "ee3d5d44299e610bd137ea6200db5ac2"
}