{
    "component": "Quizpractise/PractiseQuestionPaper",
    "props": {
        "errors": {},
        "auth": {
            "user": null
        },
        "flash": {
            "error": []
        },
        "banner": null,
        "file_url": "https://saram.blr1.cdn.digitaloceanspaces.com",
        "file_do_url": "https://saram.blr1.cdn.digitaloceanspaces.com",
        "question_paper": {
            "id": 150,
            "group_id": 24,
            "exam_id": 3,
            "total_score": "1.00",
            "duration": 4,
            "created_at": "2024-11-27T22:26:26.000000Z",
            "updated_at": "2024-11-27T22:26:26.000000Z",
            "question_paper_name": "IIT M DEGREE FN EXAM QDB1 01 Sep 2024",
            "question_paper_description": "2024 Sep01: IIT M FN EXAM QDB1",
            "uuid": "181df55f-f84",
            "year": 2024,
            "is_new": 0,
            "exam": {
                "id": 3,
                "exam_name": "End Term Quiz",
                "created_at": "2024-10-16T08:08:51.000000Z",
                "updated_at": "2024-10-16T08:08:51.000000Z",
                "uuid": "7a6ff569-f50c-40e7-a08b-f5c334392600",
                "en_id": "eyJpdiI6IlI4OUFaV1l0clJKd2ZjS3R1cGJob3c9PSIsInZhbHVlIjoiV0E2MWtBZjRaNzVWVlFhSndBU1V3UT09IiwibWFjIjoiMzQyZjRlOGZlMzU0MWRkM2VkNWFmN2RhNWYyNWEwYzE0MTI5Yjg5MzY3NWI5OGMxOGIwYjQzMzc1ZTczYWQwNSIsInRhZyI6IiJ9"
            },
            "questions": [
                {
                    "id": 44411,
                    "exam_id": 3,
                    "question_paper_id": 150,
                    "question_number": 161,
                    "question_text_1": "THIS IS QUESTION PAPER FOR THE SUBJECT \"DEGREE LEVEL : REINFORCEMENT LEARNING (COMPUTER BASED EXAM)\"  ARE YOU SURE YOU HAVE TO WRITE EXAM FOR THIS SUBJECT? CROSS CHECK YOUR HALL TICKET TO CONFIRM THE SUBJECTS TO BE WRITTEN.  (IF IT IS NOT THE CORRECT SUBJECT, PLS CHECK THE SECTION AT THE TOP FOR THE SUBJECTS REGISTERED BY YOU)",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "0.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:27.000000Z",
                    "updated_at": "2024-11-27T22:26:27.000000Z",
                    "question_num_long": 640653906888,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "2f540854a25c5235529435523fe4a851",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "86015028-ffb9-4ede-ac53-5b937d6d2a90",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "THIS IS QUESTION PAPER FOR THE SUBJECT \"DEGREE LEVEL : REINFORCEMENT LEARNING (COMPUTER BASED EXAM)\"  ARE YOU SURE YOU HAVE TO WRITE EXAM FOR THIS SUBJECT? CROSS CHECK YOUR HALL TICKET TO CONFIRM THE SUBJECTS TO BE WRITTEN.  (IF IT IS NOT THE CORRECT SUBJECT, PLS CHECK THE SECTION AT THE TOP FOR THE SUBJECTS REGISTERED BY YOU)"
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 118387,
                            "question_id": 44411,
                            "option_text": "YES",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052571,
                            "option_image_url": null
                        },
                        {
                            "id": 118388,
                            "question_id": 44411,
                            "option_text": "NO",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052572,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 44412,
                    "exam_id": 3,
                    "question_paper_id": 150,
                    "question_number": 162,
                    "question_text_1": "Note: For numerical answer type questions, enter your answer correct upto two decimal places without rounding up or off unless stated otherwise.",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "0.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:27.000000Z",
                    "updated_at": "2024-11-27T22:26:27.000000Z",
                    "question_num_long": 640653906889,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "33d58123d42ddb9df862a15fb2941781",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "365c2d83-1530-4c96-9c13-49d83197b19a",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Note: For numerical answer type questions, enter your answer correct upto two decimal places without rounding up or off unless stated otherwise."
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 118389,
                            "question_id": 44412,
                            "option_text": "Instructions has been mentioned above.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052573,
                            "option_image_url": null
                        },
                        {
                            "id": 118390,
                            "question_id": 44412,
                            "option_text": "This Instructions is just for a reference & not for an evaluation.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052574,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 44413,
                    "exam_id": 3,
                    "question_paper_id": 150,
                    "question_number": 163,
                    "question_text_1": "Consider the following assertion reason pair: Assertion: Reinforcement learning is a type of unsupervised learning algorithm as both don\u2019t have correct labels. Reason: In unsupervised learning, a reward like quantity is not maximized.",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:27.000000Z",
                    "updated_at": "2024-11-27T22:26:27.000000Z",
                    "question_num_long": 640653906890,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "2b2928644032714ad087fb1a23c375ef",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "8bb5c99f-f03e-4adb-a81c-72e34552a277",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Consider the following assertion reason pair: Assertion: Reinforcement learning is a type of unsupervised learning algorithm as both don\u2019t have correct labels. Reason: In unsupervised learning, a reward like quantity is not maximized."
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 118391,
                            "question_id": 44413,
                            "option_text": "Assertion and Reason are both true and Reason is a correct explanation ofAssertion.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052575,
                            "option_image_url": null
                        },
                        {
                            "id": 118392,
                            "question_id": 44413,
                            "option_text": "Assertion and Reason are both true and Reason is not a correct explanation ofAssertion.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052576,
                            "option_image_url": null
                        },
                        {
                            "id": 118393,
                            "question_id": 44413,
                            "option_text": "Assertion is true but Reason is false.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052577,
                            "option_image_url": null
                        },
                        {
                            "id": 118394,
                            "question_id": 44413,
                            "option_text": "Assertion is false but Reason is true.",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052578,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 44414,
                    "exam_id": 3,
                    "question_paper_id": 150,
                    "question_number": 164,
                    "question_text_1": null,
                    "question_image_1": "UfqkWY4S5lrEyRB2PLbCX9yPHsX3xCjpbG5Cgzptt6YRP29icq.png",
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:27.000000Z",
                    "updated_at": "2024-11-27T22:26:27.000000Z",
                    "question_num_long": 640653906891,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "8cc2f47d28c4a4aa4d6c83449b894e33",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "cb7df741-10c9-4921-a1dd-ac8e2bb48da0",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/UfqkWY4S5lrEyRB2PLbCX9yPHsX3xCjpbG5Cgzptt6YRP29icq.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 118395,
                            "question_id": 44414,
                            "option_text": "",
                            "option_image": "3Wjn46VNynhc4NwoFyvWt0XhdyBkGnwhyjS9CxTjDsXjj21MNO.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052579,
                            "option_image_url": "app/option_images/3Wjn46VNynhc4NwoFyvWt0XhdyBkGnwhyjS9CxTjDsXjj21MNO.png"
                        },
                        {
                            "id": 118396,
                            "question_id": 44414,
                            "option_text": "",
                            "option_image": "hOaoZGY3nFPavMN6aBTPPl66GkUmsne3n2BEEt6RxfCZriKw2c.png",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052580,
                            "option_image_url": "app/option_images/hOaoZGY3nFPavMN6aBTPPl66GkUmsne3n2BEEt6RxfCZriKw2c.png"
                        },
                        {
                            "id": 118397,
                            "question_id": 44414,
                            "option_text": "",
                            "option_image": "C76HUt90DuO3rSGHPwKTDNRAzlUJg0yzQ6ZGbwQKbVFF2xpAk4.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052581,
                            "option_image_url": "app/option_images/C76HUt90DuO3rSGHPwKTDNRAzlUJg0yzQ6ZGbwQKbVFF2xpAk4.png"
                        },
                        {
                            "id": 118398,
                            "question_id": 44414,
                            "option_text": "",
                            "option_image": "V1SEJeBp4eCqYlrirB1xFaPwlHst6DtnI9NoaszrAngP1Z0TXI.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052582,
                            "option_image_url": "app/option_images/V1SEJeBp4eCqYlrirB1xFaPwlHst6DtnI9NoaszrAngP1Z0TXI.png"
                        },
                        {
                            "id": 118399,
                            "question_id": 44414,
                            "option_text": "",
                            "option_image": "Ka5CutkpPfu8AZTCMzweMwzprS0MulctGlR6QJIL2a3LGrqexA.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052583,
                            "option_image_url": "app/option_images/Ka5CutkpPfu8AZTCMzweMwzprS0MulctGlR6QJIL2a3LGrqexA.png"
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 44415,
                    "exam_id": 3,
                    "question_paper_id": 150,
                    "question_number": 165,
                    "question_text_1": "Consider a reinforcement learning agent navigating a grid world environment. The agent receives rewards of +1 for reaching the goal state and 0 otherwise. Which of the following statements accurately describes the differences between Monte Carlo and TD learning in this scenario?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:27.000000Z",
                    "updated_at": "2024-11-27T22:26:27.000000Z",
                    "question_num_long": 640653906894,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "465422571851ae4998a8aa8e466c76ce",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "9b5f3d76-3ea6-4a17-a60c-405e58f3e587",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Consider a reinforcement learning agent navigating a grid world environment. The agent receives rewards of +1 for reaching the goal state and 0 otherwise. Which of the following statements accurately describes the differences between Monte Carlo and TD learning in this scenario?"
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 118400,
                            "question_id": 44415,
                            "option_text": "Monte Carlo updates are unbiased estimators of the true value function, whileTD updates may introduce bias.",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052593,
                            "option_image_url": null
                        },
                        {
                            "id": 118401,
                            "question_id": 44415,
                            "option_text": "TD updates are guaranteed to converge to the optimal value function, whileMonte Carlo updates may not converge.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052594,
                            "option_image_url": null
                        },
                        {
                            "id": 118402,
                            "question_id": 44415,
                            "option_text": "Monte Carlo updates require less memory and computational resourcescompared to TD updates.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052595,
                            "option_image_url": null
                        },
                        {
                            "id": 118403,
                            "question_id": 44415,
                            "option_text": "TD updates are more robust to noise and stochasticity in the environmentcompared to Monte Carlo updates.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052596,
                            "option_image_url": null
                        },
                        {
                            "id": 118404,
                            "question_id": 44415,
                            "option_text": "None of these",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052597,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 44416,
                    "exam_id": 3,
                    "question_paper_id": 150,
                    "question_number": 166,
                    "question_text_1": "Consider a reinforcement learning agent learning to navigate a grid world environment. The agent receives rewards of +1 for reaching the goal state and 0 otherwise. Which of the following statements accurately describes a difference between SARSA and Q-learning in this scenario?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:27.000000Z",
                    "updated_at": "2024-11-27T22:26:27.000000Z",
                    "question_num_long": 640653906895,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "13c052c4d0b408896b2edd0e8c8ce0a0",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "a5d45435-036d-42dc-a30b-d7c0e1491d73",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Consider a reinforcement learning agent learning to navigate a grid world environment. The agent receives rewards of +1 for reaching the goal state and 0 otherwise. Which of the following statements accurately describes a difference between SARSA and Q-learning in this scenario?"
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 118405,
                            "question_id": 44416,
                            "option_text": "SARSA updates its action-value function based on the action actually taken inthe next state, while Q-learning updates its action-value function based on the maximum action-value in the next state.",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052598,
                            "option_image_url": null
                        },
                        {
                            "id": 118406,
                            "question_id": 44416,
                            "option_text": "SARSA is guaranteed to converge to the optimal policy under certainconditions, while Q-learning may diverge or oscillate without additional modifications.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052599,
                            "option_image_url": null
                        },
                        {
                            "id": 118407,
                            "question_id": 44416,
                            "option_text": "SARSA is more computationally efficient than Q-learning, requiring fewerupdates to converge to the optimal policy.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052600,
                            "option_image_url": null
                        },
                        {
                            "id": 118408,
                            "question_id": 44416,
                            "option_text": "SARSA and Q-learning exhibit similar performance in terms of convergencespeed and solution quality in this scenario.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052601,
                            "option_image_url": null
                        },
                        {
                            "id": 118409,
                            "question_id": 44416,
                            "option_text": "None of these",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052602,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 44417,
                    "exam_id": 3,
                    "question_paper_id": 150,
                    "question_number": 167,
                    "question_text_1": "In Q-learning, how does maximization bias affect the performance of the algorithm in complex environments?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:27.000000Z",
                    "updated_at": "2024-11-27T22:26:27.000000Z",
                    "question_num_long": 640653906897,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "28146c775a7dd539399a8276a1fa6ba7",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "e88d9ddf-2bbd-4c81-9fb4-b5a40bcb946a",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "In Q-learning, how does maximization bias affect the performance of the algorithm in complex environments?"
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 118410,
                            "question_id": 44417,
                            "option_text": "Maximization bias can lead to overestimation of action values, resulting insuboptimal policies and slower convergence to the optimal policy.",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052604,
                            "option_image_url": null
                        },
                        {
                            "id": 118411,
                            "question_id": 44417,
                            "option_text": "Maximization bias helps to accelerate learning by prioritizing actions withhigher estimated values, leading to faster convergence to the optimal policy.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052605,
                            "option_image_url": null
                        },
                        {
                            "id": 118412,
                            "question_id": 44417,
                            "option_text": "Maximization bias reduces the exploration-exploitation trade-off, resulting inmore exploratory behavior and improved generalization to unseen states.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052606,
                            "option_image_url": null
                        },
                        {
                            "id": 118413,
                            "question_id": 44417,
                            "option_text": "Maximization bias has minimal impact on the performance of Q-learning incomplex environments, as it tends to balance out over time through exploration.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052607,
                            "option_image_url": null
                        },
                        {
                            "id": 118414,
                            "question_id": 44417,
                            "option_text": "None of these",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052608,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 44418,
                    "exam_id": 3,
                    "question_paper_id": 150,
                    "question_number": 168,
                    "question_text_1": null,
                    "question_image_1": "d3oFJsu7lMShGlmCQyeSqBWrlisJoLEGhUBpVuZPmJYTGFmmMg.png",
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:27.000000Z",
                    "updated_at": "2024-11-27T22:26:27.000000Z",
                    "question_num_long": 640653906899,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "cbb14c35e21bdc0402787029f803dd6f",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "7cab90c0-b834-4461-9fe5-9ce4cf15e1b8",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/d3oFJsu7lMShGlmCQyeSqBWrlisJoLEGhUBpVuZPmJYTGFmmMg.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 118415,
                            "question_id": 44418,
                            "option_text": "",
                            "option_image": "pkbwcOMG7mhYBFoJvBcDn0wCbvXXgLuz2sHtWdpsDa5Pa8QOym.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052610,
                            "option_image_url": "app/option_images/pkbwcOMG7mhYBFoJvBcDn0wCbvXXgLuz2sHtWdpsDa5Pa8QOym.png"
                        },
                        {
                            "id": 118416,
                            "question_id": 44418,
                            "option_text": "",
                            "option_image": "C3pl3q7FtWVZxUVwxPx6ysNUPMY2gUQfEeTwgZuFmqGRbCR9p4.png",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052611,
                            "option_image_url": "app/option_images/C3pl3q7FtWVZxUVwxPx6ysNUPMY2gUQfEeTwgZuFmqGRbCR9p4.png"
                        },
                        {
                            "id": 118417,
                            "question_id": 44418,
                            "option_text": "",
                            "option_image": "IGCm1E9oqnoj6FkUSObub6jAI4w6qa0aPfPg7yUGk3fp0axfvr.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052612,
                            "option_image_url": "app/option_images/IGCm1E9oqnoj6FkUSObub6jAI4w6qa0aPfPg7yUGk3fp0axfvr.png"
                        },
                        {
                            "id": 118418,
                            "question_id": 44418,
                            "option_text": "",
                            "option_image": "BXc5S3mXxvNNPH6d9qLg6Q4S3owykMtNErHBpa90Fp3qe0BscP.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052613,
                            "option_image_url": "app/option_images/BXc5S3mXxvNNPH6d9qLg6Q4S3owykMtNErHBpa90Fp3qe0BscP.png"
                        },
                        {
                            "id": 118419,
                            "question_id": 44418,
                            "option_text": "",
                            "option_image": "qR0vxEGfK5ZpyA6skV8xipTaF5za10xksDlbB6JyY5lLG2kY7h.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052614,
                            "option_image_url": "app/option_images/qR0vxEGfK5ZpyA6skV8xipTaF5za10xksDlbB6JyY5lLG2kY7h.png"
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 44419,
                    "exam_id": 3,
                    "question_paper_id": 150,
                    "question_number": 169,
                    "question_text_1": "How is the Q-value Q(s, a) computed in the dueling architecture?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:27.000000Z",
                    "updated_at": "2024-11-27T22:26:27.000000Z",
                    "question_num_long": 640653906901,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "2567d042908f92f28994bb69e60bfeea",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "b5e1897e-69c0-4e85-a9fc-97292099f452",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "How is the Q-value Q(s, a) computed in the dueling architecture?"
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 118420,
                            "question_id": 44419,
                            "option_text": "",
                            "option_image": "1Ke83kJ3sxMxZlzrUlZqj0FhSuKsvIZ1h62KmjZyilZ3iBZxY2.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052616,
                            "option_image_url": "app/option_images/1Ke83kJ3sxMxZlzrUlZqj0FhSuKsvIZ1h62KmjZyilZ3iBZxY2.png"
                        },
                        {
                            "id": 118421,
                            "question_id": 44419,
                            "option_text": "",
                            "option_image": "806WKPsdHVrym0OoVM7Qw7BePxvVMeJNdvRwmG3sPwYsE8sIxo.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052617,
                            "option_image_url": "app/option_images/806WKPsdHVrym0OoVM7Qw7BePxvVMeJNdvRwmG3sPwYsE8sIxo.png"
                        },
                        {
                            "id": 118422,
                            "question_id": 44419,
                            "option_text": "",
                            "option_image": "LRh51ItQCqADBECtrt5phN8AS3UO09FlwoleiVJyuB4Hvx6DWR.png",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052618,
                            "option_image_url": "app/option_images/LRh51ItQCqADBECtrt5phN8AS3UO09FlwoleiVJyuB4Hvx6DWR.png"
                        },
                        {
                            "id": 118423,
                            "question_id": 44419,
                            "option_text": "",
                            "option_image": "ERt3kCHAxU4K3t8BPM7koj3aYhMPP5vKyXyAUkEcfy0AWKZ83r.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052619,
                            "option_image_url": "app/option_images/ERt3kCHAxU4K3t8BPM7koj3aYhMPP5vKyXyAUkEcfy0AWKZ83r.png"
                        },
                        {
                            "id": 118424,
                            "question_id": 44419,
                            "option_text": "",
                            "option_image": "tUlZHXDBoAkVyLwCZHguK9w06bbB4fIgAnHpQVsIacS7cQ9HvP.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052620,
                            "option_image_url": "app/option_images/tUlZHXDBoAkVyLwCZHguK9w06bbB4fIgAnHpQVsIacS7cQ9HvP.png"
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 44420,
                    "exam_id": 3,
                    "question_paper_id": 150,
                    "question_number": 170,
                    "question_text_1": "What problem does the dueling architecture aim to address that is commonly faced by standard DQN?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:27.000000Z",
                    "updated_at": "2024-11-27T22:26:27.000000Z",
                    "question_num_long": 640653906902,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "7da4eb3f1778adc88d6be9bc9b2481d8",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "6057ebd9-e7b5-4dab-aece-b7ae88ed5da7",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "What problem does the dueling architecture aim to address that is commonly faced by standard DQN?"
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 118425,
                            "question_id": 44420,
                            "option_text": "The inability to handle large action spaces",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052621,
                            "option_image_url": null
                        },
                        {
                            "id": 118426,
                            "question_id": 44420,
                            "option_text": "The difficulty of learning value functions when rewards are sparse",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052622,
                            "option_image_url": null
                        },
                        {
                            "id": 118427,
                            "question_id": 44420,
                            "option_text": "The slow convergence rate of policy optimization",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052623,
                            "option_image_url": null
                        },
                        {
                            "id": 118428,
                            "question_id": 44420,
                            "option_text": "The inefficiency in estimating Q-values for actions that have little impact onthe overall state value",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052624,
                            "option_image_url": null
                        },
                        {
                            "id": 118429,
                            "question_id": 44420,
                            "option_text": "None of these",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052625,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 44421,
                    "exam_id": 3,
                    "question_paper_id": 150,
                    "question_number": 171,
                    "question_text_1": "Which of the following statements best describes the primary difference between policy gradient methods and value function methods?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:27.000000Z",
                    "updated_at": "2024-11-27T22:26:27.000000Z",
                    "question_num_long": 640653906905,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "7187c0566ce7d47521ea83bb9efc3dda",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "5fc72358-47ef-40b3-a806-253192ba9456",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following statements best describes the primary difference between policy gradient methods and value function methods?"
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 118430,
                            "question_id": 44421,
                            "option_text": "Policy gradient methods directly optimize the value function, while valuefunction methods optimize the policy parameters.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052628,
                            "option_image_url": null
                        },
                        {
                            "id": 118431,
                            "question_id": 44421,
                            "option_text": "Value function methods approximate the policy by learning the value functionand deriving the policy from it, while policy gradient methods directly optimize the policy parameters by computing gradients of expected rewards.",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052629,
                            "option_image_url": null
                        },
                        {
                            "id": 118432,
                            "question_id": 44421,
                            "option_text": "Policy gradient methods approximate the value function and use it to optimizethe policy, while value function methods directly optimize the policy using gradients of the log-probability of actions.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052630,
                            "option_image_url": null
                        },
                        {
                            "id": 118433,
                            "question_id": 44421,
                            "option_text": "Value function methods directly optimize the policy parameters, while policygradient methods focus on approximating the value function.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052631,
                            "option_image_url": null
                        },
                        {
                            "id": 118434,
                            "question_id": 44421,
                            "option_text": "None of these",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052632,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 44422,
                    "exam_id": 3,
                    "question_paper_id": 150,
                    "question_number": 172,
                    "question_text_1": "What is a major challenge that Hierarchical Reinforcement Learning (HRL) aims to address?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:27.000000Z",
                    "updated_at": "2024-11-27T22:26:27.000000Z",
                    "question_num_long": 640653906907,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "bc5d83050320e61bc96957646e95281d",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "90feaeca-ed63-4027-babd-2255b419b79f",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "What is a major challenge that Hierarchical Reinforcement Learning (HRL) aims to address?"
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 118435,
                            "question_id": 44422,
                            "option_text": "Overfitting to specific environments",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052638,
                            "option_image_url": null
                        },
                        {
                            "id": 118436,
                            "question_id": 44422,
                            "option_text": "The curse of dimensionality in large state spaces",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052639,
                            "option_image_url": null
                        },
                        {
                            "id": 118437,
                            "question_id": 44422,
                            "option_text": "Lack of exploration in early stages",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052640,
                            "option_image_url": null
                        },
                        {
                            "id": 118438,
                            "question_id": 44422,
                            "option_text": "Handling non-stationary environments",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052641,
                            "option_image_url": null
                        },
                        {
                            "id": 118439,
                            "question_id": 44422,
                            "option_text": "None of these",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052642,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 44423,
                    "exam_id": 3,
                    "question_paper_id": 150,
                    "question_number": 173,
                    "question_text_1": "In HRL, what is an \u201doption\u201d typically composed of?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:27.000000Z",
                    "updated_at": "2024-11-27T22:26:27.000000Z",
                    "question_num_long": 640653906908,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "e4fbc104a7c2e4bbc7ae5020f1ff2a51",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "959ce36b-bdfa-405c-8686-dc53b94cf0c8",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "In HRL, what is an \u201doption\u201d typically composed of?"
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 118440,
                            "question_id": 44423,
                            "option_text": "A single action",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052643,
                            "option_image_url": null
                        },
                        {
                            "id": 118441,
                            "question_id": 44423,
                            "option_text": "A sequence of random actions",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052644,
                            "option_image_url": null
                        },
                        {
                            "id": 118442,
                            "question_id": 44423,
                            "option_text": "A policy, a termination condition, and an initiation set",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052645,
                            "option_image_url": null
                        },
                        {
                            "id": 118443,
                            "question_id": 44423,
                            "option_text": "A fixed sequence of primitive actions",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052646,
                            "option_image_url": null
                        },
                        {
                            "id": 118444,
                            "question_id": 44423,
                            "option_text": "None of these",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052647,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 44424,
                    "exam_id": 3,
                    "question_paper_id": 150,
                    "question_number": 174,
                    "question_text_1": "How does HRL typically improve learning efficiency?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:27.000000Z",
                    "updated_at": "2024-11-27T22:26:27.000000Z",
                    "question_num_long": 640653906909,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "60a0e8d798e44d5e9fb415a6d557f74b",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "b9830730-1c28-4dd7-9253-62cb40073dba",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "How does HRL typically improve learning efficiency?"
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 118445,
                            "question_id": 44424,
                            "option_text": "By increasing the learning rate",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052648,
                            "option_image_url": null
                        },
                        {
                            "id": 118446,
                            "question_id": 44424,
                            "option_text": "By reducing the action space",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052649,
                            "option_image_url": null
                        },
                        {
                            "id": 118447,
                            "question_id": 44424,
                            "option_text": "By decomposing a complex task into simpler subtasks",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052650,
                            "option_image_url": null
                        },
                        {
                            "id": 118448,
                            "question_id": 44424,
                            "option_text": "By using a single policy for all tasks",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052651,
                            "option_image_url": null
                        },
                        {
                            "id": 118449,
                            "question_id": 44424,
                            "option_text": "None of these",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052652,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 44425,
                    "exam_id": 3,
                    "question_paper_id": 150,
                    "question_number": 175,
                    "question_text_1": "What distinguishes Hierarchical Reinforcement Learning from traditional reinforcement learning?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:27.000000Z",
                    "updated_at": "2024-11-27T22:26:27.000000Z",
                    "question_num_long": 640653906910,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "34e5a42e646802b9b3c1ea5472e41b96",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "2a670806-8d2f-4ee0-8a17-fef596b77799",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "What distinguishes Hierarchical Reinforcement Learning from traditional reinforcement learning?"
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 118450,
                            "question_id": 44425,
                            "option_text": "The use of Q-learning instead of policy gradients",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052653,
                            "option_image_url": null
                        },
                        {
                            "id": 118451,
                            "question_id": 44425,
                            "option_text": "The explicit decomposition of tasks into a hierarchy of subtasks",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052654,
                            "option_image_url": null
                        },
                        {
                            "id": 118452,
                            "question_id": 44425,
                            "option_text": "The use of continuous action spaces",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052655,
                            "option_image_url": null
                        },
                        {
                            "id": 118453,
                            "question_id": 44425,
                            "option_text": "The ability to learn in real-time environments",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052656,
                            "option_image_url": null
                        },
                        {
                            "id": 118454,
                            "question_id": 44425,
                            "option_text": "None of these",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052657,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 44426,
                    "exam_id": 3,
                    "question_paper_id": 150,
                    "question_number": 176,
                    "question_text_1": "UCT is different from the original version of MCTS in which of the following steps?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:27.000000Z",
                    "updated_at": "2024-11-27T22:26:27.000000Z",
                    "question_num_long": 640653906911,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "b6182d36bd2354a6593a2349bc86158d",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "7cd4a55e-0195-4bc6-b7f8-7db880619942",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "UCT is different from the original version of MCTS in which of the following steps?"
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 118455,
                            "question_id": 44426,
                            "option_text": "Expansion",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052658,
                            "option_image_url": null
                        },
                        {
                            "id": 118456,
                            "question_id": 44426,
                            "option_text": "Selection",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052659,
                            "option_image_url": null
                        },
                        {
                            "id": 118457,
                            "question_id": 44426,
                            "option_text": "Backup",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052660,
                            "option_image_url": null
                        },
                        {
                            "id": 118458,
                            "question_id": 44426,
                            "option_text": "Simulation",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052661,
                            "option_image_url": null
                        },
                        {
                            "id": 118459,
                            "question_id": 44426,
                            "option_text": "None of these",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052662,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 44427,
                    "exam_id": 3,
                    "question_paper_id": 150,
                    "question_number": 177,
                    "question_text_1": null,
                    "question_image_1": "GYLadMSNIIAcema4VbPDkxln1D8zjrvY6bbx9U7mAwwLJfBJGW.png",
                    "question_type": "MSQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:27.000000Z",
                    "updated_at": "2024-11-27T22:26:27.000000Z",
                    "question_num_long": 640653906892,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "7f9e3e888c76b0441ae60116ac77be15",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "771634e1-7126-46ea-aabc-e2ff929ffdd8",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/GYLadMSNIIAcema4VbPDkxln1D8zjrvY6bbx9U7mAwwLJfBJGW.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 118460,
                            "question_id": 44427,
                            "option_text": "",
                            "option_image": "EwNw5WQshRKIk8KlgOIKyTSE4stHyfvnVROfpniopDXucRohaT.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052584,
                            "option_image_url": "app/option_images/EwNw5WQshRKIk8KlgOIKyTSE4stHyfvnVROfpniopDXucRohaT.png"
                        },
                        {
                            "id": 118461,
                            "question_id": 44427,
                            "option_text": "",
                            "option_image": "rNlkRSZC9zs3xwJWytk0wYvvCFp2so8vq6OLNOQzWjTsj98XrE.png",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052585,
                            "option_image_url": "app/option_images/rNlkRSZC9zs3xwJWytk0wYvvCFp2so8vq6OLNOQzWjTsj98XrE.png"
                        },
                        {
                            "id": 118462,
                            "question_id": 44427,
                            "option_text": "",
                            "option_image": "f1bAXS8LXHAiqDhVq4CDtqUHGOHxz2C4krRcumD7q2MG9cK6mw.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052586,
                            "option_image_url": "app/option_images/f1bAXS8LXHAiqDhVq4CDtqUHGOHxz2C4krRcumD7q2MG9cK6mw.png"
                        },
                        {
                            "id": 118463,
                            "question_id": 44427,
                            "option_text": "",
                            "option_image": "k9thECPSTwpwPkkH0ji4Hojfy0vWJF6rKnBh601nyhNU2zH5y5.png",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052587,
                            "option_image_url": "app/option_images/k9thECPSTwpwPkkH0ji4Hojfy0vWJF6rKnBh601nyhNU2zH5y5.png"
                        },
                        {
                            "id": 118464,
                            "question_id": 44427,
                            "option_text": "",
                            "option_image": "HPpBtfnylrxbzetKzd6XTxhq1uevpTtom2wiV3TMNDQamyrCbA.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052588,
                            "option_image_url": "app/option_images/HPpBtfnylrxbzetKzd6XTxhq1uevpTtom2wiV3TMNDQamyrCbA.png"
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 44428,
                    "exam_id": 3,
                    "question_paper_id": 150,
                    "question_number": 178,
                    "question_text_1": "Which of the following statements are true with regards to Monte Carlo value approximation methods?",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:27.000000Z",
                    "updated_at": "2024-11-27T22:26:27.000000Z",
                    "question_num_long": 640653906893,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "8b60d025dfdd6a6005fad5260a0ba162",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "c4316c93-867f-4d32-ba29-b9f252a338ef",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following statements are true with regards to Monte Carlo value approximation methods?"
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 118465,
                            "question_id": 44428,
                            "option_text": "To evaluate a policy using these methods, a subset of trajectories in which allstates are encountered at least once are enough to update all state-values.",
                            "option_image": "",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052589,
                            "option_image_url": null
                        },
                        {
                            "id": 118466,
                            "question_id": 44428,
                            "option_text": "Monte-Carlo value function approximation methods need knowledge of thefull model.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052590,
                            "option_image_url": null
                        },
                        {
                            "id": 118467,
                            "question_id": 44428,
                            "option_text": "Monte-Carlo methods update state-value estimates only at the end of anepisode.",
                            "option_image": "",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052591,
                            "option_image_url": null
                        },
                        {
                            "id": 118468,
                            "question_id": 44428,
                            "option_text": "None of these",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052592,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 44429,
                    "exam_id": 3,
                    "question_paper_id": 150,
                    "question_number": 179,
                    "question_text_1": "In the context of actor-critic methods, what is the effect of replacing the return Gt with the TD target?",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:27.000000Z",
                    "updated_at": "2024-11-27T22:26:27.000000Z",
                    "question_num_long": 640653906906,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "d7ff8dfeb8e25de7ebfda7e98dba2b3a",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "c3342404-7ea5-41ba-9902-7cc87b62a58e",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "In the context of actor-critic methods, what is the effect of replacing the return Gt with the TD target?"
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 118469,
                            "question_id": 44429,
                            "option_text": "It increases the variance in the estimate of the gradient of the performance.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052633,
                            "option_image_url": null
                        },
                        {
                            "id": 118470,
                            "question_id": 44429,
                            "option_text": "It decreases the variance in the estimate of the gradient of the performance.",
                            "option_image": "",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052634,
                            "option_image_url": null
                        },
                        {
                            "id": 118471,
                            "question_id": 44429,
                            "option_text": "It introduces a bias in the estimate of the gradient of the performance.",
                            "option_image": "",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052635,
                            "option_image_url": null
                        },
                        {
                            "id": 118472,
                            "question_id": 44429,
                            "option_text": "It doesn\u2019t introduce any bias in the estimate of the gradient of theperformance.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052636,
                            "option_image_url": null
                        },
                        {
                            "id": 118473,
                            "question_id": 44429,
                            "option_text": "None of these",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:27.000000Z",
                            "updated_at": "2024-11-27T22:26:27.000000Z",
                            "option_number": 6406533052637,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 44430,
                    "exam_id": 3,
                    "question_paper_id": 150,
                    "question_number": 180,
                    "question_text_1": null,
                    "question_image_1": "ucRiQbeWVXNCUhFAtIlfcnm6DWklU4JXh34kj5fOuFfYd23tqL.png",
                    "question_type": "SA",
                    "total_mark": "2.00",
                    "value_start": "10.57",
                    "value_end": "10.59",
                    "created_at": "2024-11-27T22:26:27.000000Z",
                    "updated_at": "2024-11-27T22:26:27.000000Z",
                    "question_num_long": 640653906896,
                    "answer_type": "Range",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "9a61485efd000fb16941935faba101b3",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "8034f026-e9ca-4c30-a919-c1167d13ba6f",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/ucRiQbeWVXNCUhFAtIlfcnm6DWklU4JXh34kj5fOuFfYd23tqL.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 44431,
                    "exam_id": 3,
                    "question_paper_id": 150,
                    "question_number": 181,
                    "question_text_1": null,
                    "question_image_1": "5s31yD3r1STLy21G4yZREr0qleBreBkPay5lv4Cw06hxnND2wb.png",
                    "question_type": "SA",
                    "total_mark": "2.00",
                    "value_start": "7.09",
                    "value_end": "7.19",
                    "created_at": "2024-11-27T22:26:27.000000Z",
                    "updated_at": "2024-11-27T22:26:27.000000Z",
                    "question_num_long": 640653906904,
                    "answer_type": "Range",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "59d5fdb629904ff9e1bf65a6c51b26cf",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "561cfe14-1cb5-4059-8f37-115ac9a6b9d4",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/5s31yD3r1STLy21G4yZREr0qleBreBkPay5lv4Cw06hxnND2wb.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 44432,
                    "exam_id": 3,
                    "question_paper_id": 150,
                    "question_number": 182,
                    "question_text_1": null,
                    "question_image_1": "tMVtfUI2hL7n8AlA67Bfg3yzER9j8d0wBalDLuJOWYvq0lnYTU.png",
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "2.85",
                    "value_end": "2.95",
                    "created_at": "2024-11-27T22:26:27.000000Z",
                    "updated_at": "2024-11-27T22:26:27.000000Z",
                    "question_num_long": 640653906898,
                    "answer_type": "Range",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "30ad6f29c511fad00189faf76393a71e",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "7e1677b1-6f3c-4169-ac82-302e54efe758",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/tMVtfUI2hL7n8AlA67Bfg3yzER9j8d0wBalDLuJOWYvq0lnYTU.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 44433,
                    "exam_id": 3,
                    "question_paper_id": 150,
                    "question_number": 183,
                    "question_text_1": null,
                    "question_image_1": "idZNGNVTjKq0sY4VJkFQOPuo4sXqbNOh4LE00CAktEhWPSsSz1.png",
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "3.05",
                    "value_end": "3.15",
                    "created_at": "2024-11-27T22:26:27.000000Z",
                    "updated_at": "2024-11-27T22:26:27.000000Z",
                    "question_num_long": 640653906900,
                    "answer_type": "Range",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "0347a64258ceefbfefd9eaf5a8ba6fd0",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "069bfb1e-5e25-4b68-b385-96970900ff4f",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/idZNGNVTjKq0sY4VJkFQOPuo4sXqbNOh4LE00CAktEhWPSsSz1.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 44434,
                    "exam_id": 3,
                    "question_paper_id": 150,
                    "question_number": 184,
                    "question_text_1": null,
                    "question_image_1": "YmVBQmsU8J9Nk4nQn9oYKnguRRAYMAZasvS6eY1Aw4m9TnlehW.png",
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "3.95",
                    "value_end": "4.05",
                    "created_at": "2024-11-27T22:26:27.000000Z",
                    "updated_at": "2024-11-27T22:26:27.000000Z",
                    "question_num_long": 640653906903,
                    "answer_type": "Range",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "a55efa460b3bad86c6d5421cd18807f2",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "73cbd7b0-2fb3-4707-973d-4adbe0313735",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/YmVBQmsU8J9Nk4nQn9oYKnguRRAYMAZasvS6eY1Aw4m9TnlehW.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [],
                    "parent_question": null
                }
            ]
        },
        "summary": "Here\u2019s a structured **summary of core topics, concepts, principles, and equations** for the **Reinforcement Learning (RL) exam**, followed by **Mermaid knowledge graphs** to visualize relationships.\n\n---\n\n## **1. Core Topics & Concepts**\n### **A. Fundamentals of RL**\n1. **RL vs. Supervised/Unsupervised Learning**\n   - RL learns from **rewards** (not labels).\n   - **Not unsupervised** (unlike clustering/PCA).\n   - **Not supervised** (no input-output pairs).\n\n2. **Markov Decision Process (MDP)**\n   - Defined by: \\((S, A, P, R, \\gamma)\\)\n     - \\(S\\): State space\n     - \\(A\\): Action space\n     - \\(P(s'|s,a)\\): Transition probability\n     - \\(R(s,a,s')\\): Reward function\n     - \\(\\gamma\\): Discount factor (\\(0 \\leq \\gamma \\leq 1\\))\n\n3. **Policies (\\(\\pi\\)) & Value Functions**\n   - **Policy (\\(\\pi(a|s)\\))**: Probability of taking action \\(a\\) in state \\(s\\).\n   - **State-Value Function (\\(v_\\pi(s)\\))**:\n     \\[\n     v_\\pi(s) = \\mathbb{E}_\\pi \\left[ \\sum_{k=0}^\\infty \\gamma^k R_{t+k+1} \\mid S_t = s \\right]\n     \\]\n   - **Action-Value Function (\\(q_\\pi(s,a)\\))**:\n     \\[\n     q_\\pi(s,a) = \\mathbb{E}_\\pi \\left[ R_{t+1} + \\gamma v_\\pi(S_{t+1}) \\mid S_t = s, A_t = a \\right]\n     \\]\n     - **Bellman Equation for \\(q_\\pi(s,a)\\)**:\n       \\[\n       q_\\pi(s,a) = \\sum_{s',r} P(s',r|s,a) \\left[ r + \\gamma \\sum_{a'} \\pi(a'|s') q_\\pi(s',a') \\right]\n       \\]\n     - **Optimal Action-Value Function (\\(q_*(s,a)\\))**:\n       \\[\n       q_*(s,a) = \\sum_{s',r} P(s',r|s,a) \\left[ r + \\gamma \\max_{a'} q_*(s',a') \\right]\n       \\]\n\n---\n\n### **B. Temporal Difference (TD) Learning vs. Monte Carlo (MC)**\n| **Aspect**               | **TD Learning**                          | **Monte Carlo (MC)**                     |\n|--------------------------|------------------------------------------|------------------------------------------|\n| **Updates**              | Online (after each step)                 | Offline (after episode ends)            |\n| **Bias**                 | Can be biased (bootstrapping)            | Unbiased (uses actual returns)          |\n| **Variance**             | Lower variance                           | Higher variance                         |\n| **Model-Free?**          | Yes                                      | Yes                                      |\n| **Example Algorithms**   | SARSA, Q-Learning                        | REINFORCE, Monte Carlo Control          |\n\n- **TD(0) Update Rule**:\n  \\[\n  V(S_t) \\leftarrow V(S_t) + \\alpha \\left[ R_{t+1} + \\gamma V(S_{t+1}) - V(S_t) \\right]\n  \\]\n- **MC Update Rule**:\n  \\[\n  V(S_t) \\leftarrow V(S_t) + \\alpha \\left[ G_t - V(S_t) \\right]\n  \\]\n  where \\(G_t = \\sum_{k=0}^\\infty \\gamma^k R_{t+k+1}\\).\n\n---\n\n### **C. Q-Learning & SARSA**\n| **Algorithm** | **Update Rule**                                                                 | **Policy**               | **Convergence**               |\n|---------------|---------------------------------------------------------------------------------|--------------------------|-------------------------------|\n| **Q-Learning** | \\( Q(s,a) \\leftarrow Q(s,a) + \\alpha [r + \\gamma \\max_{a'} Q(s',a') - Q(s,a)] \\) | Off-policy (greedy)      | Converges to \\(q_*\\)          |\n| **SARSA**     | \\( Q(s,a) \\leftarrow Q(s,a) + \\alpha [r + \\gamma Q(s',a') - Q(s,a)] \\)          | On-policy (\u03b5-greedy)     | Converges to \\(q_\\pi\\)        |\n\n- **Maximization Bias in Q-Learning**:\n  - Overestimates \\(Q(s,a)\\) due to \\(\\max\\) operator.\n  - **Solution**: Double Q-Learning (uses two Q-functions to reduce bias).\n\n- **Double Q-Learning Update**:\n  \\[\n  Q_A(s,a) \\leftarrow Q_A(s,a) + \\alpha \\left[ r + \\gamma Q_B(s', \\arg\\max_{a'} Q_A(s',a')) - Q_A(s,a) \\right]\n  \\]\n\n---\n\n### **D. Policy Gradient Methods**\n1. **REINFORCE (Monte Carlo Policy Gradient)**\n   - Update rule:\n     \\[\n     \\theta \\leftarrow \\theta + \\alpha \\gamma^t G_t \\nabla_\\theta \\log \\pi_\\theta(A_t|S_t)\n     \\]\n   - **Problem**: High variance.\n\n2. **Actor-Critic Methods**\n   - **Actor**: Policy \\(\\pi_\\theta(a|s)\\)\n   - **Critic**: Value function \\(V_\\phi(s)\\)\n   - **Advantage**: \\(A(s,a) = Q(s,a) - V(s)\\)\n   - **Update Rule**:\n     \\[\n     \\theta \\leftarrow \\theta + \\alpha A(s,a) \\nabla_\\theta \\log \\pi_\\theta(a|s)\n     \\]\n   - **TD Target Replacement**:\n     - Reduces variance but introduces bias.\n\n3. **Policy Gradient Theorem**:\n   \\[\n   \\nabla_\\theta J(\\theta) = \\mathbb{E}_\\pi \\left[ \\nabla_\\theta \\log \\pi_\\theta(a|s) Q^\\pi(s,a) \\right]\n   \\]\n\n---\n\n### **E. Function Approximation**\n1. **Linear Function Approximation**:\n   \\[\n   \\hat{V}(s; \\mathbf{w}) = \\mathbf{w}^\\top \\mathbf{x}(s)\n   \\]\n   - **TD(0) Update**:\n     \\[\n     \\mathbf{w} \\leftarrow \\mathbf{w} + \\alpha \\left[ R + \\gamma \\mathbf{w}^\\top \\mathbf{x}(s') - \\mathbf{w}^\\top \\mathbf{x}(s) \\right] \\mathbf{x}(s)\n     \\]\n\n2. **Deep Q-Networks (DQN)**:\n   - Uses neural networks to approximate \\(Q(s,a)\\).\n   - **Experience Replay**: Stores transitions \\((s,a,r,s')\\) to break correlation.\n   - **Target Network**: Reduces moving-target problem.\n\n3. **Dueling DQN**:\n   - Separates \\(Q(s,a)\\) into:\n     \\[\n     Q(s,a) = V(s) + A(s,a) - \\frac{1}{|A|} \\sum_{a'} A(s,a')\n     \\]\n   - **Why?** Better estimates for actions with little impact on \\(V(s)\\).\n\n---\n\n### **F. Hierarchical RL (HRL)**\n1. **Motivation**:\n   - Solves the **curse of dimensionality** in large state spaces.\n   - Decomposes tasks into **subtasks (options)**.\n\n2. **Options**:\n   - **Policy (\\(\\pi\\))**: What to do in the option.\n   - **Termination Condition (\\(\\beta\\))**: When to stop.\n   - **Initiation Set (\\(I\\))**: Where the option can start.\n\n3. **Advantages**:\n   - **Temporal Abstraction**: Skips repetitive low-level actions.\n   - **Faster Learning**: Reuses subtask policies.\n\n---\n\n### **G. Multi-Armed Bandits & Exploration**\n1. **\u03b5-Greedy Policy**:\n   - With probability \\(1-\\epsilon\\), choose best action.\n   - With probability \\(\\epsilon\\), explore randomly.\n\n2. **Policy Gradient in Bandits**:\n   - For Bernoulli policy \\(\\pi_\\theta(a=1) = p\\):\n     \\[\n     \\nabla_\\theta J(\\theta) = (R(a=1) - R(a=0)) \\cdot \\frac{1}{p(1-p)} \\cdot \\nabla_\\theta p\n     \\]\n\n---\n\n### **H. Monte Carlo Tree Search (MCTS) & UCT**\n1. **MCTS Steps**:\n   - **Selection**: Traverse tree using UCB.\n   - **Expansion**: Add a new node.\n   - **Simulation**: Playout to terminal state.\n   - **Backup**: Update node values.\n\n2. **UCT (Upper Confidence Bound for Trees)**:\n   - Balances exploration/exploitation:\n     \\[\n     \\text{UCB1} = \\bar{X}_j + c \\sqrt{\\frac{2 \\ln N}{n_j}}\n     \\]\n   - **Difference from MCTS**: UCT uses UCB for **selection**.\n\n---\n\n## **2. Key Equations Summary**\n| **Concept**               | **Equation**                                                                                     |\n|---------------------------|-------------------------------------------------------------------------------------------------|\n| **Bellman Equation (v)**  | \\( v_\\pi(s) = \\sum_a \\pi(a|s) \\sum_{s',r} P(s',r|s,a) [r + \\gamma v_\\pi(s')] \\)                 |\n| **Bellman Equation (q)**  | \\( q_\\pi(s,a) = \\sum_{s',r} P(s',r|s,a) [r + \\gamma \\sum_{a'} \\pi(a'|s') q_\\pi(s',a')] \\)        |\n| **Q-Learning Update**     | \\( Q(s,a) \\leftarrow Q(s,a) + \\alpha [r + \\gamma \\max_{a'} Q(s',a') - Q(s,a)] \\)               |\n| **SARSA Update**          | \\( Q(s,a) \\leftarrow Q(s,a) + \\alpha [r + \\gamma Q(s',a') - Q(s,a)] \\)                          |\n| **Double Q-Learning**     | \\( Q_A(s,a) \\leftarrow Q_A(s,a) + \\alpha [r + \\gamma Q_B(s', \\arg\\max_{a'} Q_A(s',a')) - Q_A(s,a)] \\) |\n| **Dueling DQN**           | \\( Q(s,a) = V(s) + A(s,a) - \\frac{1}{|A|} \\sum_{a'} A(s,a') \\)                                  |\n| **Policy Gradient**       | \\( \\nabla_\\theta J(\\theta) = \\mathbb{E} [\\nabla_\\theta \\log \\pi_\\theta(a|s) Q(s,a)] \\)        |\n| **REINFORCE**             | \\( \\theta \\leftarrow \\theta + \\alpha \\gamma^t G_t \\nabla_\\theta \\log \\pi_\\theta(A_t|S_t) \\)  |\n| **Actor-Critic**          | \\( \\theta \\leftarrow \\theta + \\alpha A(s,a) \\nabla_\\theta \\log \\pi_\\theta(a|s) \\)            |\n| **TD(0) for FA**          | \\( \\mathbf{w} \\leftarrow \\mathbf{w} + \\alpha [R + \\gamma \\mathbf{w}^\\top \\mathbf{x}(s') - \\mathbf{w}^\\top \\mathbf{x}(s)] \\mathbf{x}(s) \\) |\n| **UCB1 (UCT)**            | \\( \\text{UCB1} = \\bar{X}_j + c \\sqrt{\\frac{2 \\ln N}{n_j}} \\)                                   |\n\n---\n\n## **3. Mermaid Knowledge Graphs**\n### **Graph 1: RL Core Concepts**\n```mermaid\ngraph TD\n    A[Reinforcement Learning] --> B[Markov Decision Process]\n    A --> C[Value Functions]\n    A --> D[Policy Methods]\n    A --> E[Model-Free Methods]\n\n    B --> B1[(S, A, P, R, \u03b3)]\n    B --> B2[Bellman Equations]\n\n    C --> C1[State-Value v\u03c0(s)]\n    C --> C2[Action-Value q\u03c0(s,a)]\n    C --> C3[Optimal Value Functions]\n\n    D --> D1[Policy Gradient]\n    D --> D2[Actor-Critic]\n    D --> D3[REINFORCE]\n\n    E --> E1[Monte Carlo]\n    E --> E2[Temporal Difference]\n    E --> E3[Q-Learning]\n    E --> E4[SARSA]\n```\n\n### **Graph 2: Q-Learning & Variants**\n```mermaid\ngraph TD\n    A[Q-Learning] --> B[Off-Policy]\n    A --> C[Maximization Bias]\n    A --> D[Double Q-Learning]\n\n    B --> B1[Uses max_a' Q(s',a')]\n    B --> B2[Converges to q*]\n\n    C --> C1[Overestimates Q-values]\n    C --> C2[Leads to suboptimal policies]\n\n    D --> D1[Uses two Q-functions]\n    D --> D2[Reduces bias]\n```\n\n### **Graph 3: Policy Gradient Methods**\n```mermaid\ngraph TD\n    A[Policy Gradient] --> B[REINFORCE]\n    A --> C[Actor-Critic]\n    A --> D[Proximal Policy Optimization]\n\n    B --> B1[Monte Carlo]\n    B --> B2[High Variance]\n\n    C --> C1[Uses Critic for Baseline]\n    C --> C2[Reduces Variance]\n\n    D --> D1[Trust Region Updates]\n    D --> D2[Stable Training]\n```\n\n### **Graph 4: Hierarchical RL**\n```mermaid\ngraph TD\n    A[Hierarchical RL] --> B[Options]\n    A --> C[Temporal Abstraction]\n    A --> D[Subtask Decomposition]\n\n    B --> B1[Policy \u03c0]\n    B --> B2[Termination \u03b2]\n    B --> B3[Initiation Set I]\n\n    C --> C1[Skips Low-Level Actions]\n    C --> C2[Faster Learning]\n\n    D --> D1[Complex Task \u2192 Subtasks]\n    D --> D2[Reusable Policies]\n```\n\n### **Graph 5: Exploration vs. Exploitation**\n```mermaid\ngraph TD\n    A[Exploration vs Exploitation] --> B[\u03b5-Greedy]\n    A --> C[UCB]\n    A --> D[Thompson Sampling]\n\n    B --> B1[Random with prob \u03b5]\n    B --> B2[Greedy with prob 1-\u03b5]\n\n    C --> C1[Balances Exploration]\n    C --> C2[Used in UCT]\n\n    D --> D1[Bayesian Approach]\n    D --> D2[Probabilistic Selection]\n```\n\n---\n## **4. Exam Tips**\n1. **Understand Bellman Equations**: Critical for value function questions.\n2. **Know the Difference Between TD and MC**: Bias/variance tradeoff.\n3. **Q-Learning vs. SARSA**: Off-policy vs. on-policy.\n4. **Double Q-Learning**: Reduces maximization bias.\n5. **Dueling DQN**: Separates value and advantage.\n6. **Policy Gradient**: REINFORCE, Actor-Critic, and their updates.\n7. **Hierarchical RL**: Options, initiation sets, termination conditions.\n8. **Function Approximation**: Linear TD updates and neural networks (DQN).\n9. **Bandits**: \u03b5-greedy, UCB, and policy gradients in bandits.\n10. **MCTS/UCT**: Selection via UCB, not standard MCTS.\n\n---\n**Final Note**: Focus on **equations** (especially Bellman, Q-Learning, Policy Gradient) and **conceptual differences** (TD vs. MC, on-policy vs. off-policy). The Mermaid graphs help visualize relationships\u2014use them for quick revision!",
        "total_score": "50.00"
    },
    "url": "/question-paper/practise/43/181df55f-f84",
    "version": "ee3d5d44299e610bd137ea6200db5ac2"
}