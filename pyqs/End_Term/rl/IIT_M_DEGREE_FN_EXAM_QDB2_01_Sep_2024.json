{
    "component": "Quizpractise/PractiseQuestionPaper",
    "props": {
        "errors": {},
        "auth": {
            "user": null
        },
        "flash": {
            "error": []
        },
        "banner": null,
        "file_url": "https://saram.blr1.cdn.digitaloceanspaces.com",
        "file_do_url": "https://saram.blr1.cdn.digitaloceanspaces.com",
        "question_paper": {
            "id": 152,
            "group_id": 24,
            "exam_id": 3,
            "total_score": "1.00",
            "duration": 4,
            "created_at": "2024-11-27T22:26:45.000000Z",
            "updated_at": "2024-11-27T22:26:45.000000Z",
            "question_paper_name": "IIT M DEGREE FN EXAM QDB2 01 Sep 2024",
            "question_paper_description": "2024 Sep01: IIT M FN EXAM QDB2",
            "uuid": "15c0d3b1-c93",
            "year": 2024,
            "is_new": 0,
            "exam": {
                "id": 3,
                "exam_name": "End Term Quiz",
                "created_at": "2024-10-16T08:08:51.000000Z",
                "updated_at": "2024-10-16T08:08:51.000000Z",
                "uuid": "7a6ff569-f50c-40e7-a08b-f5c334392600",
                "en_id": "eyJpdiI6ImwzR1RLTFEreHYybURleGVVTXBXcWc9PSIsInZhbHVlIjoiaEk4bkRhQndjNVF2N2ZNME1YWWhuUT09IiwibWFjIjoiYzg5NjAzMTgzOWQwZTA5Y2U5NTBlM2JhOThlZDZlZDc4ZjQ1NzYwNjlmZGQ3NDkxMDVmZDE2YzE3MDk3MmY1NyIsInRhZyI6IiJ9"
            },
            "questions": [
                {
                    "id": 45227,
                    "exam_id": 3,
                    "question_paper_id": 152,
                    "question_number": 161,
                    "question_text_1": "THIS IS QUESTION PAPER FOR THE SUBJECT \"DEGREE LEVEL : REINFORCEMENT LEARNING (COMPUTER BASED EXAM)\"  ARE YOU SURE YOU HAVE TO WRITE EXAM FOR THIS SUBJECT? CROSS CHECK YOUR HALL TICKET TO CONFIRM THE SUBJECTS TO BE WRITTEN.  (IF IT IS NOT THE CORRECT SUBJECT, PLS CHECK THE SECTION AT THE TOP FOR THE SUBJECTS REGISTERED BY YOU)",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "0.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:46.000000Z",
                    "updated_at": "2024-11-27T22:26:46.000000Z",
                    "question_num_long": 640653907327,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "4a495a034c0b6746dd2050db4ec7c685",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "23cd395a-2983-4a1e-bf49-76f56ec72694",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "THIS IS QUESTION PAPER FOR THE SUBJECT \"DEGREE LEVEL : REINFORCEMENT LEARNING (COMPUTER BASED EXAM)\"  ARE YOU SURE YOU HAVE TO WRITE EXAM FOR THIS SUBJECT? CROSS CHECK YOUR HALL TICKET TO CONFIRM THE SUBJECTS TO BE WRITTEN.  (IF IT IS NOT THE CORRECT SUBJECT, PLS CHECK THE SECTION AT THE TOP FOR THE SUBJECTS REGISTERED BY YOU)"
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 120598,
                            "question_id": 45227,
                            "option_text": "YES",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053845,
                            "option_image_url": null
                        },
                        {
                            "id": 120599,
                            "question_id": 45227,
                            "option_text": "NO",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053846,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 45228,
                    "exam_id": 3,
                    "question_paper_id": 152,
                    "question_number": 162,
                    "question_text_1": "Note: For numerical answer type questions, enter your answer correct upto two decimal places without rounding up or off unless stated otherwise.",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "0.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:46.000000Z",
                    "updated_at": "2024-11-27T22:26:46.000000Z",
                    "question_num_long": 640653907328,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "00244fbde6588c9acd8d705c6eacdb19",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "b8500e75-e289-4732-92d9-2b63a7346b49",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Note: For numerical answer type questions, enter your answer correct upto two decimal places without rounding up or off unless stated otherwise."
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 120600,
                            "question_id": 45228,
                            "option_text": "Instructions has been mentioned above.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053847,
                            "option_image_url": null
                        },
                        {
                            "id": 120601,
                            "question_id": 45228,
                            "option_text": "This Instructions is just for a reference & not for an evaluation.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053848,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 45229,
                    "exam_id": 3,
                    "question_paper_id": 152,
                    "question_number": 163,
                    "question_text_1": "Consider the following assertion reason pair: Assertion: Reinforcement learning is a type of unsupervised learning algorithm as both don\u2019t have correct labels. Reason: In unsupervised learning, a reward like quantity is not maximized.",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:46.000000Z",
                    "updated_at": "2024-11-27T22:26:46.000000Z",
                    "question_num_long": 640653907329,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "1fcd9444a989339f41ff459029833ad7",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "3b972c99-ace4-46d4-8020-39cb44b166bc",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Consider the following assertion reason pair: Assertion: Reinforcement learning is a type of unsupervised learning algorithm as both don\u2019t have correct labels. Reason: In unsupervised learning, a reward like quantity is not maximized."
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 120602,
                            "question_id": 45229,
                            "option_text": "Assertion and Reason are both true and Reason is a correct explanation ofAssertion.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053849,
                            "option_image_url": null
                        },
                        {
                            "id": 120603,
                            "question_id": 45229,
                            "option_text": "Assertion and Reason are both true and Reason is not a correct explanation ofAssertion.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053850,
                            "option_image_url": null
                        },
                        {
                            "id": 120604,
                            "question_id": 45229,
                            "option_text": "Assertion is true but Reason is false.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053851,
                            "option_image_url": null
                        },
                        {
                            "id": 120605,
                            "question_id": 45229,
                            "option_text": "Assertion is false but Reason is true.",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053852,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 45230,
                    "exam_id": 3,
                    "question_paper_id": 152,
                    "question_number": 164,
                    "question_text_1": null,
                    "question_image_1": "EyBF7xAmJX3NyLa9uN1o96W0q8Nd7VqbT8WTZhgViSqsQZV5xa.png",
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:46.000000Z",
                    "updated_at": "2024-11-27T22:26:46.000000Z",
                    "question_num_long": 640653907330,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "a3aa156d5776992f1f1165b2cd04118c",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "195b8ca2-396d-4390-ad21-2b0da23f9dd5",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/EyBF7xAmJX3NyLa9uN1o96W0q8Nd7VqbT8WTZhgViSqsQZV5xa.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 120606,
                            "question_id": 45230,
                            "option_text": "",
                            "option_image": "ECmmQFCeczwqLiZ3bUXV1Z7b2Ow2HtsKe68c7TXELSVABBmgyJ.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053853,
                            "option_image_url": "app/option_images/ECmmQFCeczwqLiZ3bUXV1Z7b2Ow2HtsKe68c7TXELSVABBmgyJ.png"
                        },
                        {
                            "id": 120607,
                            "question_id": 45230,
                            "option_text": "",
                            "option_image": "A49UJ7aROwprRYdx0Aek0tZQjVKRoc4KpEvTI5VEVJ85pjIViw.png",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053854,
                            "option_image_url": "app/option_images/A49UJ7aROwprRYdx0Aek0tZQjVKRoc4KpEvTI5VEVJ85pjIViw.png"
                        },
                        {
                            "id": 120608,
                            "question_id": 45230,
                            "option_text": "",
                            "option_image": "8ke16vaLHmVlDiq1zB2hgEvQdAmgb5f67oYneQeIG2r5Om2OmM.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053855,
                            "option_image_url": "app/option_images/8ke16vaLHmVlDiq1zB2hgEvQdAmgb5f67oYneQeIG2r5Om2OmM.png"
                        },
                        {
                            "id": 120609,
                            "question_id": 45230,
                            "option_text": "",
                            "option_image": "4mMZ0QssSo7ta0ybEdE5j99BXqIwxeRbwT3FvigbnSew7xbz1J.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053856,
                            "option_image_url": "app/option_images/4mMZ0QssSo7ta0ybEdE5j99BXqIwxeRbwT3FvigbnSew7xbz1J.png"
                        },
                        {
                            "id": 120610,
                            "question_id": 45230,
                            "option_text": "",
                            "option_image": "y17E1OILJTmycG4Xh1VrM8d23LLUTsYnld168U2wN5WOjJUUAC.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053857,
                            "option_image_url": "app/option_images/y17E1OILJTmycG4Xh1VrM8d23LLUTsYnld168U2wN5WOjJUUAC.png"
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 45231,
                    "exam_id": 3,
                    "question_paper_id": 152,
                    "question_number": 165,
                    "question_text_1": "Consider a reinforcement learning agent navigating a grid world environment. The agent receives rewards of +1 for reaching the goal state and 0 otherwise. Which of the following statements accurately describes the differences between Monte Carlo and TD learning in this scenario?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:46.000000Z",
                    "updated_at": "2024-11-27T22:26:46.000000Z",
                    "question_num_long": 640653907333,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "164f3b3795e5d659edfb53c6cfc70807",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "a06f73ac-3f96-499e-8c2d-6664a4407ab7",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Consider a reinforcement learning agent navigating a grid world environment. The agent receives rewards of +1 for reaching the goal state and 0 otherwise. Which of the following statements accurately describes the differences between Monte Carlo and TD learning in this scenario?"
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 120611,
                            "question_id": 45231,
                            "option_text": "Monte Carlo updates are unbiased estimators of the true value function, whileTD updates may introduce bias.",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053867,
                            "option_image_url": null
                        },
                        {
                            "id": 120612,
                            "question_id": 45231,
                            "option_text": "TD updates are guaranteed to converge to the optimal value function, whileMonte Carlo updates may not converge.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053868,
                            "option_image_url": null
                        },
                        {
                            "id": 120613,
                            "question_id": 45231,
                            "option_text": "Monte Carlo updates require less memory and computational resourcescompared to TD updates.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053869,
                            "option_image_url": null
                        },
                        {
                            "id": 120614,
                            "question_id": 45231,
                            "option_text": "TD updates are more robust to noise and stochasticity in the environmentcompared to Monte Carlo updates.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053870,
                            "option_image_url": null
                        },
                        {
                            "id": 120615,
                            "question_id": 45231,
                            "option_text": "None of these",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053871,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 45232,
                    "exam_id": 3,
                    "question_paper_id": 152,
                    "question_number": 166,
                    "question_text_1": "Consider a reinforcement learning agent learning to navigate a grid world environment. The agent receives rewards of +1 for reaching the goal state and 0 otherwise. Which of the following statements accurately describes a difference between SARSA and Q-learning in this scenario?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:46.000000Z",
                    "updated_at": "2024-11-27T22:26:46.000000Z",
                    "question_num_long": 640653907334,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "56516fd4205ae3dea8b35c2f843e51c7",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "faa999b6-7bee-4070-96a9-415622e19c53",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Consider a reinforcement learning agent learning to navigate a grid world environment. The agent receives rewards of +1 for reaching the goal state and 0 otherwise. Which of the following statements accurately describes a difference between SARSA and Q-learning in this scenario?"
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 120616,
                            "question_id": 45232,
                            "option_text": "SARSA updates its action-value function based on the action actually taken inthe next state, while Q-learning updates its action-value function based on the maximum action-value in the next state.",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053872,
                            "option_image_url": null
                        },
                        {
                            "id": 120617,
                            "question_id": 45232,
                            "option_text": "SARSA is guaranteed to converge to the optimal policy under certainconditions, while Q-learning may diverge or oscillate without additional modifications.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053873,
                            "option_image_url": null
                        },
                        {
                            "id": 120618,
                            "question_id": 45232,
                            "option_text": "SARSA is more computationally efficient than Q-learning, requiring fewerupdates to converge to the optimal policy.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053874,
                            "option_image_url": null
                        },
                        {
                            "id": 120619,
                            "question_id": 45232,
                            "option_text": "SARSA and Q-learning exhibit similar performance in terms of convergencespeed and solution quality in this scenario.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053875,
                            "option_image_url": null
                        },
                        {
                            "id": 120620,
                            "question_id": 45232,
                            "option_text": "None of these",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053876,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 45233,
                    "exam_id": 3,
                    "question_paper_id": 152,
                    "question_number": 167,
                    "question_text_1": "In Q-learning, how does maximization bias affect the performance of the algorithm in complex environments?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:46.000000Z",
                    "updated_at": "2024-11-27T22:26:46.000000Z",
                    "question_num_long": 640653907336,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "410cd3bddc27b873465b5a06a56326ad",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "fd781ae5-33cf-4933-bdc7-7b35aa20f59d",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "In Q-learning, how does maximization bias affect the performance of the algorithm in complex environments?"
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 120621,
                            "question_id": 45233,
                            "option_text": "Maximization bias can lead to overestimation of action values, resulting insuboptimal policies and slower convergence to the optimal policy.",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053878,
                            "option_image_url": null
                        },
                        {
                            "id": 120622,
                            "question_id": 45233,
                            "option_text": "Maximization bias helps to accelerate learning by prioritizing actions withhigher estimated values, leading to faster convergence to the optimal policy.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053879,
                            "option_image_url": null
                        },
                        {
                            "id": 120623,
                            "question_id": 45233,
                            "option_text": "Maximization bias reduces the exploration-exploitation trade-off, resulting inmore exploratory behavior and improved generalization to unseen states.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053880,
                            "option_image_url": null
                        },
                        {
                            "id": 120624,
                            "question_id": 45233,
                            "option_text": "Maximization bias has minimal impact on the performance of Q-learning incomplex environments, as it tends to balance out over time through exploration.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053881,
                            "option_image_url": null
                        },
                        {
                            "id": 120625,
                            "question_id": 45233,
                            "option_text": "None of these",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053882,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 45234,
                    "exam_id": 3,
                    "question_paper_id": 152,
                    "question_number": 168,
                    "question_text_1": null,
                    "question_image_1": "pjnAhz781bMIYTJ4s2vZj0Nn3zS7bhgRLkPWC5wlxtqnVF98iG.png",
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:46.000000Z",
                    "updated_at": "2024-11-27T22:26:46.000000Z",
                    "question_num_long": 640653907338,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "1954f7b6019d606033112ed3f1232ae3",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "18383f2b-beaa-425a-a662-b67b43c6cb0e",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/pjnAhz781bMIYTJ4s2vZj0Nn3zS7bhgRLkPWC5wlxtqnVF98iG.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 120626,
                            "question_id": 45234,
                            "option_text": "",
                            "option_image": "p8tu2Ne2sFu4p6mMqAQ6ehA8A4Ga9WUqLvz1QgNa4nIPXyMbgM.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053884,
                            "option_image_url": "app/option_images/p8tu2Ne2sFu4p6mMqAQ6ehA8A4Ga9WUqLvz1QgNa4nIPXyMbgM.png"
                        },
                        {
                            "id": 120627,
                            "question_id": 45234,
                            "option_text": "",
                            "option_image": "L5PUPgyRze0UvGJ54sFCiWfFcldw5qajF1hcqbiCj0PM12ahvE.png",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053885,
                            "option_image_url": "app/option_images/L5PUPgyRze0UvGJ54sFCiWfFcldw5qajF1hcqbiCj0PM12ahvE.png"
                        },
                        {
                            "id": 120628,
                            "question_id": 45234,
                            "option_text": "",
                            "option_image": "5YzIauDfw7FUJ9i0GpRv5MzwjlNJNk650PEp6QuJPf087GOCBu.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053886,
                            "option_image_url": "app/option_images/5YzIauDfw7FUJ9i0GpRv5MzwjlNJNk650PEp6QuJPf087GOCBu.png"
                        },
                        {
                            "id": 120629,
                            "question_id": 45234,
                            "option_text": "",
                            "option_image": "TphjlEO72czydmlYCWMUuw8tZkMKTJjQVOa6G5CgZUTHMlnFLs.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053887,
                            "option_image_url": "app/option_images/TphjlEO72czydmlYCWMUuw8tZkMKTJjQVOa6G5CgZUTHMlnFLs.png"
                        },
                        {
                            "id": 120630,
                            "question_id": 45234,
                            "option_text": "",
                            "option_image": "s9wPWMqrmacNMYKvnA1Xk29NcDRxaU7YCYxvllyqpZF9sqMbpG.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053888,
                            "option_image_url": "app/option_images/s9wPWMqrmacNMYKvnA1Xk29NcDRxaU7YCYxvllyqpZF9sqMbpG.png"
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 45235,
                    "exam_id": 3,
                    "question_paper_id": 152,
                    "question_number": 169,
                    "question_text_1": "How is the Q-value Q(s, a) computed in the dueling architecture?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:46.000000Z",
                    "updated_at": "2024-11-27T22:26:46.000000Z",
                    "question_num_long": 640653907340,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "0e835dd59626576b53a11ff5658abc18",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "b60f58c8-b253-40a6-b621-58ab508ac4f9",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "How is the Q-value Q(s, a) computed in the dueling architecture?"
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 120631,
                            "question_id": 45235,
                            "option_text": "",
                            "option_image": "9BnFkdd8Ar2rjCGpOsBNZCUHIU93ZAIn9tyPp8kgtGpNlhhAgV.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053890,
                            "option_image_url": "app/option_images/9BnFkdd8Ar2rjCGpOsBNZCUHIU93ZAIn9tyPp8kgtGpNlhhAgV.png"
                        },
                        {
                            "id": 120632,
                            "question_id": 45235,
                            "option_text": "",
                            "option_image": "EqgV5BkHCO3I2hCUs8grwhiRE40ofEqeEApsFZFxhm8gm0A0Ex.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053891,
                            "option_image_url": "app/option_images/EqgV5BkHCO3I2hCUs8grwhiRE40ofEqeEApsFZFxhm8gm0A0Ex.png"
                        },
                        {
                            "id": 120633,
                            "question_id": 45235,
                            "option_text": "",
                            "option_image": "2hOI11YtHk3zyivX4IMazltC9tkxSX5BghzdSCw2gLi9q0Dqlw.png",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053892,
                            "option_image_url": "app/option_images/2hOI11YtHk3zyivX4IMazltC9tkxSX5BghzdSCw2gLi9q0Dqlw.png"
                        },
                        {
                            "id": 120634,
                            "question_id": 45235,
                            "option_text": "",
                            "option_image": "ixFT4d1x4ztPV5JbnN5Xb9ElgZNa4SsRpc5hMBDiK4soq4xji8.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053893,
                            "option_image_url": "app/option_images/ixFT4d1x4ztPV5JbnN5Xb9ElgZNa4SsRpc5hMBDiK4soq4xji8.png"
                        },
                        {
                            "id": 120635,
                            "question_id": 45235,
                            "option_text": "",
                            "option_image": "8QXqGmyseHRtt5d8jpOkj3HbmdM1raQETxNKfDKzZpwzwR3Kkt.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053894,
                            "option_image_url": "app/option_images/8QXqGmyseHRtt5d8jpOkj3HbmdM1raQETxNKfDKzZpwzwR3Kkt.png"
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 45236,
                    "exam_id": 3,
                    "question_paper_id": 152,
                    "question_number": 170,
                    "question_text_1": "What problem does the dueling architecture aim to address that is commonly faced by standard DQN?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:46.000000Z",
                    "updated_at": "2024-11-27T22:26:46.000000Z",
                    "question_num_long": 640653907341,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "43c4ececcc83595d1f137cad13d693e3",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "6b7bd4cd-82c1-47e1-be76-03515e7c067b",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "What problem does the dueling architecture aim to address that is commonly faced by standard DQN?"
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 120636,
                            "question_id": 45236,
                            "option_text": "The inability to handle large action spaces",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053895,
                            "option_image_url": null
                        },
                        {
                            "id": 120637,
                            "question_id": 45236,
                            "option_text": "The difficulty of learning value functions when rewards are sparse",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053896,
                            "option_image_url": null
                        },
                        {
                            "id": 120638,
                            "question_id": 45236,
                            "option_text": "The slow convergence rate of policy optimization",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053897,
                            "option_image_url": null
                        },
                        {
                            "id": 120639,
                            "question_id": 45236,
                            "option_text": "The inefficiency in estimating Q-values for actions that have little impact onthe overall state value",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053898,
                            "option_image_url": null
                        },
                        {
                            "id": 120640,
                            "question_id": 45236,
                            "option_text": "None of these",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053899,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 45237,
                    "exam_id": 3,
                    "question_paper_id": 152,
                    "question_number": 171,
                    "question_text_1": "Which of the following statements best describes the primary difference between policy gradient methods and value function methods?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:46.000000Z",
                    "updated_at": "2024-11-27T22:26:46.000000Z",
                    "question_num_long": 640653907344,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "c2082a9e1514879c5e3f012e1e072223",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "6a7f23df-37b6-4de6-af0a-f2c463a6269e",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following statements best describes the primary difference between policy gradient methods and value function methods?"
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 120641,
                            "question_id": 45237,
                            "option_text": "Policy gradient methods directly optimize the value function, while valuefunction methods optimize the policy parameters.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053902,
                            "option_image_url": null
                        },
                        {
                            "id": 120642,
                            "question_id": 45237,
                            "option_text": "Value function methods approximate the policy by learning the value functionand deriving the policy from it, while policy gradient methods directly optimize the policy parameters by computing gradients of expected rewards.",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053903,
                            "option_image_url": null
                        },
                        {
                            "id": 120643,
                            "question_id": 45237,
                            "option_text": "Policy gradient methods approximate the value function and use it to optimizethe policy, while value function methods directly optimize the policy using gradients of the log-probability of actions.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053904,
                            "option_image_url": null
                        },
                        {
                            "id": 120644,
                            "question_id": 45237,
                            "option_text": "Value function methods directly optimize the policy parameters, while policygradient methods focus on approximating the value function.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053905,
                            "option_image_url": null
                        },
                        {
                            "id": 120645,
                            "question_id": 45237,
                            "option_text": "None of these",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053906,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 45238,
                    "exam_id": 3,
                    "question_paper_id": 152,
                    "question_number": 172,
                    "question_text_1": "What is a major challenge that Hierarchical Reinforcement Learning (HRL) aims to address?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:46.000000Z",
                    "updated_at": "2024-11-27T22:26:46.000000Z",
                    "question_num_long": 640653907346,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "194e1bce2ef8a69d80f28a59aff490c2",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "7adc6349-c3d2-4600-9de2-f363053be656",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "What is a major challenge that Hierarchical Reinforcement Learning (HRL) aims to address?"
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 120646,
                            "question_id": 45238,
                            "option_text": "Overfitting to specific environments",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053912,
                            "option_image_url": null
                        },
                        {
                            "id": 120647,
                            "question_id": 45238,
                            "option_text": "The curse of dimensionality in large state spaces",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053913,
                            "option_image_url": null
                        },
                        {
                            "id": 120648,
                            "question_id": 45238,
                            "option_text": "Lack of exploration in early stages",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053914,
                            "option_image_url": null
                        },
                        {
                            "id": 120649,
                            "question_id": 45238,
                            "option_text": "Handling non-stationary environments",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053915,
                            "option_image_url": null
                        },
                        {
                            "id": 120650,
                            "question_id": 45238,
                            "option_text": "None of these",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053916,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 45239,
                    "exam_id": 3,
                    "question_paper_id": 152,
                    "question_number": 173,
                    "question_text_1": "In HRL, what is an \u201doption\u201d typically composed of?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:46.000000Z",
                    "updated_at": "2024-11-27T22:26:46.000000Z",
                    "question_num_long": 640653907347,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "90de1a7700a6e7ab374d202ff945b74b",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "933938bb-1078-43f9-88b4-57676f92c628",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "In HRL, what is an \u201doption\u201d typically composed of?"
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 120651,
                            "question_id": 45239,
                            "option_text": "A single action",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053917,
                            "option_image_url": null
                        },
                        {
                            "id": 120652,
                            "question_id": 45239,
                            "option_text": "A sequence of random actions",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053918,
                            "option_image_url": null
                        },
                        {
                            "id": 120653,
                            "question_id": 45239,
                            "option_text": "A policy, a termination condition, and an initiation set",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053919,
                            "option_image_url": null
                        },
                        {
                            "id": 120654,
                            "question_id": 45239,
                            "option_text": "A fixed sequence of primitive actions",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053920,
                            "option_image_url": null
                        },
                        {
                            "id": 120655,
                            "question_id": 45239,
                            "option_text": "None of these",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053921,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 45240,
                    "exam_id": 3,
                    "question_paper_id": 152,
                    "question_number": 174,
                    "question_text_1": "How does HRL typically improve learning efficiency?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:46.000000Z",
                    "updated_at": "2024-11-27T22:26:46.000000Z",
                    "question_num_long": 640653907348,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "70b01efaa9d5313369fb2350c4fd40ed",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "ad1cc5dd-5acb-4c65-8a66-f5b49e8b4d10",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "How does HRL typically improve learning efficiency?"
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 120656,
                            "question_id": 45240,
                            "option_text": "By increasing the learning rate",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053922,
                            "option_image_url": null
                        },
                        {
                            "id": 120657,
                            "question_id": 45240,
                            "option_text": "By reducing the action space",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053923,
                            "option_image_url": null
                        },
                        {
                            "id": 120658,
                            "question_id": 45240,
                            "option_text": "By decomposing a complex task into simpler subtasks",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053924,
                            "option_image_url": null
                        },
                        {
                            "id": 120659,
                            "question_id": 45240,
                            "option_text": "By using a single policy for all tasks",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053925,
                            "option_image_url": null
                        },
                        {
                            "id": 120660,
                            "question_id": 45240,
                            "option_text": "None of these",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053926,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 45241,
                    "exam_id": 3,
                    "question_paper_id": 152,
                    "question_number": 175,
                    "question_text_1": "What distinguishes Hierarchical Reinforcement Learning from traditional reinforcement learning?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:46.000000Z",
                    "updated_at": "2024-11-27T22:26:46.000000Z",
                    "question_num_long": 640653907349,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "5865b942066d50be05d96a97f77844a8",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "9e15fed8-a867-4731-8a6e-f7f8af42b81f",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "What distinguishes Hierarchical Reinforcement Learning from traditional reinforcement learning?"
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 120661,
                            "question_id": 45241,
                            "option_text": "The use of Q-learning instead of policy gradients",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053927,
                            "option_image_url": null
                        },
                        {
                            "id": 120662,
                            "question_id": 45241,
                            "option_text": "The explicit decomposition of tasks into a hierarchy of subtasks",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053928,
                            "option_image_url": null
                        },
                        {
                            "id": 120663,
                            "question_id": 45241,
                            "option_text": "The use of continuous action spaces",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053929,
                            "option_image_url": null
                        },
                        {
                            "id": 120664,
                            "question_id": 45241,
                            "option_text": "The ability to learn in real-time environments",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053930,
                            "option_image_url": null
                        },
                        {
                            "id": 120665,
                            "question_id": 45241,
                            "option_text": "None of these",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053931,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 45242,
                    "exam_id": 3,
                    "question_paper_id": 152,
                    "question_number": 176,
                    "question_text_1": "UCT is different from the original version of MCTS in which of the following steps?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:46.000000Z",
                    "updated_at": "2024-11-27T22:26:46.000000Z",
                    "question_num_long": 640653907350,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "a195036f79fa58011ea669f7ef2ca2a2",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "a500c001-ba38-4d5c-9edd-57a7578eac68",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "UCT is different from the original version of MCTS in which of the following steps?"
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 120666,
                            "question_id": 45242,
                            "option_text": "Expansion",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053932,
                            "option_image_url": null
                        },
                        {
                            "id": 120667,
                            "question_id": 45242,
                            "option_text": "Selection",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053933,
                            "option_image_url": null
                        },
                        {
                            "id": 120668,
                            "question_id": 45242,
                            "option_text": "Backup",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053934,
                            "option_image_url": null
                        },
                        {
                            "id": 120669,
                            "question_id": 45242,
                            "option_text": "Simulation",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053935,
                            "option_image_url": null
                        },
                        {
                            "id": 120670,
                            "question_id": 45242,
                            "option_text": "None of these",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053936,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 45243,
                    "exam_id": 3,
                    "question_paper_id": 152,
                    "question_number": 177,
                    "question_text_1": null,
                    "question_image_1": "jzF11E7WXL2djNUrqpnqBw2lYD19Ep0M431L5otbhJmPmlw8Lc.png",
                    "question_type": "MSQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:46.000000Z",
                    "updated_at": "2024-11-27T22:26:46.000000Z",
                    "question_num_long": 640653907331,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "f03f6a8ad077e2216b52014fa6d2c170",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "8bc690ff-5b8c-43b4-b328-72b397d43528",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/jzF11E7WXL2djNUrqpnqBw2lYD19Ep0M431L5otbhJmPmlw8Lc.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 120671,
                            "question_id": 45243,
                            "option_text": "",
                            "option_image": "J2img6SynSbYJKANiyw84AHgBgtp0SHDjejS6nszOL5YbPU5zY.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053858,
                            "option_image_url": "app/option_images/J2img6SynSbYJKANiyw84AHgBgtp0SHDjejS6nszOL5YbPU5zY.png"
                        },
                        {
                            "id": 120672,
                            "question_id": 45243,
                            "option_text": "",
                            "option_image": "xMeSCHdiBiNDQN6kKoGRyiLZlMp8N2aKarTcqN1wr3kB4sucs8.png",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053859,
                            "option_image_url": "app/option_images/xMeSCHdiBiNDQN6kKoGRyiLZlMp8N2aKarTcqN1wr3kB4sucs8.png"
                        },
                        {
                            "id": 120673,
                            "question_id": 45243,
                            "option_text": "",
                            "option_image": "zkOBw2lD3vZ3zG0kOSaZRD9P8TKSAIcewYGRfOmRdG2scNMj9T.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053860,
                            "option_image_url": "app/option_images/zkOBw2lD3vZ3zG0kOSaZRD9P8TKSAIcewYGRfOmRdG2scNMj9T.png"
                        },
                        {
                            "id": 120674,
                            "question_id": 45243,
                            "option_text": "",
                            "option_image": "QzJ9fspMcfWzXZsjyCcNqb6wlV9xZ0dvCpTD5Q2J944jl5GMRb.png",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053861,
                            "option_image_url": "app/option_images/QzJ9fspMcfWzXZsjyCcNqb6wlV9xZ0dvCpTD5Q2J944jl5GMRb.png"
                        },
                        {
                            "id": 120675,
                            "question_id": 45243,
                            "option_text": "",
                            "option_image": "DKTPhfu1LHLeT6KdldHwdbhAnakNnllzxooLTHVeRlK2UumrB5.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053862,
                            "option_image_url": "app/option_images/DKTPhfu1LHLeT6KdldHwdbhAnakNnllzxooLTHVeRlK2UumrB5.png"
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 45244,
                    "exam_id": 3,
                    "question_paper_id": 152,
                    "question_number": 178,
                    "question_text_1": "Which of the following statements are true with regards to Monte Carlo value approximation methods?",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:46.000000Z",
                    "updated_at": "2024-11-27T22:26:46.000000Z",
                    "question_num_long": 640653907332,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "07d4969aff91835e50ec500d8bc3c7ab",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "f72e66e6-633e-416e-9b04-719c9c61e0af",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following statements are true with regards to Monte Carlo value approximation methods?"
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 120676,
                            "question_id": 45244,
                            "option_text": "To evaluate a policy using these methods, a subset of trajectories in which allstates are encountered at least once are enough to update all state-values.",
                            "option_image": "",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053863,
                            "option_image_url": null
                        },
                        {
                            "id": 120677,
                            "question_id": 45244,
                            "option_text": "Monte-Carlo value function approximation methods need knowledge of thefull model.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053864,
                            "option_image_url": null
                        },
                        {
                            "id": 120678,
                            "question_id": 45244,
                            "option_text": "Monte-Carlo methods update state-value estimates only at the end of anepisode.",
                            "option_image": "",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053865,
                            "option_image_url": null
                        },
                        {
                            "id": 120679,
                            "question_id": 45244,
                            "option_text": "None of these",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053866,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 45245,
                    "exam_id": 3,
                    "question_paper_id": 152,
                    "question_number": 179,
                    "question_text_1": "In the context of actor-critic methods, what is the effect of replacing the return Gt with the TD target?",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:46.000000Z",
                    "updated_at": "2024-11-27T22:26:46.000000Z",
                    "question_num_long": 640653907345,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "3e686c236f2b5ff8d72d59cd039df88c",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "06de455b-a4ac-4bc4-a0fb-689807d170c4",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "In the context of actor-critic methods, what is the effect of replacing the return Gt with the TD target?"
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 120680,
                            "question_id": 45245,
                            "option_text": "It increases the variance in the estimate of the gradient of the performance.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053907,
                            "option_image_url": null
                        },
                        {
                            "id": 120681,
                            "question_id": 45245,
                            "option_text": "It decreases the variance in the estimate of the gradient of the performance.",
                            "option_image": "",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053908,
                            "option_image_url": null
                        },
                        {
                            "id": 120682,
                            "question_id": 45245,
                            "option_text": "It introduces a bias in the estimate of the gradient of the performance.",
                            "option_image": "",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053909,
                            "option_image_url": null
                        },
                        {
                            "id": 120683,
                            "question_id": 45245,
                            "option_text": "It doesn\u2019t introduce any bias in the estimate of the gradient of theperformance.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053910,
                            "option_image_url": null
                        },
                        {
                            "id": 120684,
                            "question_id": 45245,
                            "option_text": "None of these",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:46.000000Z",
                            "updated_at": "2024-11-27T22:26:46.000000Z",
                            "option_number": 6406533053911,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 45246,
                    "exam_id": 3,
                    "question_paper_id": 152,
                    "question_number": 180,
                    "question_text_1": null,
                    "question_image_1": "oTUTmbT0OYJaITWqmJ6bRn49QFft6Z3Bp2SRkgJju6ycsm1oTh.png",
                    "question_type": "SA",
                    "total_mark": "2.00",
                    "value_start": "10.57",
                    "value_end": "10.59",
                    "created_at": "2024-11-27T22:26:46.000000Z",
                    "updated_at": "2024-11-27T22:26:46.000000Z",
                    "question_num_long": 640653907335,
                    "answer_type": "Range",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "9a61485efd000fb16941935faba101b3",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "3d0edbcd-f27c-486c-a300-feae530b7e75",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/oTUTmbT0OYJaITWqmJ6bRn49QFft6Z3Bp2SRkgJju6ycsm1oTh.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 45247,
                    "exam_id": 3,
                    "question_paper_id": 152,
                    "question_number": 181,
                    "question_text_1": null,
                    "question_image_1": "2pgP2u1MEcrVvPfb0AMxu5efvz6ORZnQ6H8kW85LQT4Xqk1Kl7.png",
                    "question_type": "SA",
                    "total_mark": "2.00",
                    "value_start": "7.09",
                    "value_end": "7.19",
                    "created_at": "2024-11-27T22:26:46.000000Z",
                    "updated_at": "2024-11-27T22:26:46.000000Z",
                    "question_num_long": 640653907343,
                    "answer_type": "Range",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "59d5fdb629904ff9e1bf65a6c51b26cf",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "dc83054b-50d1-44fe-ba71-55919fa1b8bd",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/2pgP2u1MEcrVvPfb0AMxu5efvz6ORZnQ6H8kW85LQT4Xqk1Kl7.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 45248,
                    "exam_id": 3,
                    "question_paper_id": 152,
                    "question_number": 182,
                    "question_text_1": null,
                    "question_image_1": "jOJElym6X9fu1ykgIT1rbwU6xbdWxbMhfZhBNV11Q6P78ve4kj.png",
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "2.85",
                    "value_end": "2.95",
                    "created_at": "2024-11-27T22:26:46.000000Z",
                    "updated_at": "2024-11-27T22:26:46.000000Z",
                    "question_num_long": 640653907337,
                    "answer_type": "Range",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "30ad6f29c511fad00189faf76393a71e",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "8d94725d-7874-46e9-b13f-c8fd4131a744",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/jOJElym6X9fu1ykgIT1rbwU6xbdWxbMhfZhBNV11Q6P78ve4kj.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 45249,
                    "exam_id": 3,
                    "question_paper_id": 152,
                    "question_number": 183,
                    "question_text_1": null,
                    "question_image_1": "CCvZocor8PiA8dtHpSFM2p6ry2NjbCwMjpoe255CctEwxnhqN6.png",
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "3.05",
                    "value_end": "3.15",
                    "created_at": "2024-11-27T22:26:46.000000Z",
                    "updated_at": "2024-11-27T22:26:46.000000Z",
                    "question_num_long": 640653907339,
                    "answer_type": "Range",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "0347a64258ceefbfefd9eaf5a8ba6fd0",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "dc46025c-3733-466e-a11a-7d0550dfe399",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/CCvZocor8PiA8dtHpSFM2p6ry2NjbCwMjpoe255CctEwxnhqN6.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 45250,
                    "exam_id": 3,
                    "question_paper_id": 152,
                    "question_number": 184,
                    "question_text_1": null,
                    "question_image_1": "boFjSNnBqrDuClm2GdeOG8NQ2nJrM30w9eKaTzauSVZAy5TvhM.png",
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "3.95",
                    "value_end": "4.05",
                    "created_at": "2024-11-27T22:26:46.000000Z",
                    "updated_at": "2024-11-27T22:26:46.000000Z",
                    "question_num_long": 640653907342,
                    "answer_type": "Range",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "a55efa460b3bad86c6d5421cd18807f2",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "f01492f3-fe82-4e76-b275-b33e85dcd855",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/boFjSNnBqrDuClm2GdeOG8NQ2nJrM30w9eKaTzauSVZAy5TvhM.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [],
                    "parent_question": null
                }
            ]
        },
        "summary": "Here\u2019s a structured **summary of core topics, concepts, principles, and equations** for the **Reinforcement Learning (RL) exam**, followed by **Mermaid knowledge graphs** to visualize relationships.\n\n---\n\n---\n\n### **1. Core Topics & Concepts**\n#### **A. Fundamentals of RL**\n1. **RL vs. Supervised/Unsupervised Learning**:\n   - RL learns from **rewards** (not labels).\n   - **Supervised**: Input-output pairs.\n   - **Unsupervised**: No labels (e.g., clustering).\n   - **RL**: Agent learns by interacting with an environment to maximize cumulative reward.\n\n2. **Markov Decision Process (MDP)**:\n   - Defined by \\((S, A, P, R, \\gamma)\\):\n     - \\(S\\): State space.\n     - \\(A\\): Action space.\n     - \\(P(s'|s,a)\\): Transition probability.\n     - \\(R(s,a,s')\\): Reward function.\n     - \\(\\gamma\\): Discount factor (\\(0 \\leq \\gamma \\leq 1\\)).\n   - **Bellman Equation** (for \\(q_\\pi(s,a)\\)):\n     \\[\n     q_\\pi(s,a) = \\mathbb{E}[R_{t+1} + \\gamma q_\\pi(S_{t+1}, A_{t+1}) | S_t = s, A_t = a]\n     \\]\n     or (deterministic case):\n     \\[\n     q_\\pi(s,a) = \\sum_{s',r} p(s',r|s,a) \\left[ r + \\gamma \\sum_{a'} \\pi(a'|s') q_\\pi(s',a') \\right]\n     \\]\n\n3. **Value Functions**:\n   - **State-value function** \\(v_\\pi(s)\\): Expected return from state \\(s\\) under policy \\(\\pi\\).\n   - **Action-value function** \\(q_\\pi(s,a)\\): Expected return from taking action \\(a\\) in state \\(s\\) and following \\(\\pi\\).\n   - Relationship:\n     \\[\n     v_\\pi(s) = \\sum_a \\pi(a|s) q_\\pi(s,a)\n     \\]\n     \\[\n     q_\\pi(s,a) = \\mathbb{E}[R_{t+1} + \\gamma v_\\pi(S_{t+1}) | S_t = s, A_t = a]\n     \\]\n\n4. **Policy (\\(\\pi\\))**:\n   - Deterministic: \\(\\pi(s) = a\\).\n   - Stochastic: \\(\\pi(a|s) = P(A_t = a | S_t = s)\\).\n\n---\n\n#### **B. Temporal Difference (TD) Learning**\n1. **TD(0) Update Rule**:\n   \\[\n   V(s) \\leftarrow V(s) + \\alpha [R + \\gamma V(s') - V(s)]\n   \\]\n   - **TD Error**: \\(\\delta = R + \\gamma V(s') - V(s)\\).\n\n2. **Monte Carlo (MC) vs. TD Learning**:\n   - **MC**:\n     - Updates at the **end of an episode** (full return).\n     - Unbiased but high variance.\n   - **TD**:\n     - Updates **online** (bootstrapping).\n     - Biased but low variance.\n\n3. **SARSA (On-Policy TD Control)**:\n   - Update rule:\n     \\[\n     Q(s,a) \\leftarrow Q(s,a) + \\alpha [R + \\gamma Q(s',a') - Q(s,a)]\n     \\]\n     where \\(a'\\) is the **next action taken by \\(\\pi\\)**.\n\n4. **Q-Learning (Off-Policy TD Control)**:\n   - Update rule:\n     \\[\n     Q(s,a) \\leftarrow Q(s,a) + \\alpha [R + \\gamma \\max_{a'} Q(s',a') - Q(s,a)]\n     \\]\n   - **Maximization Bias**: Overestimates Q-values by always taking the max, leading to suboptimal policies.\n\n5. **Double Q-Learning**:\n   - Uses **two Q-functions** (\\(Q_A, Q_B\\)) to reduce maximization bias.\n   - Update rule for \\(Q_A\\):\n     \\[\n     Q_A(s,a) \\leftarrow Q_A(s,a) + \\alpha \\left[ R + \\gamma Q_B(s', \\arg\\max_{a'} Q_A(s',a')) - Q_A(s,a) \\right]\n     \\]\n\n---\n\n#### **C. Deep Reinforcement Learning (DRL)**\n1. **DQN (Deep Q-Network)**:\n   - Uses a neural network to approximate \\(Q(s,a)\\).\n   - **Experience Replay**: Stores transitions \\((s,a,r,s')\\) to break temporal correlations.\n   - **Target Network**: Periodically updated to stabilize training.\n\n2. **Dueling Architecture**:\n   - Separates \\(Q(s,a)\\) into:\n     - **Value function** \\(V(s)\\): State value.\n     - **Advantage function** \\(A(s,a)\\): Action-specific advantage.\n   - Combined as:\n     \\[\n     Q(s,a) = V(s) + A(s,a) - \\frac{1}{|A|} \\sum_{a'} A(s,a')\n     \\]\n   - **Purpose**: Efficiently estimate Q-values for actions with little impact on \\(V(s)\\).\n\n3. **Policy Gradient Methods**:\n   - Directly optimize policy parameters \\(\\theta\\) via gradient ascent.\n   - **REINFORCE Algorithm**:\n     \\[\n     \\nabla_\\theta J(\\theta) = \\mathbb{E} \\left[ G_t \\nabla_\\theta \\log \\pi_\\theta(a|s) \\right]\n     \\]\n     where \\(G_t\\) is the return.\n   - **Actor-Critic**:\n     - **Actor**: Policy \\(\\pi_\\theta(a|s)\\).\n     - **Critic**: Value function \\(V_\\phi(s)\\) to reduce variance.\n     - Gradient:\n       \\[\n       \\nabla_\\theta J(\\theta) \\approx \\mathbb{E} \\left[ (G_t - V_\\phi(s)) \\nabla_\\theta \\log \\pi_\\theta(a|s) \\right]\n       \\]\n     - Replacing \\(G_t\\) with **TD target** reduces variance but introduces bias.\n\n4. **Hierarchical RL (HRL)**:\n   - **Options**: Temporal abstraction with:\n     - **Policy** \\(\\pi\\): Action selection.\n     - **Termination condition** \\(\\beta\\): When to stop.\n     - **Initiation set** \\(I\\): Where the option can start.\n   - **Advantages**:\n     - Decomposes complex tasks into subtasks.\n     - Mitigates the **curse of dimensionality**.\n\n---\n\n#### **D. Exploration vs. Exploitation**\n1. **\\(\\epsilon\\)-Greedy Policy**:\n   - With probability \\(\\epsilon\\), take a random action; else, take the greedy action.\n   - Example: \\(\\epsilon = 0.1\\) means 10% exploration.\n\n2. **Bandit Problems**:\n   - **k-Armed Bandit**: Choose among \\(k\\) actions to maximize reward.\n   - **Policy Gradient for Bandits**:\n     - For Bernoulli policy \\(\\pi_\\theta(a=1) = p\\):\n       \\[\n       \\nabla_\\theta J(\\theta) = (R(a=1) - R(a=0)) \\cdot \\frac{\\partial p}{\\partial \\theta}\n       \\]\n     - Example: If \\(p = 0.7\\), \\(R(a=1) = 5\\), then gradient \\(\\approx 7.14\\).\n\n---\n\n#### **E. Function Approximation**\n1. **Linear Function Approximation**:\n   - \\(V(s) \\approx \\mathbf{w}^\\top \\mathbf{x}(s)\\).\n   - **TD(0) Update**:\n     \\[\n     \\mathbf{w} \\leftarrow \\mathbf{w} + \\alpha [R + \\gamma \\mathbf{w}^\\top \\mathbf{x}(s') - \\mathbf{w}^\\top \\mathbf{x}(s)] \\mathbf{x}(s)\n     \\]\n\n2. **L1 Norm**:\n   - For weight vector \\(\\mathbf{w} = [w_1, w_2, w_3]\\):\n     \\[\n     \\|\\mathbf{w}\\|_1 = |w_1| + |w_2| + |w_3|\n     \\]\n\n---\n\n#### **F. Advanced Topics**\n1. **Monte Carlo Tree Search (MCTS)**:\n   - **UCT (Upper Confidence Bound for Trees)**:\n     - Differs from vanilla MCTS in the **selection step** (balances exploration/exploitation).\n     - Selection rule:\n       \\[\n       \\arg\\max_a \\left( Q(a) + c \\sqrt{\\frac{\\ln N}{N(a)}} \\right)\n       \\]\n       where \\(Q(a)\\) is the average reward for action \\(a\\), \\(N\\) is total visits, and \\(N(a)\\) is visits for \\(a\\).\n\n2. **Maximization Bias in Q-Learning**:\n   - Overestimates Q-values due to \\(\\max\\) operator.\n   - **Impact**: Slower convergence and suboptimal policies.\n   - **Example**: If true Q-values are \\([8, 10, 12]\\) but estimated as \\([10, 12, 15]\\), the expected overestimation is \\(3 \\times 0.9 + 0.1 \\times \\text{random} \\approx 2.9\\).\n\n---\n\n---\n\n### **2. Key Equations Summary**\n| **Concept**               | **Equation**                                                                                     |\n|---------------------------|-------------------------------------------------------------------------------------------------|\n| Bellman Equation (Q)      | \\(q_\\pi(s,a) = \\mathbb{E}[R + \\gamma q_\\pi(S',A') | S=s,A=a]\\)                                |\n| TD(0) Update              | \\(V(s) \\leftarrow V(s) + \\alpha [R + \\gamma V(s') - V(s)]\\)                                    |\n| SARSA Update              | \\(Q(s,a) \\leftarrow Q(s,a) + \\alpha [R + \\gamma Q(s',a') - Q(s,a)]\\)                          |\n| Q-Learning Update         | \\(Q(s,a) \\leftarrow Q(s,a) + \\alpha [R + \\gamma \\max_a Q(s',a) - Q(s,a)]\\)                    |\n| Double Q-Learning Update  | \\(Q_A(s,a) \\leftarrow Q_A(s,a) + \\alpha [R + \\gamma Q_B(s', \\arg\\max Q_A(s',a)) - Q_A(s,a)]\\)  |\n| Dueling Architecture      | \\(Q(s,a) = V(s) + A(s,a) - \\frac{1}{|A|} \\sum_{a'} A(s,a')\\)                                   |\n| Policy Gradient (REINFORCE)| \\(\\nabla_\\theta J(\\theta) = \\mathbb{E}[G_t \\nabla_\\theta \\log \\pi_\\theta(a|s)]\\)              |\n| Actor-Critic Gradient     | \\(\\nabla_\\theta J(\\theta) \\approx \\mathbb{E}[(G_t - V(s)) \\nabla_\\theta \\log \\pi_\\theta(a|s)]\\)|\n| Linear FA TD Update       | \\(\\mathbf{w} \\leftarrow \\mathbf{w} + \\alpha \\delta \\mathbf{x}(s)\\), \\(\\delta = R + \\gamma \\mathbf{w}^\\top \\mathbf{x}(s') - \\mathbf{w}^\\top \\mathbf{x}(s)\\) |\n\n---\n\n---\n\n### **3. Mermaid Knowledge Graphs**\n#### **Graph 1: Core RL Concepts**\n```mermaid\ngraph TD\n    A[Reinforcement Learning] --> B[Markov Decision Process]\n    A --> C[Value Functions]\n    A --> D[Policies]\n    B --> B1[(S, A, P, R, \u03b3)]\n    C --> C1[State-Value v\u03c0(s)]\n    C --> C2[Action-Value q\u03c0(s,a)]\n    C --> C3[Bellman Equations]\n    D --> D1[Deterministic]\n    D --> D2[Stochastic]\n```\n\n#### **Graph 2: TD Learning Methods**\n```mermaid\ngraph TD\n    A[Temporal Difference Learning] --> B[Monte Carlo]\n    A --> C[TD(0)]\n    A --> D[SARSA]\n    A --> E[Q-Learning]\n    A --> F[Double Q-Learning]\n    B --> B1[Unbiased, High Variance]\n    C --> C1[Bootstrapping]\n    D --> D1[On-Policy]\n    E --> E1[Off-Policy]\n    E --> E2[Maximization Bias]\n    F --> F1[Reduces Overestimation]\n```\n\n#### **Graph 3: Deep RL & Policy Gradients**\n```mermaid\ngraph TD\n    A[Deep Reinforcement Learning] --> B[DQN]\n    A --> C[Policy Gradients]\n    A --> D[Actor-Critic]\n    B --> B1[Experience Replay]\n    B --> B2[Target Network]\n    C --> C1[REINFORCE]\n    C --> C2[High Variance]\n    D --> D1[Critic: Value Function]\n    D --> D2[Actor: Policy]\n    D --> D3[Lower Variance]\n```\n\n#### **Graph 4: Hierarchical RL & Exploration**\n```mermaid\ngraph TD\n    A[Hierarchical RL] --> B[Options]\n    A --> C[Curse of Dimensionality]\n    B --> B1[Policy \u03c0]\n    B --> B2[Termination \u03b2]\n    B --> B3[Initiation Set I]\n    A --> D[Exploration vs Exploitation]\n    D --> D1[\u03b5-Greedy]\n    D --> D2[Bandit Problems]\n```\n\n#### **Graph 5: Function Approximation**\n```mermaid\ngraph TD\n    A[Function Approximation] --> B[Linear]\n    A --> C[Neural Networks]\n    B --> B1[TD Update Rule]\n    B --> B2[Weight Vector w]\n    C --> C1[DQN]\n    C --> C2[Dueling Architecture]\n```\n\n---\n\n---\n### **4. Exam Tips**\n1. **Understand the Bellman Equations**: Critical for deriving value functions and updates.\n2. **Know the Difference Between On-Policy (SARSA) and Off-Policy (Q-Learning)**.\n3. **Double Q-Learning**: Focus on how it reduces maximization bias.\n4. **Dueling Architecture**: Remember the equation for \\(Q(s,a)\\).\n5. **Policy Gradients**: Understand the role of the critic in Actor-Critic methods.\n6. **HRL**: Know the components of an \"option\" and its advantages.\n7. **Math Problems**:\n   - For Q-learning updates, **plug in the numbers carefully** (e.g., Question 20).\n   - For policy gradients, **compute the gradient of the log-policy** (e.g., Questions 21, 24).\n   - For function approximation, **apply the TD update rule** (e.g., Question 23).",
        "total_score": "50.00"
    },
    "url": "/question-paper/practise/43/15c0d3b1-c93",
    "version": "ee3d5d44299e610bd137ea6200db5ac2"
}