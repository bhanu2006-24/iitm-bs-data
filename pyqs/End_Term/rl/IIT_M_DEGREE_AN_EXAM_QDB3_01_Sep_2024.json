{
    "component": "Quizpractise/PractiseQuestionPaper",
    "props": {
        "errors": {},
        "auth": {
            "user": null
        },
        "flash": {
            "error": []
        },
        "banner": null,
        "file_url": "https://saram.blr1.cdn.digitaloceanspaces.com",
        "file_do_url": "https://saram.blr1.cdn.digitaloceanspaces.com",
        "question_paper": {
            "id": 165,
            "group_id": 24,
            "exam_id": 3,
            "total_score": "1.00",
            "duration": 4,
            "created_at": "2024-11-27T22:38:17.000000Z",
            "updated_at": "2024-11-27T22:38:17.000000Z",
            "question_paper_name": "IIT M DEGREE AN EXAM QDB3 01 Sep 2024",
            "question_paper_description": "2024 Sep01: IIT M AN EXAM QDB3",
            "uuid": "98a7c398-af9",
            "year": 2024,
            "is_new": 0,
            "exam": {
                "id": 3,
                "exam_name": "End Term Quiz",
                "created_at": "2024-10-16T08:08:51.000000Z",
                "updated_at": "2024-10-16T08:08:51.000000Z",
                "uuid": "7a6ff569-f50c-40e7-a08b-f5c334392600",
                "en_id": "eyJpdiI6ImFXQnVUMWNMOVNpdElSNWZQNlF3L0E9PSIsInZhbHVlIjoibmVkOWhpMmkyd1IwUU1ZaEUrdlFpdz09IiwibWFjIjoiMWQ5MWRjODA0ODNhZGJlM2U2ZWMwMTQ0NjEyNTAyZmFlMzEwZmVjZWY0YjViNDNiYTNkNDlkMmM1NWM2YjI5NCIsInRhZyI6IiJ9"
            },
            "questions": [
                {
                    "id": 49245,
                    "exam_id": 3,
                    "question_paper_id": 165,
                    "question_number": 147,
                    "question_text_1": "THIS IS QUESTION PAPER FOR THE SUBJECT \"DEGREE LEVEL : REINFORCEMENT LEARNING (COMPUTER BASED EXAM)\"  ARE YOU SURE YOU HAVE TO WRITE EXAM FOR THIS SUBJECT? CROSS CHECK YOUR HALL TICKET TO CONFIRM THE SUBJECTS TO BE WRITTEN.  (IF IT IS NOT THE CORRECT SUBJECT, PLS CHECK THE SECTION AT THE TOP FOR THE SUBJECTS REGISTERED BY YOU)",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "0.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:38:18.000000Z",
                    "updated_at": "2024-11-27T22:38:18.000000Z",
                    "question_num_long": 640653904190,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "671f0b6f89453f8e76fda5991299e809",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "0f1c1099-6a0c-40e7-9f9b-1dfea8bb51fb",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "THIS IS QUESTION PAPER FOR THE SUBJECT \"DEGREE LEVEL : REINFORCEMENT LEARNING (COMPUTER BASED EXAM)\"  ARE YOU SURE YOU HAVE TO WRITE EXAM FOR THIS SUBJECT? CROSS CHECK YOUR HALL TICKET TO CONFIRM THE SUBJECTS TO BE WRITTEN.  (IF IT IS NOT THE CORRECT SUBJECT, PLS CHECK THE SECTION AT THE TOP FOR THE SUBJECTS REGISTERED BY YOU)"
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 131487,
                            "question_id": 49245,
                            "option_text": "YES",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044690,
                            "option_image_url": null
                        },
                        {
                            "id": 131488,
                            "question_id": 49245,
                            "option_text": "NO",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044691,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 49246,
                    "exam_id": 3,
                    "question_paper_id": 165,
                    "question_number": 148,
                    "question_text_1": "Note:  For numerical answer type questions, enter your answer correct upto two decimal places without rounding up or off unless stated otherwise.",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "0.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:38:18.000000Z",
                    "updated_at": "2024-11-27T22:38:18.000000Z",
                    "question_num_long": 640653904191,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "a32d4fd374c06042f37296eb83d22d44",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "b5c5d628-9f0b-492e-8f9d-2b584640177d",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Note:  For numerical answer type questions, enter your answer correct upto two decimal places without rounding up or off unless stated otherwise."
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 131489,
                            "question_id": 49246,
                            "option_text": "Instructions has been mentioned above.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044692,
                            "option_image_url": null
                        },
                        {
                            "id": 131490,
                            "question_id": 49246,
                            "option_text": "This Instructions is just for a reference & not for an evaluation.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044693,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 49247,
                    "exam_id": 3,
                    "question_paper_id": 165,
                    "question_number": 149,
                    "question_text_1": "Consider following assertion reason pair:  Assertion: Reinforcement learning is a type of unsupervised learning algorithm as both don\u2019t have correct labels. Reason: In unsupervised learning, a reward like quantity is not maximized.",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:38:18.000000Z",
                    "updated_at": "2024-11-27T22:38:18.000000Z",
                    "question_num_long": 640653904192,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "2128ae1730287d366814efba1a0d9ee6",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "d7a1cd47-5030-43af-b504-88db3a8fc722",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Consider following assertion reason pair:  Assertion: Reinforcement learning is a type of unsupervised learning algorithm as both don\u2019t have correct labels. Reason: In unsupervised learning, a reward like quantity is not maximized."
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 131491,
                            "question_id": 49247,
                            "option_text": "Assertion and Reason are both true and Reason is a correct explanation ofAssertion.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044694,
                            "option_image_url": null
                        },
                        {
                            "id": 131492,
                            "question_id": 49247,
                            "option_text": "Assertion and Reason are both true and Reason is not a correct explanation ofAssertion.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044695,
                            "option_image_url": null
                        },
                        {
                            "id": 131493,
                            "question_id": 49247,
                            "option_text": "Assertion is true but Reason is false.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044696,
                            "option_image_url": null
                        },
                        {
                            "id": 131494,
                            "question_id": 49247,
                            "option_text": "Assertion is false but Reason is true.",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044697,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 49248,
                    "exam_id": 3,
                    "question_paper_id": 165,
                    "question_number": 150,
                    "question_text_1": "Which of these statements is true regarding the rewards obtained in an MDP?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:38:18.000000Z",
                    "updated_at": "2024-11-27T22:38:18.000000Z",
                    "question_num_long": 640653904193,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "626fedb61dfbd64c84a13bba75a6c04b",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "d6226e96-2031-4c94-8ac6-8f7f0b11e084",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of these statements is true regarding the rewards obtained in an MDP?"
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 131495,
                            "question_id": 49248,
                            "option_text": "",
                            "option_image": "gI8fxMRp4zcA68gDvDx9IJXvpWMITq6kYkPYTGLjlpsQ32umvt.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044698,
                            "option_image_url": "app/option_images/gI8fxMRp4zcA68gDvDx9IJXvpWMITq6kYkPYTGLjlpsQ32umvt.png"
                        },
                        {
                            "id": 131496,
                            "question_id": 49248,
                            "option_text": "",
                            "option_image": "7vpzik6u0NHgvK27w7Xzfsmky7TeVygowVCjiGY23jDzgIxevw.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044699,
                            "option_image_url": "app/option_images/7vpzik6u0NHgvK27w7Xzfsmky7TeVygowVCjiGY23jDzgIxevw.png"
                        },
                        {
                            "id": 131497,
                            "question_id": 49248,
                            "option_text": "",
                            "option_image": "jBiBdpkrEJzfUbz80ZvsledI1HGFv2GN1VIZK6mqr4omUnnvSU.png",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044700,
                            "option_image_url": "app/option_images/jBiBdpkrEJzfUbz80ZvsledI1HGFv2GN1VIZK6mqr4omUnnvSU.png"
                        },
                        {
                            "id": 131498,
                            "question_id": 49248,
                            "option_text": "",
                            "option_image": "lus9Ds1LzcEqST0PfrTf8O4GE1plBFahbMxiBpoeSE1CMPSEmc.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044701,
                            "option_image_url": "app/option_images/lus9Ds1LzcEqST0PfrTf8O4GE1plBFahbMxiBpoeSE1CMPSEmc.png"
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 49249,
                    "exam_id": 3,
                    "question_paper_id": 165,
                    "question_number": 151,
                    "question_text_1": "Consider a reinforcement learning agent trying to balance a pole in a continuous environment. The agent receives a reward of +1 for each time step the pole remains balanced and 0 otherwise. Which of the following statements accurately describes the differences between Monte Carlo and Temporal Difference (TD) learning in this scenario?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:38:18.000000Z",
                    "updated_at": "2024-11-27T22:38:18.000000Z",
                    "question_num_long": 640653904196,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "1561d1453016236c0b5286fc127004af",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "9414e080-def3-4214-a560-b90bd2f650c6",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Consider a reinforcement learning agent trying to balance a pole in a continuous environment. The agent receives a reward of +1 for each time step the pole remains balanced and 0 otherwise. Which of the following statements accurately describes the differences between Monte Carlo and Temporal Difference (TD) learning in this scenario?"
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 131499,
                            "question_id": 49249,
                            "option_text": "Monte Carlo methods update the value function based on complete episodes,while TD methods update after each step.",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044712,
                            "option_image_url": null
                        },
                        {
                            "id": 131500,
                            "question_id": 49249,
                            "option_text": "TD methods are guaranteed to converge to the optimal policy, while MonteCarlo methods may not converge.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044713,
                            "option_image_url": null
                        },
                        {
                            "id": 131501,
                            "question_id": 49249,
                            "option_text": "Monte Carlo methods are less sensitive to the choice of the discount factorcompared to TD methods.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044714,
                            "option_image_url": null
                        },
                        {
                            "id": 131502,
                            "question_id": 49249,
                            "option_text": "TD methods are more effective in environments with high variance andstochasticity compared to Monte Carlo methods.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044715,
                            "option_image_url": null
                        },
                        {
                            "id": 131503,
                            "question_id": 49249,
                            "option_text": "None of these.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044716,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 49250,
                    "exam_id": 3,
                    "question_paper_id": 165,
                    "question_number": 152,
                    "question_text_1": "Consider a reinforcement learning agent learning to control a robotic arm in a simulated environment. The agent receives a reward of +1 for successfully placing an object in target location and 0 otherwise. Which of the following statements accurately describes a difference between SARSA and Q-learning in this scenario?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:38:18.000000Z",
                    "updated_at": "2024-11-27T22:38:18.000000Z",
                    "question_num_long": 640653904197,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "35b48c97f5fdbb14fe255f8e4e60d2c5",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "96d4ba11-8983-4a2a-b020-73471b088949",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Consider a reinforcement learning agent learning to control a robotic arm in a simulated environment. The agent receives a reward of +1 for successfully placing an object in target location and 0 otherwise. Which of the following statements accurately describes a difference between SARSA and Q-learning in this scenario?"
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 131504,
                            "question_id": 49250,
                            "option_text": "SARSA updates its action-value function using the action taken in the nextstate, while Q-learning updates its action-value function using the maximum action-value across all possible actions in the next state.",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044717,
                            "option_image_url": null
                        },
                        {
                            "id": 131505,
                            "question_id": 49250,
                            "option_text": "SARSA is less sensitive to the choice of policy compared to Q-learning, makingit more robust in environments with frequent changes.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044718,
                            "option_image_url": null
                        },
                        {
                            "id": 131506,
                            "question_id": 49250,
                            "option_text": "SARSA converges more quickly than Q-learning in environments with highreward variance.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044719,
                            "option_image_url": null
                        },
                        {
                            "id": 131507,
                            "question_id": 49250,
                            "option_text": "Q-learning is inherently more computationally efficient than SARSA due tofewer updates required per episode.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044720,
                            "option_image_url": null
                        },
                        {
                            "id": 131508,
                            "question_id": 49250,
                            "option_text": "None of these.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044721,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 49251,
                    "exam_id": 3,
                    "question_paper_id": 165,
                    "question_number": 153,
                    "question_text_1": "In Q-learning, what is the impact of maximization bias on the algorithm\u2019s performance, especially in environments with noisy or stochastic rewards?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:38:18.000000Z",
                    "updated_at": "2024-11-27T22:38:18.000000Z",
                    "question_num_long": 640653904199,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "29cd7ab95d27d5e5da5b4bc537896d43",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "60ce4057-aa43-42ee-970d-c28cd2619163",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "In Q-learning, what is the impact of maximization bias on the algorithm\u2019s performance, especially in environments with noisy or stochastic rewards?"
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 131509,
                            "question_id": 49251,
                            "option_text": "Maximization bias can lead to an overestimation of action values, causing thealgorithm to favor suboptimal actions and potentially delaying convergence to the optimal policy.",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044723,
                            "option_image_url": null
                        },
                        {
                            "id": 131510,
                            "question_id": 49251,
                            "option_text": "Maximization bias tends to enhance the algorithm\u2019s performance byconsistently selecting actions with higher estimated values, leading to quicker convergence.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044724,
                            "option_image_url": null
                        },
                        {
                            "id": 131511,
                            "question_id": 49251,
                            "option_text": "Maximization bias may result in excessive exploration, allowing the algorithmto discover better strategies in environments with highly variable rewards.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044725,
                            "option_image_url": null
                        },
                        {
                            "id": 131512,
                            "question_id": 49251,
                            "option_text": "Maximization bias typically has a minor effect on the performance of Q-learning, as the exploration process naturally mitigates its influence over time.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044726,
                            "option_image_url": null
                        },
                        {
                            "id": 131513,
                            "question_id": 49251,
                            "option_text": "None of these.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044727,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 49252,
                    "exam_id": 3,
                    "question_paper_id": 165,
                    "question_number": 154,
                    "question_text_1": null,
                    "question_image_1": "O9rJMbOZcNq0o7CWc6rF8o8R4C3Oo883p0FFAGKVOwwIB0Chxs.png",
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:38:18.000000Z",
                    "updated_at": "2024-11-27T22:38:18.000000Z",
                    "question_num_long": 640653904201,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "3c5e45df4836a4a25bf32b616f4a73fd",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "8ff78254-a225-47fd-961b-15466205c632",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/O9rJMbOZcNq0o7CWc6rF8o8R4C3Oo883p0FFAGKVOwwIB0Chxs.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 131514,
                            "question_id": 49252,
                            "option_text": "",
                            "option_image": "lCQna8IY3I4ZodlRhj6TwPJ6tvajFejuQ07wsCVDuOb9axrGnn.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044729,
                            "option_image_url": "app/option_images/lCQna8IY3I4ZodlRhj6TwPJ6tvajFejuQ07wsCVDuOb9axrGnn.png"
                        },
                        {
                            "id": 131515,
                            "question_id": 49252,
                            "option_text": "",
                            "option_image": "MQReXaxkJMgtZCv0NWtvHLwuekPso95RVrd9dFOQGd8VeCJst8.png",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044730,
                            "option_image_url": "app/option_images/MQReXaxkJMgtZCv0NWtvHLwuekPso95RVrd9dFOQGd8VeCJst8.png"
                        },
                        {
                            "id": 131516,
                            "question_id": 49252,
                            "option_text": "",
                            "option_image": "y0ITMAhBBs1E90DV3BRrjLvcRC0j07m3Yr9DlCH13P96YNpp9y.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044731,
                            "option_image_url": "app/option_images/y0ITMAhBBs1E90DV3BRrjLvcRC0j07m3Yr9DlCH13P96YNpp9y.png"
                        },
                        {
                            "id": 131517,
                            "question_id": 49252,
                            "option_text": "",
                            "option_image": "5VbdzVuZJfheO2YFByPDn7TdsGUkryLBv3szwfx1xpIgMGSUiN.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044732,
                            "option_image_url": "app/option_images/5VbdzVuZJfheO2YFByPDn7TdsGUkryLBv3szwfx1xpIgMGSUiN.png"
                        },
                        {
                            "id": 131518,
                            "question_id": 49252,
                            "option_text": "",
                            "option_image": "tbHDfgKK9SEUvqTYXZaCJ18tn91P453DTLpPPCo4xgs1nNK0TE.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044733,
                            "option_image_url": "app/option_images/tbHDfgKK9SEUvqTYXZaCJ18tn91P453DTLpPPCo4xgs1nNK0TE.png"
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 49253,
                    "exam_id": 3,
                    "question_paper_id": 165,
                    "question_number": 155,
                    "question_text_1": null,
                    "question_image_1": "BrbwK6Pv7eUBP0KoVZtlNYnPkvqAvqAkMrVyA5NB7TKjZK7dQj.png",
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:38:18.000000Z",
                    "updated_at": "2024-11-27T22:38:18.000000Z",
                    "question_num_long": 640653904203,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "674dd19ef5c86ba3d14ee93c2914d7e3",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "0c232959-e68d-4b21-94e5-1fae662cb877",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/BrbwK6Pv7eUBP0KoVZtlNYnPkvqAvqAkMrVyA5NB7TKjZK7dQj.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 131519,
                            "question_id": 49253,
                            "option_text": "",
                            "option_image": "6vZc7uZMyvFAM20M7gPghFnUtM7vYHzedSnMmntl7RHvXhkHxD.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044735,
                            "option_image_url": "app/option_images/6vZc7uZMyvFAM20M7gPghFnUtM7vYHzedSnMmntl7RHvXhkHxD.png"
                        },
                        {
                            "id": 131520,
                            "question_id": 49253,
                            "option_text": "",
                            "option_image": "RXyq3lWYXaeaSUWJHK7IUqUv9nSdhDLQV1XoybDjBlluHqFjLq.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044736,
                            "option_image_url": "app/option_images/RXyq3lWYXaeaSUWJHK7IUqUv9nSdhDLQV1XoybDjBlluHqFjLq.png"
                        },
                        {
                            "id": 131521,
                            "question_id": 49253,
                            "option_text": "",
                            "option_image": "77mkuQUXxCpo0BiXtokroqqpicPFPpdRsuE8nD3MvlAXx25LJG.png",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044737,
                            "option_image_url": "app/option_images/77mkuQUXxCpo0BiXtokroqqpicPFPpdRsuE8nD3MvlAXx25LJG.png"
                        },
                        {
                            "id": 131522,
                            "question_id": 49253,
                            "option_text": "",
                            "option_image": "4fn66Hq2Nlpj04IkUv1tllpTxW1wAqKZSJ4XwCUf0uhtcUykgc.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044738,
                            "option_image_url": "app/option_images/4fn66Hq2Nlpj04IkUv1tllpTxW1wAqKZSJ4XwCUf0uhtcUykgc.png"
                        },
                        {
                            "id": 131523,
                            "question_id": 49253,
                            "option_text": "",
                            "option_image": "s7rwKpywkVOSALz2DnBw4dCqZWlSRUPBpf11ayJGnlDjFIus39.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044739,
                            "option_image_url": "app/option_images/s7rwKpywkVOSALz2DnBw4dCqZWlSRUPBpf11ayJGnlDjFIus39.png"
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 49254,
                    "exam_id": 3,
                    "question_paper_id": 165,
                    "question_number": 156,
                    "question_text_1": "What key issue in standard DQN does the dueling architecture seek to address?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:38:18.000000Z",
                    "updated_at": "2024-11-27T22:38:18.000000Z",
                    "question_num_long": 640653904204,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "9ce07a27a9be2904126c201eed50616a",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "bf8c6168-0ea7-4d53-8a0c-d22fcdb0b752",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "What key issue in standard DQN does the dueling architecture seek to address?"
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 131524,
                            "question_id": 49254,
                            "option_text": "The problem of ensuring faster convergence in environments with high-dimensional state spaces.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044740,
                            "option_image_url": null
                        },
                        {
                            "id": 131525,
                            "question_id": 49254,
                            "option_text": "The challenge of distinguishing between actions in environments with a largenumber of potential moves.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044741,
                            "option_image_url": null
                        },
                        {
                            "id": 131526,
                            "question_id": 49254,
                            "option_text": "The inefficiency in accurately evaluating actions that do not significantly affectthe overall value of the state.",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044742,
                            "option_image_url": null
                        },
                        {
                            "id": 131527,
                            "question_id": 49254,
                            "option_text": "The difficulty in learning effective value functions when rewards are sparseand infrequent.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044743,
                            "option_image_url": null
                        },
                        {
                            "id": 131528,
                            "question_id": 49254,
                            "option_text": "None of these.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044744,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 49255,
                    "exam_id": 3,
                    "question_paper_id": 165,
                    "question_number": 157,
                    "question_text_1": "Which of the following best captures the key difference between policy gradient methods and Q-learning in reinforcement learning?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:38:18.000000Z",
                    "updated_at": "2024-11-27T22:38:18.000000Z",
                    "question_num_long": 640653904207,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "9b33c65a9253d2a54175e4fe18218146",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "c50a1f71-ae81-4677-bc02-91355261239f",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following best captures the key difference between policy gradient methods and Q-learning in reinforcement learning?"
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 131529,
                            "question_id": 49255,
                            "option_text": "Policy gradient methods directly optimize the policy by computing gradients ofthe expected reward, while Q-learning indirectly improves the policy by learning a value function that estimates the expected rewards for actions.",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044747,
                            "option_image_url": null
                        },
                        {
                            "id": 131530,
                            "question_id": 49255,
                            "option_text": "Q-learning focuses on optimizing the policy parameters directly, while policygradient methods estimate the action-value function to guide policy improvement.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044748,
                            "option_image_url": null
                        },
                        {
                            "id": 131531,
                            "question_id": 49255,
                            "option_text": "Policy gradient methods require a model of the environment\u2019s dynamics tocompute gradients, while Q-learning does not rely on any such model.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044749,
                            "option_image_url": null
                        },
                        {
                            "id": 131532,
                            "question_id": 49255,
                            "option_text": "Q-learning is used primarily for continuous action spaces, while policygradient methods are better suited for discrete action spaces.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044750,
                            "option_image_url": null
                        },
                        {
                            "id": 131533,
                            "question_id": 49255,
                            "option_text": "None of these.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044751,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 49256,
                    "exam_id": 3,
                    "question_paper_id": 165,
                    "question_number": 158,
                    "question_text_1": "Consider following assertion reason pair:  Assertion: A3C can provide better performance compared to A2C, provided the updates are small enough. Reason: In A2C, if a thread runs for a long time, other threads have to wait for it to finish.",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:38:18.000000Z",
                    "updated_at": "2024-11-27T22:38:18.000000Z",
                    "question_num_long": 640653904208,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "add24e72d1e772f31df307c05e8b16f2",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "82a5767a-02bb-468c-92ad-3cbb09e6fb60",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Consider following assertion reason pair:  Assertion: A3C can provide better performance compared to A2C, provided the updates are small enough. Reason: In A2C, if a thread runs for a long time, other threads have to wait for it to finish."
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 131534,
                            "question_id": 49256,
                            "option_text": "Assertion and Reason are both true and Reason is a correct explanation ofAssertion.",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044752,
                            "option_image_url": null
                        },
                        {
                            "id": 131535,
                            "question_id": 49256,
                            "option_text": "Assertion and Reason are both true and Reason is not a correct explanation ofAssertion.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044753,
                            "option_image_url": null
                        },
                        {
                            "id": 131536,
                            "question_id": 49256,
                            "option_text": "Assertion is true but Reason is false.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044754,
                            "option_image_url": null
                        },
                        {
                            "id": 131537,
                            "question_id": 49256,
                            "option_text": "Assertion is false but Reason is true.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044755,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 49257,
                    "exam_id": 3,
                    "question_paper_id": 165,
                    "question_number": 159,
                    "question_text_1": "What role do \u201dmeta-policies\u201d play in Hierarchical Reinforcement Learning?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:38:18.000000Z",
                    "updated_at": "2024-11-27T22:38:18.000000Z",
                    "question_num_long": 640653904209,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "a7589206ee7659936278e06f3f33d116",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "4350a6bf-9b59-473c-ae4b-df0655299c8c",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "What role do \u201dmeta-policies\u201d play in Hierarchical Reinforcement Learning?"
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 131538,
                            "question_id": 49257,
                            "option_text": "They define the specific actions to take in each state.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044756,
                            "option_image_url": null
                        },
                        {
                            "id": 131539,
                            "question_id": 49257,
                            "option_text": "They manage the high-level decisions and selection of subtasks.",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044757,
                            "option_image_url": null
                        },
                        {
                            "id": 131540,
                            "question_id": 49257,
                            "option_text": "They directly compute the rewards for each subtask.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044758,
                            "option_image_url": null
                        },
                        {
                            "id": 131541,
                            "question_id": 49257,
                            "option_text": "They optimize the low-level action policies.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044759,
                            "option_image_url": null
                        },
                        {
                            "id": 131542,
                            "question_id": 49257,
                            "option_text": "None of these.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044760,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 49258,
                    "exam_id": 3,
                    "question_paper_id": 165,
                    "question_number": 160,
                    "question_text_1": "In HRL, what is a \u201dsubtask\u201d typically used for?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:38:18.000000Z",
                    "updated_at": "2024-11-27T22:38:18.000000Z",
                    "question_num_long": 640653904210,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "702664a8921ae9af5eb68d8c19eb0437",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "d530c438-0dc3-4a36-a608-24f6e8461c61",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "In HRL, what is a \u201dsubtask\u201d typically used for?"
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 131543,
                            "question_id": 49258,
                            "option_text": "To evaluate the performance of the overall policy",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044761,
                            "option_image_url": null
                        },
                        {
                            "id": 131544,
                            "question_id": 49258,
                            "option_text": "To execute the final decision made by the high-level policy",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044762,
                            "option_image_url": null
                        },
                        {
                            "id": 131545,
                            "question_id": 49258,
                            "option_text": "To break down complex tasks into more manageable components",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044763,
                            "option_image_url": null
                        },
                        {
                            "id": 131546,
                            "question_id": 49258,
                            "option_text": "To directly interact with the environment and collect rewards",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044764,
                            "option_image_url": null
                        },
                        {
                            "id": 131547,
                            "question_id": 49258,
                            "option_text": "None of these.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044765,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 49259,
                    "exam_id": 3,
                    "question_paper_id": 165,
                    "question_number": 161,
                    "question_text_1": "How does HRL handle long-term dependencies in tasks?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:38:18.000000Z",
                    "updated_at": "2024-11-27T22:38:18.000000Z",
                    "question_num_long": 640653904211,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "43cee299c5ea3e8257114cca0b38a08c",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "3dfeaf84-c85b-4c13-a14f-3f5ae21b533c",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "How does HRL handle long-term dependencies in tasks?"
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 131548,
                            "question_id": 49259,
                            "option_text": "By using recurrent neural networks (RNNs)",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044766,
                            "option_image_url": null
                        },
                        {
                            "id": 131549,
                            "question_id": 49259,
                            "option_text": "By focusing on immediate rewards only",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044767,
                            "option_image_url": null
                        },
                        {
                            "id": 131550,
                            "question_id": 49259,
                            "option_text": "By leveraging hierarchical structures to manage dependencies",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044768,
                            "option_image_url": null
                        },
                        {
                            "id": 131551,
                            "question_id": 49259,
                            "option_text": "By reducing the state space through dimensionality reduction",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044769,
                            "option_image_url": null
                        },
                        {
                            "id": 131552,
                            "question_id": 49259,
                            "option_text": "None of these.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044770,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 49260,
                    "exam_id": 3,
                    "question_paper_id": 165,
                    "question_number": 162,
                    "question_text_1": "What is a common challenge when implementing HRL in practice?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:38:18.000000Z",
                    "updated_at": "2024-11-27T22:38:18.000000Z",
                    "question_num_long": 640653904212,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "23b8280d1b6a418cb303576232a87a0e",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "cff989cd-3665-493c-a29c-a64665c3f3d1",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "What is a common challenge when implementing HRL in practice?"
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 131553,
                            "question_id": 49260,
                            "option_text": "Finding suitable reward functions for all levels",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044771,
                            "option_image_url": null
                        },
                        {
                            "id": 131554,
                            "question_id": 49260,
                            "option_text": "Scaling the approach to very large state spaces",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044772,
                            "option_image_url": null
                        },
                        {
                            "id": 131555,
                            "question_id": 49260,
                            "option_text": "Ensuring the subtasks are independent of each other",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044773,
                            "option_image_url": null
                        },
                        {
                            "id": 131556,
                            "question_id": 49260,
                            "option_text": "Integrating HRL with existing non-hierarchical methods",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044774,
                            "option_image_url": null
                        },
                        {
                            "id": 131557,
                            "question_id": 49260,
                            "option_text": "None of these.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044775,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 49261,
                    "exam_id": 3,
                    "question_paper_id": 165,
                    "question_number": 163,
                    "question_text_1": "Choose the correct formula for UCT:",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:38:18.000000Z",
                    "updated_at": "2024-11-27T22:38:18.000000Z",
                    "question_num_long": 640653904213,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "87b1ae74dc37f10e0bf3181374db3ef0",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "fa249413-e968-4836-9442-2d4e6edc60c7",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Choose the correct formula for UCT:"
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 131558,
                            "question_id": 49261,
                            "option_text": "",
                            "option_image": "7upDfcB3F3gUtEY003AyevEoIREEMFqPBzSibdAUal5RhjWxVR.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044776,
                            "option_image_url": "app/option_images/7upDfcB3F3gUtEY003AyevEoIREEMFqPBzSibdAUal5RhjWxVR.png"
                        },
                        {
                            "id": 131559,
                            "question_id": 49261,
                            "option_text": "",
                            "option_image": "ztRshQk1AHIGRzNNc9Um5RZ2J6a74XQaEXyNi1b8mWxIErmfRT.png",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044777,
                            "option_image_url": "app/option_images/ztRshQk1AHIGRzNNc9Um5RZ2J6a74XQaEXyNi1b8mWxIErmfRT.png"
                        },
                        {
                            "id": 131560,
                            "question_id": 49261,
                            "option_text": "",
                            "option_image": "bNMwvtoGi635cfpdRixbDs9Nt9w3DPIFXcHbjdUYEucZjs1LZm.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044778,
                            "option_image_url": "app/option_images/bNMwvtoGi635cfpdRixbDs9Nt9w3DPIFXcHbjdUYEucZjs1LZm.png"
                        },
                        {
                            "id": 131561,
                            "question_id": 49261,
                            "option_text": "",
                            "option_image": "utZJr3ZK7ter0silJTE6xFG8ufpy9caz3MGRm46IyRMCqlUtix.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044779,
                            "option_image_url": "app/option_images/utZJr3ZK7ter0silJTE6xFG8ufpy9caz3MGRm46IyRMCqlUtix.png"
                        },
                        {
                            "id": 131562,
                            "question_id": 49261,
                            "option_text": "",
                            "option_image": "yiaoQVXe3C9TVguOg6hNsQrpJjrZtoYyMnXDWMlonPi1ppEXEe.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044780,
                            "option_image_url": "app/option_images/yiaoQVXe3C9TVguOg6hNsQrpJjrZtoYyMnXDWMlonPi1ppEXEe.png"
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 49262,
                    "exam_id": 3,
                    "question_paper_id": 165,
                    "question_number": 164,
                    "question_text_1": null,
                    "question_image_1": "unmZZcQxn5v4YVpxqBKFVt9cD4ZHC25bfLuTU0gHpQhdqgAbvN.png",
                    "question_type": "MSQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:38:18.000000Z",
                    "updated_at": "2024-11-27T22:38:18.000000Z",
                    "question_num_long": 640653904194,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "1868c0577f90bd2afcd721a524940e75",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "c9fe1833-c6dd-44da-a012-72272c0d16ae",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/unmZZcQxn5v4YVpxqBKFVt9cD4ZHC25bfLuTU0gHpQhdqgAbvN.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 131563,
                            "question_id": 49262,
                            "option_text": "",
                            "option_image": "dIE3uuzaPKZ6iuH6FDhX2GY7uXXHwoNDH6dI9KQXfu0B8Mpr6p.png",
                            "score": "0.500",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044702,
                            "option_image_url": "app/option_images/dIE3uuzaPKZ6iuH6FDhX2GY7uXXHwoNDH6dI9KQXfu0B8Mpr6p.png"
                        },
                        {
                            "id": 131564,
                            "question_id": 49262,
                            "option_text": "",
                            "option_image": "FY4hX0FppWkrJqBfL8za76TR25R3mm7QzjijbYwtdBM7ydn6R2.png",
                            "score": "0.500",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044703,
                            "option_image_url": "app/option_images/FY4hX0FppWkrJqBfL8za76TR25R3mm7QzjijbYwtdBM7ydn6R2.png"
                        },
                        {
                            "id": 131565,
                            "question_id": 49262,
                            "option_text": "",
                            "option_image": "ADnx2SYFUzonNwFRk30fTDQPmhi8UsBpXIqrRTkoVi6CdU5Jrk.png",
                            "score": "0.500",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044704,
                            "option_image_url": "app/option_images/ADnx2SYFUzonNwFRk30fTDQPmhi8UsBpXIqrRTkoVi6CdU5Jrk.png"
                        },
                        {
                            "id": 131566,
                            "question_id": 49262,
                            "option_text": "",
                            "option_image": "6daSF31okfy3oOHdJI39sULFXvDf8Eb8Q8mL4oy9OBbcLU6J3h.png",
                            "score": "0.500",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044705,
                            "option_image_url": "app/option_images/6daSF31okfy3oOHdJI39sULFXvDf8Eb8Q8mL4oy9OBbcLU6J3h.png"
                        },
                        {
                            "id": 131567,
                            "question_id": 49262,
                            "option_text": "",
                            "option_image": "PQI6unqDt0radSUSUCGwvaH4XGG3YpDX1FMcDZSXdpz4ctPSzC.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044706,
                            "option_image_url": "app/option_images/PQI6unqDt0radSUSUCGwvaH4XGG3YpDX1FMcDZSXdpz4ctPSzC.png"
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 49263,
                    "exam_id": 3,
                    "question_paper_id": 165,
                    "question_number": 165,
                    "question_text_1": "Select the correct statements about Generalized Policy Iteration (GPI).",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:38:18.000000Z",
                    "updated_at": "2024-11-27T22:38:18.000000Z",
                    "question_num_long": 640653904195,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "3808cc32f716101125ae8ef54f7c75c8",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "a6dcdc73-d5ba-47d4-8cd8-0dcca1606d35",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Select the correct statements about Generalized Policy Iteration (GPI)."
                    ],
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [
                        {
                            "id": 131568,
                            "question_id": 49263,
                            "option_text": "GPI lets policy evaluation and policy improvement interact with each otherregardless of the details of the two processes.",
                            "option_image": "",
                            "score": "0.500",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044707,
                            "option_image_url": null
                        },
                        {
                            "id": 131569,
                            "question_id": 49263,
                            "option_text": "At the end of evaluation, the policy is not greedy with respect to the valuefunction computed",
                            "option_image": "",
                            "score": "0.500",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044708,
                            "option_image_url": null
                        },
                        {
                            "id": 131570,
                            "question_id": 49263,
                            "option_text": "GPI converges only when a policy has been found which is greedy with respectto its own value function.",
                            "option_image": "",
                            "score": "0.500",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044709,
                            "option_image_url": null
                        },
                        {
                            "id": 131571,
                            "question_id": 49263,
                            "option_text": "The policy and value function found by GPI at convergence will both beoptimal.",
                            "option_image": "",
                            "score": "0.500",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044710,
                            "option_image_url": null
                        },
                        {
                            "id": 131572,
                            "question_id": 49263,
                            "option_text": "None of these.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:38:18.000000Z",
                            "updated_at": "2024-11-27T22:38:18.000000Z",
                            "option_number": 6406533044711,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 49264,
                    "exam_id": 3,
                    "question_paper_id": 165,
                    "question_number": 166,
                    "question_text_1": null,
                    "question_image_1": "vCieLzC4Zw044VVimPoYCRKjjokoQlwEvGxoYFs8SnfAIHy3Dw.png",
                    "question_type": "SA",
                    "total_mark": "2.00",
                    "value_start": "9.93",
                    "value_end": "10.3",
                    "created_at": "2024-11-27T22:38:18.000000Z",
                    "updated_at": "2024-11-27T22:38:18.000000Z",
                    "question_num_long": 640653904198,
                    "answer_type": "Range",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "c1f5975fa4648e5c5df4eb8046dd8dad",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "6d8656ef-e756-447c-8610-88955c3a3691",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/vCieLzC4Zw044VVimPoYCRKjjokoQlwEvGxoYFs8SnfAIHy3Dw.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 49265,
                    "exam_id": 3,
                    "question_paper_id": 165,
                    "question_number": 167,
                    "question_text_1": null,
                    "question_image_1": "LDPqiHQhByU2JzosEBTdL5PBpyk1UqSVF9m6lO1umfSQS4jHC4.png",
                    "question_type": "SA",
                    "total_mark": "2.00",
                    "value_start": "1.35",
                    "value_end": "1.45",
                    "created_at": "2024-11-27T22:38:18.000000Z",
                    "updated_at": "2024-11-27T22:38:18.000000Z",
                    "question_num_long": 640653904206,
                    "answer_type": "Range",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "b5d806d93a487af304c71cbfc40f8ef8",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "64dec3f5-9f27-4740-b991-debe1cf767cd",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/LDPqiHQhByU2JzosEBTdL5PBpyk1UqSVF9m6lO1umfSQS4jHC4.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 49266,
                    "exam_id": 3,
                    "question_paper_id": 165,
                    "question_number": 168,
                    "question_text_1": null,
                    "question_image_1": "ZKawcSokF4m1TbOqyarXcxren0p7IBUjWbNk8ucgcb0tEymI3b.png",
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "2.85",
                    "value_end": "2.95",
                    "created_at": "2024-11-27T22:38:18.000000Z",
                    "updated_at": "2024-11-27T22:38:18.000000Z",
                    "question_num_long": 640653904200,
                    "answer_type": "Range",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "1abf9f1ff8bcc84b0f100cf2c7ede52e",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "3d01a0ba-4c09-4f6e-b341-d41bf323ca9d",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/ZKawcSokF4m1TbOqyarXcxren0p7IBUjWbNk8ucgcb0tEymI3b.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 49267,
                    "exam_id": 3,
                    "question_paper_id": 165,
                    "question_number": 169,
                    "question_text_1": null,
                    "question_image_1": "Xlj6BZXU9Zm8u0qsHWEPzzLXNP45YgV90IW9YV1QzJ1auhvliN.png",
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "4.3",
                    "value_end": "4.4",
                    "created_at": "2024-11-27T22:38:18.000000Z",
                    "updated_at": "2024-11-27T22:38:18.000000Z",
                    "question_num_long": 640653904202,
                    "answer_type": "Range",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "3d72c766cd93a9cc5813301597eb42ef",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "3253e4fc-83c6-44e1-a9ed-3e19693723c1",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/Xlj6BZXU9Zm8u0qsHWEPzzLXNP45YgV90IW9YV1QzJ1auhvliN.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 49268,
                    "exam_id": 3,
                    "question_paper_id": 165,
                    "question_number": 170,
                    "question_text_1": null,
                    "question_image_1": "A1tMEOPGrPihy7aSQKaA8WhBHiaxlWsMiJKq6XCbqLDucRslIP.png",
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "7.95",
                    "value_end": "8.05",
                    "created_at": "2024-11-27T22:38:18.000000Z",
                    "updated_at": "2024-11-27T22:38:18.000000Z",
                    "question_num_long": 640653904205,
                    "answer_type": "Range",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "2103f1e91f9ca4fc3fbd74e6bd8affc0",
                    "course_id": 43,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "bee7e63f-aec8-4994-bdb7-38b5b4a1cd8f",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/A1tMEOPGrPihy7aSQKaA8WhBHiaxlWsMiJKq6XCbqLDucRslIP.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 43,
                        "course_name": "RL",
                        "course_code": "RL",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "ab3e4efa-6f4b-4ac6-a32f-ad4f63a17064"
                    },
                    "options": [],
                    "parent_question": null
                }
            ]
        },
        "summary": "Here\u2019s a structured **summary of core topics, concepts, principles, and equations** for the **Reinforcement Learning (RL) exam**, followed by **Mermaid knowledge graphs** to visualize relationships.\n\n---\n\n## **Core Topics & Key Concepts**\n### **1. Fundamentals of Reinforcement Learning (RL)**\n- **RL vs. Supervised/Unsupervised Learning**:\n  - RL learns from **rewards** (not labels).\n  - **MDP (Markov Decision Process)**: Defines RL problems with states, actions, rewards, and transitions.\n  - **Reward Hypothesis**: All goals can be framed as maximizing cumulative reward.\n- **Key Equation**:\n  - **Reward Function**: \\( r_{t+1} = R(s_t, a_t, s_{t+1}) \\) (depends on state, action, and next state).\n\n### **2. Value Functions & Bellman Equations**\n- **State-Value Function (V)**:\n  \\( V^\\pi(s) = \\mathbb{E}_\\pi \\left[ \\sum_{k=0}^\\infty \\gamma^k r_{t+k+1} \\mid s_t = s \\right] \\)\n- **Action-Value Function (Q)**:\n  \\( Q^\\pi(s, a) = \\mathbb{E}_\\pi \\left[ \\sum_{k=0}^\\infty \\gamma^k r_{t+k+1} \\mid s_t = s, a_t = a \\right] \\)\n- **Bellman Optimality Equations**:\n  - \\( V^*(s) = \\max_a \\sum_{s'} P(s'|s,a) [R(s,a,s') + \\gamma V^*(s')] \\)\n  - \\( Q^*(s,a) = \\sum_{s'} P(s'|s,a) [R(s,a,s') + \\gamma \\max_{a'} Q^*(s',a')] \\)\n\n### **3. Temporal Difference (TD) Learning vs. Monte Carlo (MC)**\n| **Aspect**               | **TD Learning**                          | **Monte Carlo**                          |\n|--------------------------|------------------------------------------|------------------------------------------|\n| **Update Timing**        | After each step (bootstrapping)          | After full episode (complete return)     |\n| **Bias-Variance Tradeoff** | Low variance, some bias                 | High variance, unbiased                 |\n| **Convergence**          | Faster (online updates)                  | Slower (requires full episodes)          |\n| **Example Algorithms**   | SARSA, Q-Learning                        | REINFORCE, Monte Carlo Control           |\n\n### **4. Q-Learning & SARSA**\n| **Algorithm** | **Update Rule**                                                                 | **Policy**               | **Bias**                     |\n|---------------|---------------------------------------------------------------------------------|--------------------------|------------------------------|\n| **Q-Learning** | \\( Q(s,a) \\leftarrow Q(s,a) + \\alpha [r + \\gamma \\max_{a'} Q(s',a') - Q(s,a)] \\) | Off-policy (greedy)      | Overestimates Q-values (maximization bias) |\n| **SARSA**     | \\( Q(s,a) \\leftarrow Q(s,a) + \\alpha [r + \\gamma Q(s',a') - Q(s,a)] \\)         | On-policy (\u03b5-greedy)     | Less bias, safer updates      |\n\n- **Maximization Bias in Q-Learning**:\n  - Overestimates Q-values due to \\(\\max\\) operator in noisy environments.\n  - **Solution**: Double Q-Learning (uses two Q-functions to reduce bias).\n\n### **5. Double Q-Learning**\n- **Update Rule**:\n  \\( Q_A(s,a) \\leftarrow Q_A(s,a) + \\alpha \\left[ r + \\gamma Q_B(s', \\arg\\max_{a'} Q_A(s',a')) - Q_A(s,a) \\right] \\)\n  (Swaps \\( Q_A \\) and \\( Q_B \\) alternately to reduce overestimation.)\n\n### **6. Dueling Network Architecture**\n- **Q-Value Decomposition**:\n  \\( Q(s,a) = V(s) + A(s,a) - \\frac{1}{|A|} \\sum_{a'} A(s,a') \\)\n  - **Purpose**: Separates **state value (V)** and **advantage (A)** to better evaluate actions in states where some actions don\u2019t matter.\n\n### **7. Policy Gradient Methods**\n- **Objective**: Directly optimize policy parameters \\( \\theta \\) via gradient ascent.\n- **REINFORCE Update**:\n  \\( \\nabla_\\theta J(\\theta) = \\mathbb{E}_\\pi \\left[ \\nabla_\\theta \\log \\pi_\\theta(a|s) \\cdot Q^\\pi(s,a) \\right] \\)\n- **Advantages**:\n  - Works in **continuous action spaces**.\n  - Avoids maximization bias (unlike Q-Learning).\n- **Challenges**:\n  - High variance in gradients.\n  - Requires careful tuning of learning rates.\n\n### **8. Actor-Critic Methods**\n- **Actor**: Policy \\( \\pi_\\theta(a|s) \\).\n- **Critic**: Value function \\( V^\\pi(s) \\) or \\( Q^\\pi(s,a) \\).\n- **Update Rules**:\n  - **Critic**: TD error \\( \\delta = r + \\gamma V(s') - V(s) \\).\n  - **Actor**: \\( \\nabla_\\theta J(\\theta) \\approx \\nabla_\\theta \\log \\pi_\\theta(a|s) \\cdot \\delta \\).\n- **Variants**:\n  - **A2C (Advantage Actor-Critic)**: Synchronized updates.\n  - **A3C (Asynchronous A2C)**: Parallel actors for faster learning.\n\n### **9. Hierarchical Reinforcement Learning (HRL)**\n- **Meta-Policies**: High-level decisions (e.g., subtask selection).\n- **Subtasks**: Break complex tasks into simpler components.\n- **Temporal Abstraction**: Options (macro-actions) for long-term planning.\n- **Challenges**:\n  - Designing **reward functions** for subtasks.\n  - **Credit assignment** across hierarchy levels.\n\n### **10. Exploration vs. Exploitation**\n- **\u03b5-Greedy**: Explore with probability \\( \\epsilon \\), exploit otherwise.\n- **UCT (Upper Confidence Bound for Trees)**:\n  \\( \\text{UCT} = Q(s,a) + 2c \\sqrt{\\frac{2 \\ln N(s)}{N(s,a)}} \\)\n  - Balances exploration (second term) and exploitation (first term).\n\n### **11. Function Approximation**\n- **Linear TD(0) Update**:\n  \\( \\mathbf{w} \\leftarrow \\mathbf{w} + \\alpha \\delta \\nabla_\\mathbf{w} \\hat{V}(s;\\mathbf{w}) \\)\n  where \\( \\delta = r + \\gamma \\hat{V}(s';\\mathbf{w}) - \\hat{V}(s;\\mathbf{w}) \\).\n- **Deep Q-Networks (DQN)**:\n  - Uses neural networks to approximate \\( Q(s,a) \\).\n  - **Experience Replay**: Stores transitions to break correlation.\n  - **Target Network**: Stabilizes training by freezing targets periodically.\n\n### **12. Bandit Problems**\n- **k-Armed Bandit**: Single-state RL problem.\n- **Policy Gradient for Bandits**:\n  \\( \\nabla_\\theta J(\\theta) = \\mathbb{E} \\left[ \\nabla_\\theta \\log \\pi_\\theta(a) \\cdot R(a) \\right] \\)\n  - Example: For Bernoulli policy \\( \\pi_\\theta(a=1) = p \\), gradient is \\( \\frac{R(a=1) - R(a=0)}{p(1-p)} \\).\n\n---\n\n## **Key Equations Summary**\n| **Concept**               | **Equation**                                                                                     |\n|---------------------------|-------------------------------------------------------------------------------------------------|\n| **Q-Learning Update**     | \\( Q(s,a) \\leftarrow Q(s,a) + \\alpha [r + \\gamma \\max_{a'} Q(s',a') - Q(s,a)] \\)                |\n| **SARSA Update**          | \\( Q(s,a) \\leftarrow Q(s,a) + \\alpha [r + \\gamma Q(s',a') - Q(s,a)] \\)                          |\n| **Double Q-Learning**     | \\( Q_A(s,a) \\leftarrow Q_A(s,a) + \\alpha [r + \\gamma Q_B(s', \\arg\\max_{a'} Q_A(s',a')) - Q_A(s,a)] \\) |\n| **Dueling Network**       | \\( Q(s,a) = V(s) + A(s,a) - \\frac{1}{|A|} \\sum_{a'} A(s,a') \\)                                  |\n| **Policy Gradient (REINFORCE)** | \\( \\nabla_\\theta J(\\theta) = \\mathbb{E} \\left[ \\nabla_\\theta \\log \\pi_\\theta(a|s) \\cdot Q(s,a) \\right] \\) |\n| **Actor-Critic (A2C)**    | \\( \\nabla_\\theta J(\\theta) \\approx \\nabla_\\theta \\log \\pi_\\theta(a|s) \\cdot \\delta \\)        |\n| **UCT**                   | \\( \\text{UCT} = Q(s,a) + 2c \\sqrt{\\frac{2 \\ln N(s)}{N(s,a)}} \\)                                |\n| **TD(0) Update**          | \\( \\delta = r + \\gamma \\hat{V}(s';\\mathbf{w}) - \\hat{V}(s;\\mathbf{w}) \\)                     |\n| **Bellman Optimality (Q)**| \\( Q^*(s,a) = \\sum_{s'} P(s'|s,a) [R(s,a,s') + \\gamma \\max_{a'} Q^*(s',a')] \\)                 |\n\n---\n\n## **Mermaid Knowledge Graphs**\n### **1. RL Core Concepts**\n```mermaid\ngraph TD\n    A[Reinforcement Learning] --> B[Markov Decision Process]\n    A --> C[Value Functions]\n    A --> D[Policy Methods]\n    A --> E[Model-Free vs. Model-Based]\n\n    B --> B1[States S]\n    B --> B2[Actions A]\n    B --> B3[Rewards R]\n    B --> B4[Transition P]\n\n    C --> C1[State-Value V]\n    C --> C2[Action-Value Q]\n    C --> C3[Bellman Equations]\n\n    D --> D1[Value-Based]\n    D --> D2[Policy-Based]\n    D --> D3[Actor-Critic]\n\n    E --> E1[Q-Learning]\n    E --> E2[Policy Gradients]\n    E --> E3[DQN]\n```\n\n### **2. Q-Learning Family**\n```mermaid\ngraph TD\n    A[Q-Learning] --> B[Overestimation Bias]\n    A --> C[Double Q-Learning]\n    A --> D[Dueling Network]\n\n    B --> B1[Maximization Bias]\n    B --> B2[Noisy Rewards]\n\n    C --> C1[Two Q-Functions]\n    C --> C2[Reduces Overestimation]\n\n    D --> D1[V(s) + A(s,a)]\n    D --> D2[Better Action Evaluation]\n```\n\n### **3. Policy Gradient Methods**\n```mermaid\ngraph TD\n    A[Policy Gradients] --> B[REINFORCE]\n    A --> C[Actor-Critic]\n    A --> D[A2C/A3C]\n\n    B --> B1[Monte Carlo Returns]\n    B --> B2[High Variance]\n\n    C --> C1[Critic: Value Function]\n    C --> C2[Actor: Policy]\n\n    D --> D1[Synchronous Updates]\n    D --> D2[Asynchronous Parallelism]\n```\n\n### **4. Hierarchical RL**\n```mermaid\ngraph TD\n    A[Hierarchical RL] --> B[Meta-Policies]\n    A --> C[Subtasks]\n    A --> D[Temporal Abstraction]\n\n    B --> B1[High-Level Decisions]\n    B --> B2[Subtask Selection]\n\n    C --> C1[Simpler Components]\n    C --> C2[Modular Learning]\n\n    D --> D1[Options]\n    D --> D2[Macro-Actions]\n```\n\n### **5. Exploration vs. Exploitation**\n```mermaid\ngraph TD\n    A[Exploration vs. Exploitation] --> B[\u03b5-Greedy]\n    A --> C[UCT]\n    A --> D[Thompson Sampling]\n\n    B --> B1[Random Actions]\n    B --> B2[Probability \u03b5]\n\n    C --> C1[Upper Confidence Bound]\n    C --> C2[Balances Exploration]\n\n    D --> D1[Bayesian Approach]\n    D --> D2[Probabilistic Models]\n```\n\n---\n## **Exam Preparation Tips**\n1. **Focus on Equations**:\n   - Q-Learning, SARSA, Double Q-Learning, Dueling Network, Policy Gradient, UCT.\n2. **Understand Bias-Variance Tradeoffs**:\n   - TD vs. Monte Carlo, Q-Learning vs. SARSA, A2C vs. A3C.\n3. **Hierarchical RL**:\n   - Meta-policies, subtasks, and credit assignment.\n4. **Practical Calculations**:\n   - Q-value updates, policy gradients, UCT scores.\n5. **Algorithmic Differences**:\n   - On-policy vs. off-policy, model-free vs. model-based.",
        "total_score": "50.00"
    },
    "url": "/question-paper/practise/43/98a7c398-af9",
    "version": "ee3d5d44299e610bd137ea6200db5ac2"
}