{
    "component": "Quizpractise/PractiseQuestionPaper",
    "props": {
        "errors": {},
        "auth": {
            "user": null
        },
        "flash": {
            "error": []
        },
        "banner": null,
        "file_url": "https://saram.blr1.cdn.digitaloceanspaces.com",
        "file_do_url": "https://saram.blr1.cdn.digitaloceanspaces.com",
        "question_paper": {
            "id": 151,
            "group_id": 19,
            "exam_id": 3,
            "total_score": "1.00",
            "duration": 4,
            "created_at": "2024-11-27T22:26:36.000000Z",
            "updated_at": "2024-11-27T22:26:36.000000Z",
            "question_paper_name": "IIT M DEGREE FN EXAM QDB1 28 Apr 2024",
            "question_paper_description": "2024 Apr28: IIT M FN EXAM QDB1",
            "uuid": "2e0a2dd1-27a",
            "year": 2024,
            "is_new": 0,
            "exam": {
                "id": 3,
                "exam_name": "End Term Quiz",
                "created_at": "2024-10-16T08:08:51.000000Z",
                "updated_at": "2024-10-16T08:08:51.000000Z",
                "uuid": "7a6ff569-f50c-40e7-a08b-f5c334392600",
                "en_id": "eyJpdiI6Illjd2xqbCtPUlhLTHZaMU1jUmdQelE9PSIsInZhbHVlIjoicjFaajA3aFhoRmw0NDM3dFBPU1lpQT09IiwibWFjIjoiZWU0NGI4MWY5YTJkZDg1NmUzZTA2YWUwNWNkYmU1MGZlMTFlYmI1ZDk3ZGQwMmM0Y2Y3MTlmYzkxOThmMzQ3NSIsInRhZyI6IiJ9"
            },
            "questions": [
                {
                    "id": 44877,
                    "exam_id": 3,
                    "question_paper_id": 151,
                    "question_number": 196,
                    "question_text_1": "THIS IS QUESTION PAPER FOR THE SUBJECT \"DEGREE LEVEL : INTRODUCTION TO LARGE LANGUAGE MODELS (COMPUTER BASED EXAM)\"  ARE YOU SURE YOU HAVE TO WRITE EXAM FOR THIS SUBJECT? CROSS CHECK YOUR HALL TICKET TO CONFIRM THE SUBJECTS TO BE WRITTEN.  (IF IT IS NOT THE CORRECT SUBJECT, PLS CHECK THE SECTION AT THE TOP FOR THE SUBJECTS REGISTERED BY YOU)",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "0.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:37.000000Z",
                    "updated_at": "2024-11-27T22:26:37.000000Z",
                    "question_num_long": 640653820861,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "edf4c72dbc2bba16ae9e5dbabd8ad242",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "af11c683-a1e5-46f0-bc7a-c73d928e1618",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "THIS IS QUESTION PAPER FOR THE SUBJECT \"DEGREE LEVEL : INTRODUCTION TO LARGE LANGUAGE MODELS (COMPUTER BASED EXAM)\"  ARE YOU SURE YOU HAVE TO WRITE EXAM FOR THIS SUBJECT? CROSS CHECK YOUR HALL TICKET TO CONFIRM THE SUBJECTS TO BE WRITTEN.  (IF IT IS NOT THE CORRECT SUBJECT, PLS CHECK THE SECTION AT THE TOP FOR THE SUBJECTS REGISTERED BY YOU)"
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [
                        {
                            "id": 119700,
                            "question_id": 44877,
                            "option_text": "YES",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:37.000000Z",
                            "updated_at": "2024-11-27T22:26:37.000000Z",
                            "option_number": 6406532755205,
                            "option_image_url": null
                        },
                        {
                            "id": 119701,
                            "question_id": 44877,
                            "option_text": "NO",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:37.000000Z",
                            "updated_at": "2024-11-27T22:26:37.000000Z",
                            "option_number": 6406532755206,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 44878,
                    "exam_id": 3,
                    "question_paper_id": 151,
                    "question_number": 197,
                    "question_text_1": null,
                    "question_image_1": "3IturLy69TfkkBplRWX3apMGhMicrBztkUK5LoeeHkYO6G4BoT.png",
                    "question_type": "MCQ",
                    "total_mark": "0.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:37.000000Z",
                    "updated_at": "2024-11-27T22:26:37.000000Z",
                    "question_num_long": 640653820862,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "9e1960017fb5211141f2f5d8754ec61b",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "fcbe53a0-dd17-404f-8fcd-860d830fe629",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/3IturLy69TfkkBplRWX3apMGhMicrBztkUK5LoeeHkYO6G4BoT.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [
                        {
                            "id": 119702,
                            "question_id": 44878,
                            "option_text": "Instruction has been mentioned above.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:37.000000Z",
                            "updated_at": "2024-11-27T22:26:37.000000Z",
                            "option_number": 6406532755207,
                            "option_image_url": null
                        },
                        {
                            "id": 119703,
                            "question_id": 44878,
                            "option_text": "This Instruction is just for a reference & not for an evaluation.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:37.000000Z",
                            "updated_at": "2024-11-27T22:26:37.000000Z",
                            "option_number": 6406532755208,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 44879,
                    "exam_id": 3,
                    "question_paper_id": 151,
                    "question_number": 198,
                    "question_text_1": "BERT stands for",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:37.000000Z",
                    "updated_at": "2024-11-27T22:26:37.000000Z",
                    "question_num_long": 640653820866,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "02bcef75f45461a85efd422329243d1d",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "1b256119-29be-4bd4-b10c-488dea140f5c",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "BERT stands for"
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [
                        {
                            "id": 119704,
                            "question_id": 44879,
                            "option_text": "Bidirectional Encoder Representation for Text",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:37.000000Z",
                            "updated_at": "2024-11-27T22:26:37.000000Z",
                            "option_number": 6406532755211,
                            "option_image_url": null
                        },
                        {
                            "id": 119705,
                            "question_id": 44879,
                            "option_text": "Bidirectional Encoder Representation from Transformer",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:37.000000Z",
                            "updated_at": "2024-11-27T22:26:37.000000Z",
                            "option_number": 6406532755212,
                            "option_image_url": null
                        },
                        {
                            "id": 119706,
                            "question_id": 44879,
                            "option_text": "Bidirectionaly Extracted Representation from Transformer",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:37.000000Z",
                            "updated_at": "2024-11-27T22:26:37.000000Z",
                            "option_number": 6406532755213,
                            "option_image_url": null
                        },
                        {
                            "id": 119707,
                            "question_id": 44879,
                            "option_text": "Bidirectionaly Extracted Representation of Text",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:37.000000Z",
                            "updated_at": "2024-11-27T22:26:37.000000Z",
                            "option_number": 6406532755214,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 44880,
                    "exam_id": 3,
                    "question_paper_id": 151,
                    "question_number": 199,
                    "question_text_1": "The statement that, in general, position information can also be injected into the attention layers of a transformer model instead of the embedding of input tokens is",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:37.000000Z",
                    "updated_at": "2024-11-27T22:26:37.000000Z",
                    "question_num_long": 640653820882,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "28c1dc5789a1c0b174f876e62cfb87a0",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "bfce3bef-5e95-45a6-bbd8-2e16ff6d8a99",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "The statement that, in general, position information can also be injected into the attention layers of a transformer model instead of the embedding of input tokens is"
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [
                        {
                            "id": 119708,
                            "question_id": 44880,
                            "option_text": "TRUE",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:37.000000Z",
                            "updated_at": "2024-11-27T22:26:37.000000Z",
                            "option_number": 6406532755241,
                            "option_image_url": null
                        },
                        {
                            "id": 119709,
                            "question_id": 44880,
                            "option_text": "FALSE",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:37.000000Z",
                            "updated_at": "2024-11-27T22:26:37.000000Z",
                            "option_number": 6406532755242,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 44881,
                    "exam_id": 3,
                    "question_paper_id": 151,
                    "question_number": 200,
                    "question_text_1": null,
                    "question_image_1": "x3ik8ptdkZjUNMJ3OH6maqwXYA51Lgert6ALtbxSOcbxnW9V4Q.png",
                    "question_type": "MCQ",
                    "total_mark": "4.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:37.000000Z",
                    "updated_at": "2024-11-27T22:26:37.000000Z",
                    "question_num_long": 640653820881,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "aabb39b836e770517bc4ac0e1c822b5a",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "fa8ede24-3b60-4234-aefd-d36de6fc7d65",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/x3ik8ptdkZjUNMJ3OH6maqwXYA51Lgert6ALtbxSOcbxnW9V4Q.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [
                        {
                            "id": 119710,
                            "question_id": 44881,
                            "option_text": "",
                            "option_image": "aZijSal8SnToX2jjZIzyfwHHfr1MwTkBz1JqIkfkdIutB1PlgP.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:37.000000Z",
                            "updated_at": "2024-11-27T22:26:37.000000Z",
                            "option_number": 6406532755237,
                            "option_image_url": "app/option_images/aZijSal8SnToX2jjZIzyfwHHfr1MwTkBz1JqIkfkdIutB1PlgP.png"
                        },
                        {
                            "id": 119711,
                            "question_id": 44881,
                            "option_text": "",
                            "option_image": "8pr529DudLLlxIPPEV023TkRR0bk0LMA2o6zhyjtO9TTxqO8m3.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:37.000000Z",
                            "updated_at": "2024-11-27T22:26:37.000000Z",
                            "option_number": 6406532755238,
                            "option_image_url": "app/option_images/8pr529DudLLlxIPPEV023TkRR0bk0LMA2o6zhyjtO9TTxqO8m3.png"
                        },
                        {
                            "id": 119712,
                            "question_id": 44881,
                            "option_text": "",
                            "option_image": "duQhG9u0d4RH5gqw7Pvb9P8tanCC5TZEVzJxRVa59uoIKnZxvm.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:37.000000Z",
                            "updated_at": "2024-11-27T22:26:37.000000Z",
                            "option_number": 6406532755239,
                            "option_image_url": "app/option_images/duQhG9u0d4RH5gqw7Pvb9P8tanCC5TZEVzJxRVa59uoIKnZxvm.png"
                        },
                        {
                            "id": 119713,
                            "question_id": 44881,
                            "option_text": "",
                            "option_image": "dVpLeHljLZJvROJ2uGELfHgl9Feahln9SYro5TMsqxRxP6tnS3.png",
                            "score": "4.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:37.000000Z",
                            "updated_at": "2024-11-27T22:26:37.000000Z",
                            "option_number": 6406532755240,
                            "option_image_url": "app/option_images/dVpLeHljLZJvROJ2uGELfHgl9Feahln9SYro5TMsqxRxP6tnS3.png"
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 44882,
                    "exam_id": 3,
                    "question_paper_id": 151,
                    "question_number": 201,
                    "question_text_1": null,
                    "question_image_1": "n74algZEEv9GDBnSFYTwo2FJktTSNmzT4Md3k3ZllkNmJTpd48.png",
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "somewhere something incredible is waiting be",
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:37.000000Z",
                    "updated_at": "2024-11-27T22:26:37.000000Z",
                    "question_num_long": 640653820877,
                    "answer_type": "Equal",
                    "response_type": "Alphanumeric",
                    "have_answers": 0,
                    "hash": "a43079fe3beb25d1d66dc469841a2511",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "199b7e47-a05f-4f9c-b2d2-69b82a105c38",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/n74algZEEv9GDBnSFYTwo2FJktTSNmzT4Md3k3ZllkNmJTpd48.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 44883,
                    "exam_id": 3,
                    "question_paper_id": 151,
                    "question_number": 0,
                    "question_text_1": "Suppose a GPT model is pre-trained using the Causal Language Modelling (CLM) objective and fine-tuned on a text summarization task. The context length T of the model was kept at 1024 during both pre-training and fine-tuning. Assume that the model uses Absolute Position Embedding (APE) with learnable parameters.  Based on the above data, answer the given subquestions.",
                    "question_image_1": null,
                    "question_type": "COMPREHENSION",
                    "total_mark": "0.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:37.000000Z",
                    "updated_at": "2024-11-27T22:26:37.000000Z",
                    "question_num_long": 640653820874,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 0,
                    "hash": "2f6b285e08141e1191b15b8e7c808e13",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "7fce2bce-4a54-442f-be00-1d1d4f28bb81",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Suppose a GPT model is pre-trained using the Causal Language Modelling (CLM) objective and fine-tuned on a text summarization task. The context length T of the model was kept at 1024 during both pre-training and fine-tuning. Assume that the model uses Absolute Position Embedding (APE) with learnable parameters.  Based on the above data, answer the given subquestions."
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 44884,
                    "exam_id": 3,
                    "question_paper_id": 151,
                    "question_number": 202,
                    "question_text_1": "A user runs inference on the model N times with an input text that contains 712 tokens (including the special [start] token), then which of the following could be the possible length of summarized text",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:37.000000Z",
                    "updated_at": "2024-11-27T22:26:37.000000Z",
                    "question_num_long": 640653820875,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "d475f091d3d4cc564ba1bed161080873",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 44883,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "5698bea6-853d-40e7-b482-137f9e99a717",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "A user runs inference on the model N times with an input text that contains 712 tokens (including the special [start] token), then which of the following could be the possible length of summarized text"
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [
                        {
                            "id": 119714,
                            "question_id": 44884,
                            "option_text": "256",
                            "option_image": "",
                            "score": "1.500",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:37.000000Z",
                            "updated_at": "2024-11-27T22:26:37.000000Z",
                            "option_number": 6406532755225,
                            "option_image_url": null
                        },
                        {
                            "id": 119715,
                            "question_id": 44884,
                            "option_text": "16",
                            "option_image": "",
                            "score": "1.500",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:37.000000Z",
                            "updated_at": "2024-11-27T22:26:37.000000Z",
                            "option_number": 6406532755226,
                            "option_image_url": null
                        },
                        {
                            "id": 119716,
                            "question_id": 44884,
                            "option_text": "1024",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:37.000000Z",
                            "updated_at": "2024-11-27T22:26:37.000000Z",
                            "option_number": 6406532755227,
                            "option_image_url": null
                        },
                        {
                            "id": 119717,
                            "question_id": 44884,
                            "option_text": "512",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:37.000000Z",
                            "updated_at": "2024-11-27T22:26:37.000000Z",
                            "option_number": 6406532755228,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": {
                        "id": 44883,
                        "exam_id": 3,
                        "question_paper_id": 151,
                        "question_number": 0,
                        "question_text_1": "Suppose a GPT model is pre-trained using the Causal Language Modelling (CLM) objective and fine-tuned on a text summarization task. The context length T of the model was kept at 1024 during both pre-training and fine-tuning. Assume that the model uses Absolute Position Embedding (APE) with learnable parameters.  Based on the above data, answer the given subquestions.",
                        "question_image_1": null,
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2024-11-27T22:26:37.000000Z",
                        "updated_at": "2024-11-27T22:26:37.000000Z",
                        "question_num_long": 640653820874,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "2f6b285e08141e1191b15b8e7c808e13",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "7fce2bce-4a54-442f-be00-1d1d4f28bb81",
                        "question_image_url": null,
                        "question_texts": [
                            "Suppose a GPT model is pre-trained using the Causal Language Modelling (CLM) objective and fine-tuned on a text summarization task. The context length T of the model was kept at 1024 during both pre-training and fine-tuning. Assume that the model uses Absolute Position Embedding (APE) with learnable parameters.  Based on the above data, answer the given subquestions."
                        ]
                    }
                },
                {
                    "id": 44885,
                    "exam_id": 3,
                    "question_paper_id": 151,
                    "question_number": 203,
                    "question_text_1": "A user runs inference on the model N times with an input text that contains 712 tokens (including the special [start] token). However, the user observed that in each run the model generated the exact same summary. Based on this observation, select the decoding strategy that the model might be using",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:37.000000Z",
                    "updated_at": "2024-11-27T22:26:37.000000Z",
                    "question_num_long": 640653820876,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "ecbb90d8b1b4b34b6368c9220acc3ebb",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 44883,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "8d30a2f8-87ed-47a1-9c37-faaa8cbdb0d5",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "A user runs inference on the model N times with an input text that contains 712 tokens (including the special [start] token). However, the user observed that in each run the model generated the exact same summary. Based on this observation, select the decoding strategy that the model might be using"
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [
                        {
                            "id": 119718,
                            "question_id": 44885,
                            "option_text": "Greedy decoding strategy",
                            "option_image": "",
                            "score": "1.500",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:37.000000Z",
                            "updated_at": "2024-11-27T22:26:37.000000Z",
                            "option_number": 6406532755229,
                            "option_image_url": null
                        },
                        {
                            "id": 119719,
                            "question_id": 44885,
                            "option_text": "Beam search with beam size K > 2",
                            "option_image": "",
                            "score": "1.500",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:37.000000Z",
                            "updated_at": "2024-11-27T22:26:37.000000Z",
                            "option_number": 6406532755230,
                            "option_image_url": null
                        },
                        {
                            "id": 119720,
                            "question_id": 44885,
                            "option_text": "Top-k sampling with K > 3",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:37.000000Z",
                            "updated_at": "2024-11-27T22:26:37.000000Z",
                            "option_number": 6406532755231,
                            "option_image_url": null
                        },
                        {
                            "id": 119721,
                            "question_id": 44885,
                            "option_text": "Top-P sampling with p = 0.25",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:37.000000Z",
                            "updated_at": "2024-11-27T22:26:37.000000Z",
                            "option_number": 6406532755232,
                            "option_image_url": null
                        },
                        {
                            "id": 119722,
                            "question_id": 44885,
                            "option_text": "Greedy decoding by varying the temperature parameter T in the softmaxfunction for each run",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:37.000000Z",
                            "updated_at": "2024-11-27T22:26:37.000000Z",
                            "option_number": 6406532755233,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": {
                        "id": 44883,
                        "exam_id": 3,
                        "question_paper_id": 151,
                        "question_number": 0,
                        "question_text_1": "Suppose a GPT model is pre-trained using the Causal Language Modelling (CLM) objective and fine-tuned on a text summarization task. The context length T of the model was kept at 1024 during both pre-training and fine-tuning. Assume that the model uses Absolute Position Embedding (APE) with learnable parameters.  Based on the above data, answer the given subquestions.",
                        "question_image_1": null,
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2024-11-27T22:26:37.000000Z",
                        "updated_at": "2024-11-27T22:26:37.000000Z",
                        "question_num_long": 640653820874,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "2f6b285e08141e1191b15b8e7c808e13",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "7fce2bce-4a54-442f-be00-1d1d4f28bb81",
                        "question_image_url": null,
                        "question_texts": [
                            "Suppose a GPT model is pre-trained using the Causal Language Modelling (CLM) objective and fine-tuned on a text summarization task. The context length T of the model was kept at 1024 during both pre-training and fine-tuning. Assume that the model uses Absolute Position Embedding (APE) with learnable parameters.  Based on the above data, answer the given subquestions."
                        ]
                    }
                },
                {
                    "id": 44886,
                    "exam_id": 3,
                    "question_paper_id": 151,
                    "question_number": 0,
                    "question_text_1": "  Based on the above data, answer the given subquestions.",
                    "question_image_1": "OAZctfTHTKI9G1lvp0LsUP6MdD6nUsruJsZqzTyCGrFDxrRmX1.png",
                    "question_type": "COMPREHENSION",
                    "total_mark": "0.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:37.000000Z",
                    "updated_at": "2024-11-27T22:26:37.000000Z",
                    "question_num_long": 640653820878,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 0,
                    "hash": "6e0bce493d190744da2519aac33db2f5",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "9a6e2a04-e51d-4cc9-bd25-402c946c37ed",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/OAZctfTHTKI9G1lvp0LsUP6MdD6nUsruJsZqzTyCGrFDxrRmX1.png"
                    ],
                    "question_texts": [
                        "  Based on the above data, answer the given subquestions."
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 44887,
                    "exam_id": 3,
                    "question_paper_id": 151,
                    "question_number": 204,
                    "question_text_1": "Suppose the input word to the tokenizer is \u201cSomeThing\u201d. Assume that input text is normalized before applying pre-tokenization. Enter the number of tokens returned by the tokenizer. Ignore the special token used to represent the boundary of the word/token.",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "3.00",
                    "value_start": "6",
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:37.000000Z",
                    "updated_at": "2024-11-27T22:26:37.000000Z",
                    "question_num_long": 640653820879,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "5cf4d6da8aaac9aba83ab6069f95efad",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 44886,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "50304c66-cf7d-4533-8c7f-d4de1041c7c7",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Suppose the input word to the tokenizer is \u201cSomeThing\u201d. Assume that input text is normalized before applying pre-tokenization. Enter the number of tokens returned by the tokenizer. Ignore the special token used to represent the boundary of the word/token."
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": {
                        "id": 44886,
                        "exam_id": 3,
                        "question_paper_id": 151,
                        "question_number": 0,
                        "question_text_1": "  Based on the above data, answer the given subquestions.",
                        "question_image_1": "OAZctfTHTKI9G1lvp0LsUP6MdD6nUsruJsZqzTyCGrFDxrRmX1.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2024-11-27T22:26:37.000000Z",
                        "updated_at": "2024-11-27T22:26:37.000000Z",
                        "question_num_long": 640653820878,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "6e0bce493d190744da2519aac33db2f5",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "9a6e2a04-e51d-4cc9-bd25-402c946c37ed",
                        "question_image_url": [
                            "/question_images/OAZctfTHTKI9G1lvp0LsUP6MdD6nUsruJsZqzTyCGrFDxrRmX1.png"
                        ],
                        "question_texts": [
                            "  Based on the above data, answer the given subquestions."
                        ]
                    }
                },
                {
                    "id": 44888,
                    "exam_id": 3,
                    "question_paper_id": 151,
                    "question_number": 205,
                    "question_text_1": "Suppose the input word to the tokenizer is \u201c1000000\u201d.Enter the number of tokens returned by the tokenizer.",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "3.00",
                    "value_start": "6",
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:37.000000Z",
                    "updated_at": "2024-11-27T22:26:37.000000Z",
                    "question_num_long": 640653820880,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "5cf4d6da8aaac9aba83ab6069f95efad",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 44886,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "1ad6fd8f-bf49-4c5a-9116-a4d3dcb2627f",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Suppose the input word to the tokenizer is \u201c1000000\u201d.Enter the number of tokens returned by the tokenizer."
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": {
                        "id": 44886,
                        "exam_id": 3,
                        "question_paper_id": 151,
                        "question_number": 0,
                        "question_text_1": "  Based on the above data, answer the given subquestions.",
                        "question_image_1": "OAZctfTHTKI9G1lvp0LsUP6MdD6nUsruJsZqzTyCGrFDxrRmX1.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2024-11-27T22:26:37.000000Z",
                        "updated_at": "2024-11-27T22:26:37.000000Z",
                        "question_num_long": 640653820878,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "6e0bce493d190744da2519aac33db2f5",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "9a6e2a04-e51d-4cc9-bd25-402c946c37ed",
                        "question_image_url": [
                            "/question_images/OAZctfTHTKI9G1lvp0LsUP6MdD6nUsruJsZqzTyCGrFDxrRmX1.png"
                        ],
                        "question_texts": [
                            "  Based on the above data, answer the given subquestions."
                        ]
                    }
                },
                {
                    "id": 44889,
                    "exam_id": 3,
                    "question_paper_id": 151,
                    "question_number": 0,
                    "question_text_1": "  Based on the above data, answer the given subquestions.",
                    "question_image_1": "RjIEOfCFD8HwE9JTrAVmYTMu14mLekUczOOevGAczHnt5FGj5f.png",
                    "question_type": "COMPREHENSION",
                    "total_mark": "0.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:37.000000Z",
                    "updated_at": "2024-11-27T22:26:37.000000Z",
                    "question_num_long": 640653820867,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 0,
                    "hash": "711226bf61e73d512d0053dfb2e2ee1a",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "3ba1e1ac-f7bb-4059-a895-186917fd6048",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/RjIEOfCFD8HwE9JTrAVmYTMu14mLekUczOOevGAczHnt5FGj5f.png"
                    ],
                    "question_texts": [
                        "  Based on the above data, answer the given subquestions."
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 44890,
                    "exam_id": 3,
                    "question_paper_id": 151,
                    "question_number": 206,
                    "question_text_1": "Suppose the number of encoder layers N = 3. What is the total number of learnable parameters, including the parameters of the input and position embedding layers, in the model? Enter the final answer in thousands. For example, if the answer is 12,238, then enter 12 as the answer.",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "2566",
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:37.000000Z",
                    "updated_at": "2024-11-27T22:26:37.000000Z",
                    "question_num_long": 640653820868,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "d746f047571ccfe168bcb0a6966068bf",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 44889,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "9d7858a3-79e6-47e1-986a-43eddd4d4dd5",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Suppose the number of encoder layers N = 3. What is the total number of learnable parameters, including the parameters of the input and position embedding layers, in the model? Enter the final answer in thousands. For example, if the answer is 12,238, then enter 12 as the answer."
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": {
                        "id": 44889,
                        "exam_id": 3,
                        "question_paper_id": 151,
                        "question_number": 0,
                        "question_text_1": "  Based on the above data, answer the given subquestions.",
                        "question_image_1": "RjIEOfCFD8HwE9JTrAVmYTMu14mLekUczOOevGAczHnt5FGj5f.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2024-11-27T22:26:37.000000Z",
                        "updated_at": "2024-11-27T22:26:37.000000Z",
                        "question_num_long": 640653820867,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "711226bf61e73d512d0053dfb2e2ee1a",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "3ba1e1ac-f7bb-4059-a895-186917fd6048",
                        "question_image_url": [
                            "/question_images/RjIEOfCFD8HwE9JTrAVmYTMu14mLekUczOOevGAczHnt5FGj5f.png"
                        ],
                        "question_texts": [
                            "  Based on the above data, answer the given subquestions."
                        ]
                    }
                },
                {
                    "id": 44891,
                    "exam_id": 3,
                    "question_paper_id": 151,
                    "question_number": 207,
                    "question_text_1": "Suppose we increase the context length from T = 256 to T = 512 keeping number of layers same (N = 3). How many parameters does the model need to learn additionally compared to the previous setting?",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "3.00",
                    "value_start": "0",
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:37.000000Z",
                    "updated_at": "2024-11-27T22:26:37.000000Z",
                    "question_num_long": 640653820869,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "27ab2ee264aa09f00a8c213026d4fb47",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 44889,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "389e1d83-048c-4a59-ac28-c3ccbdde5936",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Suppose we increase the context length from T = 256 to T = 512 keeping number of layers same (N = 3). How many parameters does the model need to learn additionally compared to the previous setting?"
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": {
                        "id": 44889,
                        "exam_id": 3,
                        "question_paper_id": 151,
                        "question_number": 0,
                        "question_text_1": "  Based on the above data, answer the given subquestions.",
                        "question_image_1": "RjIEOfCFD8HwE9JTrAVmYTMu14mLekUczOOevGAczHnt5FGj5f.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2024-11-27T22:26:37.000000Z",
                        "updated_at": "2024-11-27T22:26:37.000000Z",
                        "question_num_long": 640653820867,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "711226bf61e73d512d0053dfb2e2ee1a",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "3ba1e1ac-f7bb-4059-a895-186917fd6048",
                        "question_image_url": [
                            "/question_images/RjIEOfCFD8HwE9JTrAVmYTMu14mLekUczOOevGAczHnt5FGj5f.png"
                        ],
                        "question_texts": [
                            "  Based on the above data, answer the given subquestions."
                        ]
                    }
                },
                {
                    "id": 44892,
                    "exam_id": 3,
                    "question_paper_id": 151,
                    "question_number": 0,
                    "question_text_1": null,
                    "question_image_1": "u3rLQu9sTWYzM7RDSLCKdgAujPaxGGnOE7sy5oybTfimf9jLZQ.png",
                    "question_type": "COMPREHENSION",
                    "total_mark": "0.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:37.000000Z",
                    "updated_at": "2024-11-27T22:26:37.000000Z",
                    "question_num_long": 640653820863,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 0,
                    "hash": "4eecb7797d55dfcb5f1858b9abe8d8c3",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "9772fc1e-3fef-4845-aabc-88012334b38a",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/u3rLQu9sTWYzM7RDSLCKdgAujPaxGGnOE7sy5oybTfimf9jLZQ.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 44893,
                    "exam_id": 3,
                    "question_paper_id": 151,
                    "question_number": 208,
                    "question_text_1": "Compute the representation for the word \u201ccoffee\u201d and enter the sum of the elements in it.",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "1.75",
                    "value_end": "1.95",
                    "created_at": "2024-11-27T22:26:37.000000Z",
                    "updated_at": "2024-11-27T22:26:37.000000Z",
                    "question_num_long": 640653820864,
                    "answer_type": "Range",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "94dbc5bde1764ddabf235f9a4db36e7a",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 44892,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "ef2a490c-31f1-4850-9065-845f6e653bb1",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Compute the representation for the word \u201ccoffee\u201d and enter the sum of the elements in it."
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": {
                        "id": 44892,
                        "exam_id": 3,
                        "question_paper_id": 151,
                        "question_number": 0,
                        "question_text_1": null,
                        "question_image_1": "u3rLQu9sTWYzM7RDSLCKdgAujPaxGGnOE7sy5oybTfimf9jLZQ.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2024-11-27T22:26:37.000000Z",
                        "updated_at": "2024-11-27T22:26:37.000000Z",
                        "question_num_long": 640653820863,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "4eecb7797d55dfcb5f1858b9abe8d8c3",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "9772fc1e-3fef-4845-aabc-88012334b38a",
                        "question_image_url": [
                            "/question_images/u3rLQu9sTWYzM7RDSLCKdgAujPaxGGnOE7sy5oybTfimf9jLZQ.png"
                        ],
                        "question_texts": null
                    }
                },
                {
                    "id": 44894,
                    "exam_id": 3,
                    "question_paper_id": 151,
                    "question_number": 209,
                    "question_text_1": "Suppose the input sentence is \u201ccoffee i like much\u201c. What is the attention score between the word \u201ccoffee\u201d with \u201cmuch\u201d?",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "0.53",
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:37.000000Z",
                    "updated_at": "2024-11-27T22:26:37.000000Z",
                    "question_num_long": 640653820865,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "ce25408ee63558fbfeb68aa138992425",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 44892,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "a1a052fd-40c1-4515-b2d1-04842e71842d",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Suppose the input sentence is \u201ccoffee i like much\u201c. What is the attention score between the word \u201ccoffee\u201d with \u201cmuch\u201d?"
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": {
                        "id": 44892,
                        "exam_id": 3,
                        "question_paper_id": 151,
                        "question_number": 0,
                        "question_text_1": null,
                        "question_image_1": "u3rLQu9sTWYzM7RDSLCKdgAujPaxGGnOE7sy5oybTfimf9jLZQ.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2024-11-27T22:26:37.000000Z",
                        "updated_at": "2024-11-27T22:26:37.000000Z",
                        "question_num_long": 640653820863,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "4eecb7797d55dfcb5f1858b9abe8d8c3",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "9772fc1e-3fef-4845-aabc-88012334b38a",
                        "question_image_url": [
                            "/question_images/u3rLQu9sTWYzM7RDSLCKdgAujPaxGGnOE7sy5oybTfimf9jLZQ.png"
                        ],
                        "question_texts": null
                    }
                },
                {
                    "id": 44895,
                    "exam_id": 3,
                    "question_paper_id": 151,
                    "question_number": 0,
                    "question_text_1": "  Based on the above data, answer the given subquestions.",
                    "question_image_1": "uCUjXBzpf51ra7nD3SzYSgD4lR9uV2h21CTI9sBjKPVH2FWO01.png",
                    "question_type": "COMPREHENSION",
                    "total_mark": "0.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:37.000000Z",
                    "updated_at": "2024-11-27T22:26:37.000000Z",
                    "question_num_long": 640653820870,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 0,
                    "hash": "609839dac457989e3aada16522215fc1",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "bf68977a-d8fd-4eb1-a0cd-d93dfeb3d997",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/uCUjXBzpf51ra7nD3SzYSgD4lR9uV2h21CTI9sBjKPVH2FWO01.png"
                    ],
                    "question_texts": [
                        "  Based on the above data, answer the given subquestions."
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 44896,
                    "exam_id": 3,
                    "question_paper_id": 151,
                    "question_number": 210,
                    "question_text_1": "What is the input sequence length that would have generated this matrix?",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "3.00",
                    "value_start": "8",
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:37.000000Z",
                    "updated_at": "2024-11-27T22:26:37.000000Z",
                    "question_num_long": 640653820871,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "555e23d305f47b9a246569ad152e366f",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 44895,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "c7ee52da-8ae4-4f81-9abb-5c489dc766cb",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "What is the input sequence length that would have generated this matrix?"
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": {
                        "id": 44895,
                        "exam_id": 3,
                        "question_paper_id": 151,
                        "question_number": 0,
                        "question_text_1": "  Based on the above data, answer the given subquestions.",
                        "question_image_1": "uCUjXBzpf51ra7nD3SzYSgD4lR9uV2h21CTI9sBjKPVH2FWO01.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2024-11-27T22:26:37.000000Z",
                        "updated_at": "2024-11-27T22:26:37.000000Z",
                        "question_num_long": 640653820870,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "609839dac457989e3aada16522215fc1",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "bf68977a-d8fd-4eb1-a0cd-d93dfeb3d997",
                        "question_image_url": [
                            "/question_images/uCUjXBzpf51ra7nD3SzYSgD4lR9uV2h21CTI9sBjKPVH2FWO01.png"
                        ],
                        "question_texts": [
                            "  Based on the above data, answer the given subquestions."
                        ]
                    }
                },
                {
                    "id": 44897,
                    "exam_id": 3,
                    "question_paper_id": 151,
                    "question_number": 211,
                    "question_text_1": null,
                    "question_image_1": "eVkHFQnww3jCXHqlmPRVqpAcE1gpy92NEE1rpKuj3wqcy1CvX2.png",
                    "question_type": "MSQ",
                    "total_mark": "4.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:37.000000Z",
                    "updated_at": "2024-11-27T22:26:37.000000Z",
                    "question_num_long": 640653820872,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "bd31f4453e113744c5fa1d92f320d3bd",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 44895,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "3ecf0765-959d-410d-b5be-a4fada12f07d",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/eVkHFQnww3jCXHqlmPRVqpAcE1gpy92NEE1rpKuj3wqcy1CvX2.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [
                        {
                            "id": 119723,
                            "question_id": 44897,
                            "option_text": "(8,8)",
                            "option_image": "",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:37.000000Z",
                            "updated_at": "2024-11-27T22:26:37.000000Z",
                            "option_number": 6406532755218,
                            "option_image_url": null
                        },
                        {
                            "id": 119724,
                            "question_id": 44897,
                            "option_text": "(64,64)",
                            "option_image": "",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:37.000000Z",
                            "updated_at": "2024-11-27T22:26:37.000000Z",
                            "option_number": 6406532755219,
                            "option_image_url": null
                        },
                        {
                            "id": 119725,
                            "question_id": 44897,
                            "option_text": "(32,32)",
                            "option_image": "",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:37.000000Z",
                            "updated_at": "2024-11-27T22:26:37.000000Z",
                            "option_number": 6406532755220,
                            "option_image_url": null
                        },
                        {
                            "id": 119726,
                            "question_id": 44897,
                            "option_text": "(16,16)",
                            "option_image": "",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:37.000000Z",
                            "updated_at": "2024-11-27T22:26:37.000000Z",
                            "option_number": 6406532755221,
                            "option_image_url": null
                        },
                        {
                            "id": 119727,
                            "question_id": 44897,
                            "option_text": "(8,16)",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:37.000000Z",
                            "updated_at": "2024-11-27T22:26:37.000000Z",
                            "option_number": 6406532755222,
                            "option_image_url": null
                        },
                        {
                            "id": 119728,
                            "question_id": 44897,
                            "option_text": "(16,8)",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:37.000000Z",
                            "updated_at": "2024-11-27T22:26:37.000000Z",
                            "option_number": 6406532755223,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": {
                        "id": 44895,
                        "exam_id": 3,
                        "question_paper_id": 151,
                        "question_number": 0,
                        "question_text_1": "  Based on the above data, answer the given subquestions.",
                        "question_image_1": "uCUjXBzpf51ra7nD3SzYSgD4lR9uV2h21CTI9sBjKPVH2FWO01.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2024-11-27T22:26:37.000000Z",
                        "updated_at": "2024-11-27T22:26:37.000000Z",
                        "question_num_long": 640653820870,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "609839dac457989e3aada16522215fc1",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "bf68977a-d8fd-4eb1-a0cd-d93dfeb3d997",
                        "question_image_url": [
                            "/question_images/uCUjXBzpf51ra7nD3SzYSgD4lR9uV2h21CTI9sBjKPVH2FWO01.png"
                        ],
                        "question_texts": [
                            "  Based on the above data, answer the given subquestions."
                        ]
                    }
                },
                {
                    "id": 44898,
                    "exam_id": 3,
                    "question_paper_id": 151,
                    "question_number": 212,
                    "question_text_1": null,
                    "question_image_1": "3mps3jtJsQUI1vvq6vmrm6NDdXNGv4GaIR7rt2PGVveyQIYXJN.png",
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "3",
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:37.000000Z",
                    "updated_at": "2024-11-27T22:26:37.000000Z",
                    "question_num_long": 640653820873,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "56e79ba0efb0d72727191608a57b5f6a",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 44895,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "03e85949-cd38-4844-b365-6b6295ebf183",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/3mps3jtJsQUI1vvq6vmrm6NDdXNGv4GaIR7rt2PGVveyQIYXJN.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": {
                        "id": 44895,
                        "exam_id": 3,
                        "question_paper_id": 151,
                        "question_number": 0,
                        "question_text_1": "  Based on the above data, answer the given subquestions.",
                        "question_image_1": "uCUjXBzpf51ra7nD3SzYSgD4lR9uV2h21CTI9sBjKPVH2FWO01.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2024-11-27T22:26:37.000000Z",
                        "updated_at": "2024-11-27T22:26:37.000000Z",
                        "question_num_long": 640653820870,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "609839dac457989e3aada16522215fc1",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "bf68977a-d8fd-4eb1-a0cd-d93dfeb3d997",
                        "question_image_url": [
                            "/question_images/uCUjXBzpf51ra7nD3SzYSgD4lR9uV2h21CTI9sBjKPVH2FWO01.png"
                        ],
                        "question_texts": [
                            "  Based on the above data, answer the given subquestions."
                        ]
                    }
                }
            ]
        },
        "summary": "Here\u2019s a structured **summary of core topics, concepts, principles, and equations** for the exam on **\"Introduction to Large Language Models (LLMs)\"**, along with **Mermaid knowledge graphs** to visualize relationships.\n\n---\n\n## **1. Core Topics & Concepts**\n### **A. Foundations of LLMs**\n1. **Transformer Architecture**\n   - **Self-Attention Mechanism**:\n     - Computes attention scores as:\n       \\[\n       \\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\n       \\]\n     - **Query (Q)**, **Key (K)**, **Value (V)** matrices are derived from input embeddings via learned weights \\(W_Q, W_K, W_V\\).\n     - **Multi-Head Attention**: Splits \\(Q, K, V\\) into \\(h\\) heads, computes attention in parallel, then concatenates and projects:\n       \\[\n       \\text{MultiHead}(Q, K, V) = \\text{Concat}(\\text{head}_1, ..., \\text{head}_h)W_O\n       \\]\n   - **Positional Encoding**:\n     - **Absolute Position Embedding (APE)**: Fixed (sinusoidal) or learnable embeddings added to token embeddings.\n     - **Relative Position Embedding**: Injects position info into attention scores (e.g., via bias terms in \\(QK^T\\)).\n   - **Feed-Forward Network (FFN)**:\n     - Typically a 2-layer MLP with ReLU/GELU activation:\n       \\[\n       \\text{FFN}(x) = W_2 \\cdot \\text{ReLU}(W_1 x + b_1) + b_2\n       \\]\n   - **Layer Normalization & Residual Connections**:\n     - Normalizes activations and adds input to output (residual connection) for stable training.\n\n2. **BERT vs. GPT**\n   - **BERT (Bidirectional Encoder Representations from Transformers)**:\n     - **Masked Language Modeling (MLM)**: Randomly masks tokens and predicts them.\n     - **Next Sentence Prediction (NSP)**: Predicts if two sentences are consecutive.\n     - **Bidirectional**: Attends to left and right context.\n   - **GPT (Generative Pre-trained Transformer)**:\n     - **Causal Language Modeling (CLM)**: Predicts next token autoregressively.\n     - **Unidirectional**: Attends only to left context (upper-triangular attention mask).\n\n3. **Tokenization**\n   - **Byte Pair Encoding (BPE)**:\n     - Starts with characters, iteratively merges frequent pairs into new tokens.\n     - Example: `\"SomeThing\"` \u2192 `[\"Some\", \"Th\", \"ing\"]` (6 tokens in the given vocab).\n   - **WordPiece**: Similar to BPE but uses likelihood-based merging.\n   - **SentencePiece**: Treats text as raw bytes (no pre-tokenization).\n\n4. **Decoding Strategies**\n   - **Greedy Search**: Picks the most probable token at each step.\n   - **Beam Search**: Keeps top-\\(k\\) sequences (beam size \\(k\\)) and expands them.\n   - **Sampling Methods**:\n     - **Top-\\(k\\) Sampling**: Samples from top-\\(k\\) probable tokens.\n     - **Top-\\(p\\) (Nucleus) Sampling**: Samples from the smallest set of tokens whose cumulative probability \u2265 \\(p\\).\n     - **Temperature Scaling**: Sharpens/flattens softmax probabilities:\n       \\[\n       p_i = \\frac{\\exp(z_i / T)}{\\sum_j \\exp(z_j / T)}\n       \\]\n       where \\(T\\) is temperature (\\(T < 1\\) sharpens, \\(T > 1\\) flattens).\n\n---\n\n### **B. Attention Mechanisms**\n1. **Sparse Attention**\n   - **Block-Sparse Attention**: Restricts attention to local blocks (e.g., 4 identity blocks in \\(M\\)).\n     - **Complexity**: If \\(M\\) has \\(b\\) blocks of size \\(T/b\\), complexity is \\(O(T^2 / b)\\).\n     - In Q5, since \\(M\\) has 4 identity blocks, complexity remains \\(O(T^2)\\) (no sparsity gain unless \\(M\\) is structured to reduce computations).\n\n2. **Causal Masking (for GPT)**\n   - Upper-triangular mask in \\(QK^T\\) to prevent attending to future tokens.\n\n3. **Attention Matrix Analysis**\n   - Given \\(QK^T\\), apply **softmax** to get attention weights:\n     \\[\n     A_{ij} = \\frac{\\exp(QK^T_{ij})}{\\sum_k \\exp(QK^T_{ik})}\n     \\]\n   - Example (Q14): Attention score between \"coffee\" (query) and \"much\" (key) is **0.53** (from the given \\(A\\) matrix).\n\n---\n\n### **C. Model Parameters & Complexity**\n1. **Parameter Count in Transformers**\n   - **Embedding Layer**:\n     - Token embeddings: \\(|\\mathcal{V}| \\times d_{\\text{model}}\\).\n     - Position embeddings: \\(T \\times d_{\\text{model}}\\) (if learnable; fixed sinusoidal has 0 parameters).\n   - **Attention Layer (per head)**:\n     - \\(W_Q, W_K, W_V\\): Each is \\(d_{\\text{model}} \\times d_q\\) (or \\(d_k, d_v\\)).\n     - \\(W_O\\): \\(d_v \\times d_{\\text{model}}\\).\n   - **FFN Layer**:\n     - \\(W_1\\): \\(d_{\\text{model}} \\times d_{\\text{ff}}\\).\n     - \\(W_2\\): \\(d_{\\text{ff}} \\times d_{\\text{model}}\\).\n   - **Total Parameters (Q11)**:\n     - For \\(N=3\\) layers, \\(T=256\\), \\(d_{\\text{model}}=256\\), \\(d_{\\text{ff}}=1024\\), \\(n_h=8\\), \\(d_q=d_k=d_v=32\\):\n       - **Attention**: \\(3 \\times 8 \\times (256 \\times 32 \\times 2 + 32 \\times 256) = 3 \\times 8 \\times (16,384 + 8,192) = 3 \\times 8 \\times 24,576 = 589,824\\).\n       - **FFN**: \\(3 \\times (256 \\times 1024 + 1024 \\times 256) = 3 \\times (262,144 + 262,144) = 1,572,864\\).\n       - **Embeddings**: \\(|\\mathcal{V}| \\times 256 + 256 \\times 256\\) (assuming \\(|\\mathcal{V}| = 10,000\\) \u2192 \\(2,560,000 + 65,536 = 2,625,536\\)).\n       - **Total**: ~4.8M parameters (but Q11 answer is **2,566K**, suggesting \\(|\\mathcal{V}|\\) is smaller or shared embeddings reduce count).\n\n2. **Impact of Context Length**\n   - Increasing \\(T\\) from 256 to 512 **does not change parameter count** if using **fixed sinusoidal positional embeddings** (Q12 answer: **0**).\n   - If using **learnable positional embeddings**, additional parameters = \\((512 - 256) \\times d_{\\text{model}} = 256 \\times 256 = 65,536\\).\n\n---\n\n### **D. Inference & Generation**\n1. **Greedy Decoding (Q6, Q8)**\n   - At each step, select the token with the highest probability.\n   - Example (Q6): Given \\(\\hat{Y}\\) and vocabulary \\(\\mathcal{V}\\), the generated sequence is:\n     ```\n     [start] something somewhere incredible is waiting be [end]\n     ```\n   - **Deterministic**: Always produces the same output for the same input (Q8: **Greedy decoding** or **Beam search with \\(K > 2\\)**).\n\n2. **Input/Output Length Constraints (Q7)**\n   - For a model with context length \\(T = 1024\\):\n     - Input tokens = 712 \u2192 Max output tokens = \\(1024 - 712 = 312\\).\n     - Possible summary lengths: **256** or **16** (but not 1024 or 512, as they exceed \\(T\\)).\n\n---\n\n### **E. Key Equations**\n| **Component**               | **Equation**                                                                 |\n|-----------------------------|------------------------------------------------------------------------------|\n| Self-Attention              | \\( \\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V \\) |\n| Multi-Head Attention        | \\( \\text{MultiHead}(Q, K, V) = \\text{Concat}(\\text{head}_1, ..., \\text{head}_h)W_O \\) |\n| Positional Encoding (Fixed) | \\( PE_{(pos, 2i)} = \\sin(pos / 10000^{2i/d_{\\text{model}}}) \\)             |\n| FFN                         | \\( \\text{FFN}(x) = W_2 \\cdot \\text{ReLU}(W_1 x + b_1) + b_2 \\)             |\n| Softmax                     | \\( \\text{softmax}(x_i) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)} \\)              |\n| Temperature Scaling         | \\( p_i = \\frac{\\exp(z_i / T)}{\\sum_j \\exp(z_j / T)} \\)                      |\n\n---\n\n## **2. Mermaid Knowledge Graphs**\n### **Graph 1: Transformer Architecture Overview**\n```mermaid\ngraph TD\n    A[Input Tokens] --> B[Token Embeddings]\n    A --> C[Position Embeddings]\n    B --> D[Sum]\n    C --> D\n    D --> E[Multi-Head Attention]\n    E --> F[Add & Norm]\n    F --> G[Feed-Forward Network]\n    G --> H[Add & Norm]\n    H --> I[Output]\n    E -.-> J[Query/Key/Value Projections]\n    G -.-> K[FFN Weights]\n```\n\n### **Graph 2: Decoding Strategies**\n```mermaid\ngraph TD\n    A[Model Output Probabilities] --> B[Greedy Search]\n    A --> C[Beam Search]\n    A --> D[Top-k Sampling]\n    A --> E[Top-p Sampling]\n    B --> F[Deterministic]\n    C --> F\n    D --> G[Stochastic]\n    E --> G\n```\n\n### **Graph 3: BPE Tokenization**\n```mermaid\ngraph LR\n    A[Raw Text: \"SomeThing\"] --> B[Pre-tokenization: \"Some\", \"Thing\"]\n    B --> C[BPE Merges: \"Th\", \"ing\"]\n    C --> D[Final Tokens: \"Some\", \"Th\", \"ing\"]\n```\n\n### **Graph 4: Attention Mechanisms**\n```mermaid\ngraph TD\n    A[Full Attention] --> B[O(T\u00b2)]\n    A --> C[Block-Sparse Attention]\n    C --> D[O(T\u00b2 / b)]\n    A --> E[Causal Masking]\n    E --> F[Upper-Triangular]\n```\n\n### **Graph 5: BERT vs. GPT**\n```mermaid\ngraph LR\n    A[BERT] --> B[Bidirectional]\n    A --> C[Masked LM]\n    D[GPT] --> E[Unidirectional]\n    D --> F[Causal LM]\n```",
        "total_score": "50.00"
    },
    "url": "/question-paper/practise/85/2e0a2dd1-27a",
    "version": "ee3d5d44299e610bd137ea6200db5ac2"
}