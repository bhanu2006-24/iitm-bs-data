{
    "component": "Quizpractise/PractiseQuestionPaper",
    "props": {
        "errors": {},
        "auth": {
            "user": null
        },
        "flash": {
            "error": []
        },
        "banner": null,
        "file_url": "https://saram.blr1.cdn.digitaloceanspaces.com",
        "file_do_url": "https://saram.blr1.cdn.digitaloceanspaces.com",
        "question_paper": {
            "id": 386,
            "group_id": 32,
            "exam_id": 3,
            "total_score": "1.00",
            "duration": 4,
            "created_at": "2025-12-13T07:03:35.000000Z",
            "updated_at": "2025-12-13T07:03:35.000000Z",
            "question_paper_name": "IIT M DEGREE AN EXAM QDB4 31 Aug 2025",
            "question_paper_description": "2025 Aug31: IIT M AN EXAM QDB4",
            "uuid": "ff60a8af-cf5",
            "year": 2025,
            "is_new": 0,
            "exam": {
                "id": 3,
                "exam_name": "End Term Quiz",
                "created_at": "2024-10-16T08:08:51.000000Z",
                "updated_at": "2024-10-16T08:08:51.000000Z",
                "uuid": "7a6ff569-f50c-40e7-a08b-f5c334392600",
                "en_id": "eyJpdiI6Ik41TVdVeUZHaEJldk51QmtWNnRuT2c9PSIsInZhbHVlIjoiNVJGOCszQjlpV3ZsMktISEwvK0dkZz09IiwibWFjIjoiMmQ0ZDNiMjA2NjkxYTc4YTljY2IwMTA3MzhhYWEwNjQwNTZmYTUwNWFjYzg3OGQzMzU3MGMyOTE5OGVjZGYwNCIsInRhZyI6IiJ9"
            },
            "questions": [
                {
                    "id": 119517,
                    "exam_id": 3,
                    "question_paper_id": 386,
                    "question_number": 191,
                    "question_text_1": "THIS IS QUESTION PAPER FOR THE SUBJECT <b>\"DEGREE LEVEL : LARGE LANGUAGE MODELS </b><b>(COMPUTER BASED EXAM)\"</b><b> </b><b> </b><b>ARE YOU SURE YOU HAVE TO WRITE EXAM FOR THIS SUBJECT? </b><b>CROSS CHECK YOUR HALL TICKET TO CONFIRM THE SUBJECTS TO BE WRITTEN. </b><b> </b><b>(IF IT IS NOT THE CORRECT SUBJECT, PLS CHECK THE SECTION AT THE TOP FOR THE SUBJECTS </b><b>REGISTERED BY YOU)</b>",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "0.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-12-13T07:03:37.000000Z",
                    "updated_at": "2025-12-13T07:03:37.000000Z",
                    "question_num_long": 6406531428295,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "f20032763ea41ee131ac7aa4a0744b64",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "69c220dc-13f1-43de-920b-fd1e158c8186",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "THIS IS QUESTION PAPER FOR THE SUBJECT <b>\"DEGREE LEVEL : LARGE LANGUAGE MODELS </b><b>(COMPUTER BASED EXAM)\"</b><b> </b><b> </b><b>ARE YOU SURE YOU HAVE TO WRITE EXAM FOR THIS SUBJECT? </b><b>CROSS CHECK YOUR HALL TICKET TO CONFIRM THE SUBJECTS TO BE WRITTEN. </b><b> </b><b>(IF IT IS NOT THE CORRECT SUBJECT, PLS CHECK THE SECTION AT THE TOP FOR THE SUBJECTS </b><b>REGISTERED BY YOU)</b>"
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [
                        {
                            "id": 312244,
                            "question_id": 119517,
                            "option_text": "YES",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 1,
                            "created_at": "2025-12-13T07:03:37.000000Z",
                            "updated_at": "2025-12-13T07:03:37.000000Z",
                            "option_number": 6406534772066,
                            "option_image_url": null
                        },
                        {
                            "id": 312245,
                            "question_id": 119517,
                            "option_text": "NO",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:03:37.000000Z",
                            "updated_at": "2025-12-13T07:03:37.000000Z",
                            "option_number": 6406534772067,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 119518,
                    "exam_id": 3,
                    "question_paper_id": 386,
                    "question_number": 192,
                    "question_text_1": null,
                    "question_image_1": "8zdWelqQBPnrS3sIs41wMqNkxMl4VueJ2rklgfia8N29HcJPtb.png",
                    "question_type": "MCQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-12-13T07:03:37.000000Z",
                    "updated_at": "2025-12-13T07:03:37.000000Z",
                    "question_num_long": 6406531428296,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "45b1648bc6d8deb9b91ba40e648ba398",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "cad71977-57e8-4b2a-bc3b-67f901ebe940",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/8zdWelqQBPnrS3sIs41wMqNkxMl4VueJ2rklgfia8N29HcJPtb.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [
                        {
                            "id": 312246,
                            "question_id": 119518,
                            "option_text": "",
                            "option_image": "FTxn8BsjwI7tvB611iGNPG8qgz5zoa0po0RsIVTr8I099UIHJ8.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:03:37.000000Z",
                            "updated_at": "2025-12-13T07:03:37.000000Z",
                            "option_number": 6406534772068,
                            "option_image_url": "app/option_images/FTxn8BsjwI7tvB611iGNPG8qgz5zoa0po0RsIVTr8I099UIHJ8.png"
                        },
                        {
                            "id": 312247,
                            "question_id": 119518,
                            "option_text": "",
                            "option_image": "bCkkT5mZgQ0BQVRAQ4hfTXSX8QC2cpFUNcLk3GZm2YLotKV9SF.png",
                            "score": "3.000",
                            "is_correct": 1,
                            "created_at": "2025-12-13T07:03:37.000000Z",
                            "updated_at": "2025-12-13T07:03:37.000000Z",
                            "option_number": 6406534772069,
                            "option_image_url": "app/option_images/bCkkT5mZgQ0BQVRAQ4hfTXSX8QC2cpFUNcLk3GZm2YLotKV9SF.png"
                        },
                        {
                            "id": 312248,
                            "question_id": 119518,
                            "option_text": "",
                            "option_image": "I6q4ZCbazji1VTheMi1cFwivbZRsYcAmU9Gacl5svhNloF5aay.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:03:37.000000Z",
                            "updated_at": "2025-12-13T07:03:37.000000Z",
                            "option_number": 6406534772070,
                            "option_image_url": "app/option_images/I6q4ZCbazji1VTheMi1cFwivbZRsYcAmU9Gacl5svhNloF5aay.png"
                        },
                        {
                            "id": 312249,
                            "question_id": 119518,
                            "option_text": "",
                            "option_image": "0gF4YW0HtEuqeInD2xJ5J07yZskuOrb184UtypFoam1MWoRmGd.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:03:37.000000Z",
                            "updated_at": "2025-12-13T07:03:37.000000Z",
                            "option_number": 6406534772071,
                            "option_image_url": "app/option_images/0gF4YW0HtEuqeInD2xJ5J07yZskuOrb184UtypFoam1MWoRmGd.png"
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 119519,
                    "exam_id": 3,
                    "question_paper_id": 386,
                    "question_number": 193,
                    "question_text_1": "A GPT model is trained using <b>causal language modeling</b>. During training, for a sequence of T = 4 tokens, which of the following correctly represents the <b>attention mask matrix</b> applied to the attention logits?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-12-13T07:03:37.000000Z",
                    "updated_at": "2025-12-13T07:03:37.000000Z",
                    "question_num_long": 6406531428297,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "e0071b8f5f7f1da79d04c5943af06e17",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "77221d07-dd3c-43d2-8ba2-2a679c9881ef",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "A GPT model is trained using <b>causal language modeling</b>. During training, for a sequence of T = 4 tokens, which of the following correctly represents the <b>attention mask matrix</b> applied to the attention logits?"
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [
                        {
                            "id": 312250,
                            "question_id": 119519,
                            "option_text": "",
                            "option_image": "qYmKMJjXvAa4aUujPA7GLFK9kkw6zbkvNWBx5xse8AqHupmZbQ.png",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-12-13T07:03:37.000000Z",
                            "updated_at": "2025-12-13T07:03:37.000000Z",
                            "option_number": 6406534772072,
                            "option_image_url": "app/option_images/qYmKMJjXvAa4aUujPA7GLFK9kkw6zbkvNWBx5xse8AqHupmZbQ.png"
                        },
                        {
                            "id": 312251,
                            "question_id": 119519,
                            "option_text": "",
                            "option_image": "pDWI5Q74Jh9QUOt2PhKwCDDU3sCoNtOA5JzKdybeY9qD593Tam.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:03:37.000000Z",
                            "updated_at": "2025-12-13T07:03:37.000000Z",
                            "option_number": 6406534772073,
                            "option_image_url": "app/option_images/pDWI5Q74Jh9QUOt2PhKwCDDU3sCoNtOA5JzKdybeY9qD593Tam.png"
                        },
                        {
                            "id": 312252,
                            "question_id": 119519,
                            "option_text": "",
                            "option_image": "mVBRPhsYZpCpzvw1UvombTHzIFgzHVMqmBRUM7er5unrG4H8fy.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:03:37.000000Z",
                            "updated_at": "2025-12-13T07:03:37.000000Z",
                            "option_number": 6406534772074,
                            "option_image_url": "app/option_images/mVBRPhsYZpCpzvw1UvombTHzIFgzHVMqmBRUM7er5unrG4H8fy.png"
                        },
                        {
                            "id": 312253,
                            "question_id": 119519,
                            "option_text": "",
                            "option_image": "VGeSizBo6HN4tXN2QLlDLTIhOry6tfEjcjpyHmuReWplscjzyY.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:03:37.000000Z",
                            "updated_at": "2025-12-13T07:03:37.000000Z",
                            "option_number": 6406534772075,
                            "option_image_url": "app/option_images/VGeSizBo6HN4tXN2QLlDLTIhOry6tfEjcjpyHmuReWplscjzyY.png"
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 119520,
                    "exam_id": 3,
                    "question_paper_id": 386,
                    "question_number": 194,
                    "question_text_1": null,
                    "question_image_1": "s5XAGUMR4ZKrQ2NiLnYqvh6PmO5jew9OwOtH0KOddKNVB9Czfg.png",
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-12-13T07:03:37.000000Z",
                    "updated_at": "2025-12-13T07:03:37.000000Z",
                    "question_num_long": 6406531428298,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "3750500918ee1f7513ef8f549367979e",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "b31fde03-e72d-45f5-aa0a-cc0d93eb9860",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/s5XAGUMR4ZKrQ2NiLnYqvh6PmO5jew9OwOtH0KOddKNVB9Czfg.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [
                        {
                            "id": 312254,
                            "question_id": 119520,
                            "option_text": "(a) : Random Local Attention,(b) : Strided Local Attention, (c) : Sparse Block Attention, (d) : Local + Global Attention",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:03:37.000000Z",
                            "updated_at": "2025-12-13T07:03:37.000000Z",
                            "option_number": 6406534772076,
                            "option_image_url": null
                        },
                        {
                            "id": 312255,
                            "question_id": 119520,
                            "option_text": "(a) : Strided Local Attention,(b) : Local + Global Attention, (c) : Random Local Attention, (d) : Sparse Block Attention",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-12-13T07:03:37.000000Z",
                            "updated_at": "2025-12-13T07:03:37.000000Z",
                            "option_number": 6406534772077,
                            "option_image_url": null
                        },
                        {
                            "id": 312256,
                            "question_id": 119520,
                            "option_text": "(a) : Strided Local Attention,(b) : Random Local Attention, (c) : Local + Global Attention, (d) : Sparse Block Attention",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:03:37.000000Z",
                            "updated_at": "2025-12-13T07:03:37.000000Z",
                            "option_number": 6406534772078,
                            "option_image_url": null
                        },
                        {
                            "id": 312257,
                            "question_id": 119520,
                            "option_text": "(a) : Sparse Block Attention,(b) : Local + Global Attention, (c) : Strided Local Attention, (d) : Random Local Attention",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:03:37.000000Z",
                            "updated_at": "2025-12-13T07:03:37.000000Z",
                            "option_number": 6406534772079,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 119521,
                    "exam_id": 3,
                    "question_paper_id": 386,
                    "question_number": 195,
                    "question_text_1": "Which of the following preprocessing steps are commonly used when preparing data for transformer models like BERT?",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-12-13T07:03:37.000000Z",
                    "updated_at": "2025-12-13T07:03:37.000000Z",
                    "question_num_long": 6406531428299,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "7abb8df20ad9af1d894c87f982abfa2c",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "0a1ee4ab-b4ae-4b41-889d-b72e50f420a5",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following preprocessing steps are commonly used when preparing data for transformer models like BERT?"
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [
                        {
                            "id": 312258,
                            "question_id": 119521,
                            "option_text": "Adding special tokens such as [CLS] and [SEP] to the sequence",
                            "option_image": "",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2025-12-13T07:03:37.000000Z",
                            "updated_at": "2025-12-13T07:03:37.000000Z",
                            "option_number": 6406534772080,
                            "option_image_url": null
                        },
                        {
                            "id": 312259,
                            "question_id": 119521,
                            "option_text": "Splitting tokens into subword units using a model-specific tokenizer",
                            "option_image": "",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2025-12-13T07:03:37.000000Z",
                            "updated_at": "2025-12-13T07:03:37.000000Z",
                            "option_number": 6406534772081,
                            "option_image_url": null
                        },
                        {
                            "id": 312260,
                            "question_id": 119521,
                            "option_text": "Removing all punctuation marks to ensure cleaner embeddings",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:03:37.000000Z",
                            "updated_at": "2025-12-13T07:03:37.000000Z",
                            "option_number": 6406534772082,
                            "option_image_url": null
                        },
                        {
                            "id": 312261,
                            "question_id": 119521,
                            "option_text": "Adding positional information to each token embedding",
                            "option_image": "",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2025-12-13T07:03:37.000000Z",
                            "updated_at": "2025-12-13T07:03:37.000000Z",
                            "option_number": 6406534772083,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 119522,
                    "exam_id": 3,
                    "question_paper_id": 386,
                    "question_number": 196,
                    "question_text_1": "Which modifications are used in transformers to handle longer sequences efficiently?",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-12-13T07:03:37.000000Z",
                    "updated_at": "2025-12-13T07:03:37.000000Z",
                    "question_num_long": 6406531428300,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "493d0f8802d547ddd38c1b30dcfe8c66",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "ac3dfac6-e1f9-48ef-969a-a4dd6d878d23",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which modifications are used in transformers to handle longer sequences efficiently?"
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [
                        {
                            "id": 312262,
                            "question_id": 119522,
                            "option_text": "Using sparse attention patterns to reduce computational complexity",
                            "option_image": "",
                            "score": "1.500",
                            "is_correct": 1,
                            "created_at": "2025-12-13T07:03:37.000000Z",
                            "updated_at": "2025-12-13T07:03:37.000000Z",
                            "option_number": 6406534772084,
                            "option_image_url": null
                        },
                        {
                            "id": 312263,
                            "question_id": 119522,
                            "option_text": "Applying low-rank matrix factorization to approximate attention",
                            "option_image": "",
                            "score": "1.500",
                            "is_correct": 1,
                            "created_at": "2025-12-13T07:03:37.000000Z",
                            "updated_at": "2025-12-13T07:03:37.000000Z",
                            "option_number": 6406534772085,
                            "option_image_url": null
                        },
                        {
                            "id": 312264,
                            "question_id": 119522,
                            "option_text": "Increasing only the feed-forward network width without modifying attention",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:03:37.000000Z",
                            "updated_at": "2025-12-13T07:03:37.000000Z",
                            "option_number": 6406534772086,
                            "option_image_url": null
                        },
                        {
                            "id": 312265,
                            "question_id": 119522,
                            "option_text": "Replacing the softmax function in attention with other activation function forfaster training",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:03:37.000000Z",
                            "updated_at": "2025-12-13T07:03:37.000000Z",
                            "option_number": 6406534772087,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 119523,
                    "exam_id": 3,
                    "question_paper_id": 386,
                    "question_number": 197,
                    "question_text_1": "In Transformer models that use relative position embeddings (such as in Transformer-XL or T5), clipping is often applied to the relative position indices. Which of the following statements about clipping in relative position embeddings are correct?",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-12-13T07:03:37.000000Z",
                    "updated_at": "2025-12-13T07:03:37.000000Z",
                    "question_num_long": 6406531428301,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "f7dcca89b1831275cc0c1cb76178599f",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "a399a77c-c807-459e-8e64-1cb1b8351384",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "In Transformer models that use relative position embeddings (such as in Transformer-XL or T5), clipping is often applied to the relative position indices. Which of the following statements about clipping in relative position embeddings are correct?"
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [
                        {
                            "id": 312266,
                            "question_id": 119523,
                            "option_text": "Clipping ensures that very large relative distances are mapped to a fixedmaximum distance.",
                            "option_image": "",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2025-12-13T07:03:37.000000Z",
                            "updated_at": "2025-12-13T07:03:37.000000Z",
                            "option_number": 6406534772088,
                            "option_image_url": null
                        },
                        {
                            "id": 312267,
                            "question_id": 119523,
                            "option_text": "Without clipping, the model would require embeddings for every possiblerelative distance, which is infeasible for long sequences.",
                            "option_image": "",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2025-12-13T07:03:37.000000Z",
                            "updated_at": "2025-12-13T07:03:37.000000Z",
                            "option_number": 6406534772089,
                            "option_image_url": null
                        },
                        {
                            "id": 312268,
                            "question_id": 119523,
                            "option_text": "Clipping increases the precision of embeddings for large relative distances.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:03:37.000000Z",
                            "updated_at": "2025-12-13T07:03:37.000000Z",
                            "option_number": 6406534772090,
                            "option_image_url": null
                        },
                        {
                            "id": 312269,
                            "question_id": 119523,
                            "option_text": "Clipping introduces an upper bound k such that all distances greater than kare mapped to the same index.",
                            "option_image": "",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2025-12-13T07:03:37.000000Z",
                            "updated_at": "2025-12-13T07:03:37.000000Z",
                            "option_number": 6406534772091,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 119524,
                    "exam_id": 3,
                    "question_paper_id": 386,
                    "question_number": 198,
                    "question_text_1": null,
                    "question_image_1": "awJKrBy6zzt7oHHfQZjZ3UKXkakJXouWgzNVBKX2JATVMjlQyu.png",
                    "question_type": "SA",
                    "total_mark": "2.00",
                    "value_start": "6",
                    "value_end": null,
                    "created_at": "2025-12-13T07:03:37.000000Z",
                    "updated_at": "2025-12-13T07:03:37.000000Z",
                    "question_num_long": 6406531428302,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "35a88990e05bad17d59eca169ff6ccf5",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "9e146bb2-fb0e-418e-ac4e-6b1cef44bc5e",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/awJKrBy6zzt7oHHfQZjZ3UKXkakJXouWgzNVBKX2JATVMjlQyu.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 119525,
                    "exam_id": 3,
                    "question_paper_id": 386,
                    "question_number": 0,
                    "question_text_1": null,
                    "question_image_1": "SK34l9KBA7u9CecrmdjwcwyDoJd7vYTwiOjn2mQndSEKC7ygT8.png",
                    "question_type": "COMPREHENSION",
                    "total_mark": "0.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-12-13T07:03:37.000000Z",
                    "updated_at": "2025-12-13T07:03:37.000000Z",
                    "question_num_long": 6406531428303,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 0,
                    "hash": "8e3417063afa6c2475443302b56f0051",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "cb4b6f45-9ce8-45b9-aa84-5b7eec65dbb6",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/SK34l9KBA7u9CecrmdjwcwyDoJd7vYTwiOjn2mQndSEKC7ygT8.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 119526,
                    "exam_id": 3,
                    "question_paper_id": 386,
                    "question_number": 199,
                    "question_text_1": "For the input \u201cyou enjoy tea often\u201d, compute the final representation of the word \u201cenjoy\u201d after the attention layer (i.e., after applying WQ, WK, WV , attention weights, and WO). Enter the sum of the elements in the resulting vector.",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "3.00",
                    "value_start": "0.92",
                    "value_end": "1.0",
                    "created_at": "2025-12-13T07:03:37.000000Z",
                    "updated_at": "2025-12-13T07:03:37.000000Z",
                    "question_num_long": 6406531428304,
                    "answer_type": "Range",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "83a8e085fc583041b333d4d975cde321",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 119525,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "5bf2bfea-aa40-4ea2-a5f0-6b6ef6a539b7",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "For the input \u201cyou enjoy tea often\u201d, compute the final representation of the word \u201cenjoy\u201d after the attention layer (i.e., after applying WQ, WK, WV , attention weights, and WO). Enter the sum of the elements in the resulting vector."
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": {
                        "id": 119525,
                        "exam_id": 3,
                        "question_paper_id": 386,
                        "question_number": 0,
                        "question_text_1": null,
                        "question_image_1": "SK34l9KBA7u9CecrmdjwcwyDoJd7vYTwiOjn2mQndSEKC7ygT8.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2025-12-13T07:03:37.000000Z",
                        "updated_at": "2025-12-13T07:03:37.000000Z",
                        "question_num_long": 6406531428303,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "8e3417063afa6c2475443302b56f0051",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "cb4b6f45-9ce8-45b9-aa84-5b7eec65dbb6",
                        "question_image_url": [
                            "/question_images/SK34l9KBA7u9CecrmdjwcwyDoJd7vYTwiOjn2mQndSEKC7ygT8.png"
                        ],
                        "question_texts": null
                    }
                },
                {
                    "id": 119527,
                    "exam_id": 3,
                    "question_paper_id": 386,
                    "question_number": 200,
                    "question_text_1": "Suppose the input sentence is \u201ctea you enjoy often\u201d. Using the same matrices and processing method, what is the attention score (i.e., softmax entry from A) for the query word \u201ctea\u201d attending to key word \u201coften\u201d?",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "2.00",
                    "value_start": "0.04",
                    "value_end": "0.10",
                    "created_at": "2025-12-13T07:03:37.000000Z",
                    "updated_at": "2025-12-13T07:03:37.000000Z",
                    "question_num_long": 6406531428305,
                    "answer_type": "Range",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "dba843e519bb36138b5311cd61797da8",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 119525,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "aea5d41e-3329-4a17-a69b-80d4f989f210",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Suppose the input sentence is \u201ctea you enjoy often\u201d. Using the same matrices and processing method, what is the attention score (i.e., softmax entry from A) for the query word \u201ctea\u201d attending to key word \u201coften\u201d?"
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": {
                        "id": 119525,
                        "exam_id": 3,
                        "question_paper_id": 386,
                        "question_number": 0,
                        "question_text_1": null,
                        "question_image_1": "SK34l9KBA7u9CecrmdjwcwyDoJd7vYTwiOjn2mQndSEKC7ygT8.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2025-12-13T07:03:37.000000Z",
                        "updated_at": "2025-12-13T07:03:37.000000Z",
                        "question_num_long": 6406531428303,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "8e3417063afa6c2475443302b56f0051",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "cb4b6f45-9ce8-45b9-aa84-5b7eec65dbb6",
                        "question_image_url": [
                            "/question_images/SK34l9KBA7u9CecrmdjwcwyDoJd7vYTwiOjn2mQndSEKC7ygT8.png"
                        ],
                        "question_texts": null
                    }
                },
                {
                    "id": 119528,
                    "exam_id": 3,
                    "question_paper_id": 386,
                    "question_number": 0,
                    "question_text_1": "  Based on the above data, answer the given subquestions.",
                    "question_image_1": "5BcghSJ3KMpz4pYTCzMRIlPV5e3ngyvbYxuiDqBRivZfKUSZBa.png",
                    "question_type": "COMPREHENSION",
                    "total_mark": "0.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-12-13T07:03:37.000000Z",
                    "updated_at": "2025-12-13T07:03:37.000000Z",
                    "question_num_long": 6406531428312,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 0,
                    "hash": "eac62d1b2c493ac254652ce669eababf",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "0d3a5c69-fe1a-4c6f-93c2-e3b2e94a446c",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/5BcghSJ3KMpz4pYTCzMRIlPV5e3ngyvbYxuiDqBRivZfKUSZBa.png"
                    ],
                    "question_texts": [
                        "  Based on the above data, answer the given subquestions."
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 119529,
                    "exam_id": 3,
                    "question_paper_id": 386,
                    "question_number": 201,
                    "question_text_1": "Choose the correct representation of \u03c0 for the given mask image.",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-12-13T07:03:37.000000Z",
                    "updated_at": "2025-12-13T07:03:37.000000Z",
                    "question_num_long": 6406531428313,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "883b864390e14f46ca30e05caea3b272",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 119528,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "61dd7632-86cb-4b39-884b-9cae91a14758",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Choose the correct representation of \u03c0 for the given mask image."
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [
                        {
                            "id": 312270,
                            "question_id": 119529,
                            "option_text": "\u03c0 = (2, 1, 3, 4, 0)",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:03:37.000000Z",
                            "updated_at": "2025-12-13T07:03:37.000000Z",
                            "option_number": 6406534772106,
                            "option_image_url": null
                        },
                        {
                            "id": 312271,
                            "question_id": 119529,
                            "option_text": "\u03c0 = (0, 4, 3, 1, 2)",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:03:37.000000Z",
                            "updated_at": "2025-12-13T07:03:37.000000Z",
                            "option_number": 6406534772107,
                            "option_image_url": null
                        },
                        {
                            "id": 312272,
                            "question_id": 119529,
                            "option_text": "\u03c0 = (0, 3, 4, 2, 1)",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-12-13T07:03:37.000000Z",
                            "updated_at": "2025-12-13T07:03:37.000000Z",
                            "option_number": 6406534772108,
                            "option_image_url": null
                        },
                        {
                            "id": 312273,
                            "question_id": 119529,
                            "option_text": "All of these",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:03:37.000000Z",
                            "updated_at": "2025-12-13T07:03:37.000000Z",
                            "option_number": 6406534772109,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": {
                        "id": 119528,
                        "exam_id": 3,
                        "question_paper_id": 386,
                        "question_number": 0,
                        "question_text_1": "  Based on the above data, answer the given subquestions.",
                        "question_image_1": "5BcghSJ3KMpz4pYTCzMRIlPV5e3ngyvbYxuiDqBRivZfKUSZBa.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2025-12-13T07:03:37.000000Z",
                        "updated_at": "2025-12-13T07:03:37.000000Z",
                        "question_num_long": 6406531428312,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "eac62d1b2c493ac254652ce669eababf",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "0d3a5c69-fe1a-4c6f-93c2-e3b2e94a446c",
                        "question_image_url": [
                            "/question_images/5BcghSJ3KMpz4pYTCzMRIlPV5e3ngyvbYxuiDqBRivZfKUSZBa.png"
                        ],
                        "question_texts": [
                            "  Based on the above data, answer the given subquestions."
                        ]
                    }
                },
                {
                    "id": 119530,
                    "exam_id": 3,
                    "question_paper_id": 386,
                    "question_number": 202,
                    "question_text_1": "How many permutations of \u03c0 are possible for n = 5?",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "1.00",
                    "value_start": "120",
                    "value_end": null,
                    "created_at": "2025-12-13T07:03:37.000000Z",
                    "updated_at": "2025-12-13T07:03:37.000000Z",
                    "question_num_long": 6406531428314,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "321f9b968b49387b9b724789bd3f4002",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 119528,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "94ec9788-7484-477f-86f8-f7466786bb7f",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "How many permutations of \u03c0 are possible for n = 5?"
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": {
                        "id": 119528,
                        "exam_id": 3,
                        "question_paper_id": 386,
                        "question_number": 0,
                        "question_text_1": "  Based on the above data, answer the given subquestions.",
                        "question_image_1": "5BcghSJ3KMpz4pYTCzMRIlPV5e3ngyvbYxuiDqBRivZfKUSZBa.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2025-12-13T07:03:37.000000Z",
                        "updated_at": "2025-12-13T07:03:37.000000Z",
                        "question_num_long": 6406531428312,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "eac62d1b2c493ac254652ce669eababf",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "0d3a5c69-fe1a-4c6f-93c2-e3b2e94a446c",
                        "question_image_url": [
                            "/question_images/5BcghSJ3KMpz4pYTCzMRIlPV5e3ngyvbYxuiDqBRivZfKUSZBa.png"
                        ],
                        "question_texts": [
                            "  Based on the above data, answer the given subquestions."
                        ]
                    }
                },
                {
                    "id": 119531,
                    "exam_id": 3,
                    "question_paper_id": 386,
                    "question_number": 203,
                    "question_text_1": "What percentage of entries in the attention matrix are zero (i.e., the sparsity)?",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "2.00",
                    "value_start": "80",
                    "value_end": null,
                    "created_at": "2025-12-13T07:03:37.000000Z",
                    "updated_at": "2025-12-13T07:03:37.000000Z",
                    "question_num_long": 6406531428315,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "9b53a6012fceeb1e1b5d869a59295cbb",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 119528,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "5204d46c-5571-4edf-8aea-276f3fdcc7a6",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "What percentage of entries in the attention matrix are zero (i.e., the sparsity)?"
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": {
                        "id": 119528,
                        "exam_id": 3,
                        "question_paper_id": 386,
                        "question_number": 0,
                        "question_text_1": "  Based on the above data, answer the given subquestions.",
                        "question_image_1": "5BcghSJ3KMpz4pYTCzMRIlPV5e3ngyvbYxuiDqBRivZfKUSZBa.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2025-12-13T07:03:37.000000Z",
                        "updated_at": "2025-12-13T07:03:37.000000Z",
                        "question_num_long": 6406531428312,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "eac62d1b2c493ac254652ce669eababf",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "0d3a5c69-fe1a-4c6f-93c2-e3b2e94a446c",
                        "question_image_url": [
                            "/question_images/5BcghSJ3KMpz4pYTCzMRIlPV5e3ngyvbYxuiDqBRivZfKUSZBa.png"
                        ],
                        "question_texts": [
                            "  Based on the above data, answer the given subquestions."
                        ]
                    }
                },
                {
                    "id": 119532,
                    "exam_id": 3,
                    "question_paper_id": 386,
                    "question_number": 0,
                    "question_text_1": "  Based on the above data, answer the given subquestions.",
                    "question_image_1": "O51sHHG3bexZtNCVNkmAXg5H9aHr9TGjWyWhxt3rxA3WQOnqPf.png",
                    "question_type": "COMPREHENSION",
                    "total_mark": "0.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-12-13T07:03:37.000000Z",
                    "updated_at": "2025-12-13T07:03:37.000000Z",
                    "question_num_long": 6406531428306,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 0,
                    "hash": "f7ab4de1986238572b9c44c1f6025c97",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "a1372f49-a58b-45e5-a2dc-e08f2f9240c9",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/O51sHHG3bexZtNCVNkmAXg5H9aHr9TGjWyWhxt3rxA3WQOnqPf.png"
                    ],
                    "question_texts": [
                        "  Based on the above data, answer the given subquestions."
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 119533,
                    "exam_id": 3,
                    "question_paper_id": 386,
                    "question_number": 204,
                    "question_text_1": null,
                    "question_image_1": "B5B8GhuiiKFx5XkjMYy8bz7HOtZU2XXPHrJ9y6u4O3paGGKe2H.png",
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-12-13T07:03:37.000000Z",
                    "updated_at": "2025-12-13T07:03:37.000000Z",
                    "question_num_long": 6406531428307,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "521e36fee91f7b813fc10f4939c02d51",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 119532,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "90760709-6ca1-43c0-a4f6-fc99ce69374c",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/B5B8GhuiiKFx5XkjMYy8bz7HOtZU2XXPHrJ9y6u4O3paGGKe2H.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [
                        {
                            "id": 312274,
                            "question_id": 119533,
                            "option_text": "(0, 1, 2, 3, 4, 5)",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:03:37.000000Z",
                            "updated_at": "2025-12-13T07:03:37.000000Z",
                            "option_number": 6406534772095,
                            "option_image_url": null
                        },
                        {
                            "id": 312275,
                            "question_id": 119533,
                            "option_text": "(-1, 0, 1, 2, 3, 4)",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:03:37.000000Z",
                            "updated_at": "2025-12-13T07:03:37.000000Z",
                            "option_number": 6406534772096,
                            "option_image_url": null
                        },
                        {
                            "id": 312276,
                            "question_id": 119533,
                            "option_text": "(-3, -2, -1, 0, 1, 2)",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:03:37.000000Z",
                            "updated_at": "2025-12-13T07:03:37.000000Z",
                            "option_number": 6406534772097,
                            "option_image_url": null
                        },
                        {
                            "id": 312277,
                            "question_id": 119533,
                            "option_text": "(-2, -1, 0, 1, 2, 3)",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-12-13T07:03:37.000000Z",
                            "updated_at": "2025-12-13T07:03:37.000000Z",
                            "option_number": 6406534772098,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": {
                        "id": 119532,
                        "exam_id": 3,
                        "question_paper_id": 386,
                        "question_number": 0,
                        "question_text_1": "  Based on the above data, answer the given subquestions.",
                        "question_image_1": "O51sHHG3bexZtNCVNkmAXg5H9aHr9TGjWyWhxt3rxA3WQOnqPf.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2025-12-13T07:03:37.000000Z",
                        "updated_at": "2025-12-13T07:03:37.000000Z",
                        "question_num_long": 6406531428306,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "f7ab4de1986238572b9c44c1f6025c97",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "a1372f49-a58b-45e5-a2dc-e08f2f9240c9",
                        "question_image_url": [
                            "/question_images/O51sHHG3bexZtNCVNkmAXg5H9aHr9TGjWyWhxt3rxA3WQOnqPf.png"
                        ],
                        "question_texts": [
                            "  Based on the above data, answer the given subquestions."
                        ]
                    }
                },
                {
                    "id": 119534,
                    "exam_id": 3,
                    "question_paper_id": 386,
                    "question_number": 205,
                    "question_text_1": null,
                    "question_image_1": "I0qKnFXajZo1DkLwbQgi3QxehqKD8dSofIzaGQyMVSnQPngr45.png",
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-12-13T07:03:37.000000Z",
                    "updated_at": "2025-12-13T07:03:37.000000Z",
                    "question_num_long": 6406531428308,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "b186f6b2601e219d254e9fef223a60af",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 119532,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "991d932c-c3bd-4e63-9f51-28266f359271",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/I0qKnFXajZo1DkLwbQgi3QxehqKD8dSofIzaGQyMVSnQPngr45.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [
                        {
                            "id": 312278,
                            "question_id": 119534,
                            "option_text": "[\u22120.4,\u22120.4,\u22120.4,\u22120.4]",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:03:37.000000Z",
                            "updated_at": "2025-12-13T07:03:37.000000Z",
                            "option_number": 6406534772099,
                            "option_image_url": null
                        },
                        {
                            "id": 312279,
                            "question_id": 119534,
                            "option_text": "[\u22120.1,\u22120.1,\u22120.1,\u22120.1]",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:03:37.000000Z",
                            "updated_at": "2025-12-13T07:03:37.000000Z",
                            "option_number": 6406534772100,
                            "option_image_url": null
                        },
                        {
                            "id": 312280,
                            "question_id": 119534,
                            "option_text": "[\u22120.8,\u22120.8,\u22120.8,\u22120.8]",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-12-13T07:03:37.000000Z",
                            "updated_at": "2025-12-13T07:03:37.000000Z",
                            "option_number": 6406534772101,
                            "option_image_url": null
                        },
                        {
                            "id": 312281,
                            "question_id": 119534,
                            "option_text": "[\u22120.2,\u22120.2,\u22120.2,\u22120.2]",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:03:37.000000Z",
                            "updated_at": "2025-12-13T07:03:37.000000Z",
                            "option_number": 6406534772102,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": {
                        "id": 119532,
                        "exam_id": 3,
                        "question_paper_id": 386,
                        "question_number": 0,
                        "question_text_1": "  Based on the above data, answer the given subquestions.",
                        "question_image_1": "O51sHHG3bexZtNCVNkmAXg5H9aHr9TGjWyWhxt3rxA3WQOnqPf.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2025-12-13T07:03:37.000000Z",
                        "updated_at": "2025-12-13T07:03:37.000000Z",
                        "question_num_long": 6406531428306,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "f7ab4de1986238572b9c44c1f6025c97",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "a1372f49-a58b-45e5-a2dc-e08f2f9240c9",
                        "question_image_url": [
                            "/question_images/O51sHHG3bexZtNCVNkmAXg5H9aHr9TGjWyWhxt3rxA3WQOnqPf.png"
                        ],
                        "question_texts": [
                            "  Based on the above data, answer the given subquestions."
                        ]
                    }
                },
                {
                    "id": 119535,
                    "exam_id": 3,
                    "question_paper_id": 386,
                    "question_number": 206,
                    "question_text_1": null,
                    "question_image_1": "pPDJoo32l6O38nHKpdfISfsevbbvvOJArzELl13H4qjGrlHT4o.png",
                    "question_type": "SA",
                    "total_mark": "3.00",
                    "value_start": "15.2",
                    "value_end": null,
                    "created_at": "2025-12-13T07:03:37.000000Z",
                    "updated_at": "2025-12-13T07:03:37.000000Z",
                    "question_num_long": 6406531428309,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "1f02794f13cafa5e46a1092a00ea893c",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 119532,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "d32eabe7-c252-411b-803f-4b65c0abf0eb",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/pPDJoo32l6O38nHKpdfISfsevbbvvOJArzELl13H4qjGrlHT4o.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": {
                        "id": 119532,
                        "exam_id": 3,
                        "question_paper_id": 386,
                        "question_number": 0,
                        "question_text_1": "  Based on the above data, answer the given subquestions.",
                        "question_image_1": "O51sHHG3bexZtNCVNkmAXg5H9aHr9TGjWyWhxt3rxA3WQOnqPf.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2025-12-13T07:03:37.000000Z",
                        "updated_at": "2025-12-13T07:03:37.000000Z",
                        "question_num_long": 6406531428306,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "f7ab4de1986238572b9c44c1f6025c97",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "a1372f49-a58b-45e5-a2dc-e08f2f9240c9",
                        "question_image_url": [
                            "/question_images/O51sHHG3bexZtNCVNkmAXg5H9aHr9TGjWyWhxt3rxA3WQOnqPf.png"
                        ],
                        "question_texts": [
                            "  Based on the above data, answer the given subquestions."
                        ]
                    }
                },
                {
                    "id": 119536,
                    "exam_id": 3,
                    "question_paper_id": 386,
                    "question_number": 207,
                    "question_text_1": null,
                    "question_image_1": "TidOKmnnHt1EhnR2D9gq37aACKKTC03qoSnYoLJb25I5FCe6UR.png",
                    "question_type": "SA",
                    "total_mark": "2.00",
                    "value_start": "23.7",
                    "value_end": "24.3",
                    "created_at": "2025-12-13T07:03:37.000000Z",
                    "updated_at": "2025-12-13T07:03:37.000000Z",
                    "question_num_long": 6406531428310,
                    "answer_type": "Range",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "7d1b7d897f6c4e859bb216bfb5e5d9c5",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 119532,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "67b1a938-8e88-4480-a53b-b9d2fec71270",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/TidOKmnnHt1EhnR2D9gq37aACKKTC03qoSnYoLJb25I5FCe6UR.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": {
                        "id": 119532,
                        "exam_id": 3,
                        "question_paper_id": 386,
                        "question_number": 0,
                        "question_text_1": "  Based on the above data, answer the given subquestions.",
                        "question_image_1": "O51sHHG3bexZtNCVNkmAXg5H9aHr9TGjWyWhxt3rxA3WQOnqPf.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2025-12-13T07:03:37.000000Z",
                        "updated_at": "2025-12-13T07:03:37.000000Z",
                        "question_num_long": 6406531428306,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "f7ab4de1986238572b9c44c1f6025c97",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "a1372f49-a58b-45e5-a2dc-e08f2f9240c9",
                        "question_image_url": [
                            "/question_images/O51sHHG3bexZtNCVNkmAXg5H9aHr9TGjWyWhxt3rxA3WQOnqPf.png"
                        ],
                        "question_texts": [
                            "  Based on the above data, answer the given subquestions."
                        ]
                    }
                },
                {
                    "id": 119537,
                    "exam_id": 3,
                    "question_paper_id": 386,
                    "question_number": 208,
                    "question_text_1": null,
                    "question_image_1": "BX0752oHMKidVFjSJPOoeqmtadKdczu0zTs7CzXfFecJG0Mfvg.png",
                    "question_type": "SA",
                    "total_mark": "3.00",
                    "value_start": "39",
                    "value_end": null,
                    "created_at": "2025-12-13T07:03:37.000000Z",
                    "updated_at": "2025-12-13T07:03:37.000000Z",
                    "question_num_long": 6406531428311,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "2a315189ba0cf75d1dc5507a18808e33",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 119532,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "89432c7b-f421-447a-8c57-5d9b78d772bd",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/BX0752oHMKidVFjSJPOoeqmtadKdczu0zTs7CzXfFecJG0Mfvg.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": {
                        "id": 119532,
                        "exam_id": 3,
                        "question_paper_id": 386,
                        "question_number": 0,
                        "question_text_1": "  Based on the above data, answer the given subquestions.",
                        "question_image_1": "O51sHHG3bexZtNCVNkmAXg5H9aHr9TGjWyWhxt3rxA3WQOnqPf.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2025-12-13T07:03:37.000000Z",
                        "updated_at": "2025-12-13T07:03:37.000000Z",
                        "question_num_long": 6406531428306,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "f7ab4de1986238572b9c44c1f6025c97",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "a1372f49-a58b-45e5-a2dc-e08f2f9240c9",
                        "question_image_url": [
                            "/question_images/O51sHHG3bexZtNCVNkmAXg5H9aHr9TGjWyWhxt3rxA3WQOnqPf.png"
                        ],
                        "question_texts": [
                            "  Based on the above data, answer the given subquestions."
                        ]
                    }
                }
            ]
        },
        "summary": "Here\u2019s a structured summary of the **core topics, concepts, principles, and equations** essential for the **Large Language Models (LLM) exam**, along with **Mermaid knowledge graphs** to visualize relationships.\n\n---\n\n---\n\n### **1. Core Topics & Concepts**\n#### **A. Tokenization & Subword Models**\n- **Subword Tokenization**: Splitting words into subword units (e.g., BPE, WordPiece, SentencePiece).\n- **Viterbi Algorithm**: Used in SentencePiece to find the most probable tokenization by maximizing the sum of log-probabilities.\n  - **Key Idea**: Dynamic programming to select the optimal path.\n  - **Equation**:\n    \\[\n    \\text{Score}(i) = \\max_{j < i} \\left( \\text{Score}(j) + \\log P(\\text{subword}_{j+1:i}) \\right)\n    \\]\n- **Example**: For \"sunshine,\" the optimal split is `[\"su\", \"nshine\"]` (log-prob = -0.3 + -0.4 = -0.7), which is better than `[\"sun\", \"shine\"]` (-1.2) or `[\"sunshine\"]` (-1.6).\n\n#### **B. Attention Mechanisms**\n1. **Causal (Autoregressive) Masking**:\n   - Used in **GPT-like models** to prevent attending to future tokens.\n   - **Mask Matrix** (for sequence length `T`):\n     \\[\n     M_{ij} = \\begin{cases}\n     0 & \\text{if } i \\geq j, \\\\\n     -\\infty & \\text{otherwise.}\n     \\end{cases}\n     \\]\n   - **Example** (T=4):\n     ```\n     [[0, -\u221e, -\u221e, -\u221e],\n      [0, 0,  -\u221e, -\u221e],\n      [0, 0,  0,  -\u221e],\n      [0, 0,  0,   0 ]]\n     ```\n\n2. **Sparse Attention Patterns**:\n   - **Strided Local Attention**: Attend to tokens in fixed-stride windows.\n   - **Local + Global Attention**: Combine local windows with global tokens (e.g., [CLS]).\n   - **Block-Sparse Attention** (e.g., Transformer-XL):\n     - Partition sequences into blocks and restrict attention to specific block pairs via a permutation `\u03c0`.\n     - **Sparsity**: For `n` blocks, only `1/n` of the attention matrix is non-zero (e.g., 80% sparsity for `n=5`).\n\n3. **Relative Position Embeddings**:\n   - **Naive Method**: Add relative position embeddings `p_(j-i)` to token embeddings.\n     - **Equation**:\n       \\[\n       h_i = x_i + \\sum_{j=0}^{T-1} p_{(j-i)}\n       \\]\n   - **Clipping**: Limit maximum relative distance to `k` to bound the embedding table size.\n   - **ALiBi (Attention with Linear Biases)**:\n     - Add a penalty `m_h * (j - i)` to attention scores, where `m_h = 1/2^h` for head `h`.\n     - **Equation**:\n       \\[\n       e_{ij} = x_i W_Q (x_j W_K)^T + m_h \\cdot (j - i)\n       \\]\n\n#### **C. Sampling Methods**\n1. **Top-p (Nucleus) Sampling**:\n   - Sample from the smallest set of tokens whose cumulative probability \u2265 `p`.\n   - **Steps**:\n     1. Sort token probabilities in descending order.\n     2. Select the smallest prefix where `\u2211 prob \u2265 p`.\n   - **Example**: For `p=0.7` and probabilities `[0.06, 0.20, 0.14, 0.06, 0.09, 0.08, 0.05, 0.15, 0.06, 0.11]`, the selected tokens are the first 6 (cumulative prob = 0.7).\n\n2. **Temperature Scaling**:\n   - Sharpen/flatten the softmax distribution:\n     \\[\n     p_i = \\frac{\\exp(z_i / \\tau)}{\\sum_j \\exp(z_j / \\tau)}\n     \\]\n   - `\u03c4 \u2192 0`: Greedy sampling.\n   - `\u03c4 \u2192 \u221e`: Uniform sampling.\n\n#### **D. Transformer Architecture**\n1. **Input Preprocessing**:\n   - Add special tokens (e.g., `[CLS]`, `[SEP]` for BERT).\n   - Split tokens into subwords (e.g., \"enjoying\" \u2192 [\"enjoy\", \"##ing\"]).\n   - Add positional embeddings (absolute or relative).\n\n2. **Attention Layer**:\n   - **Query/Key/Value**:\n     \\[\n     Q = X W_Q, \\quad K = X W_K, \\quad V = X W_V\n     \\]\n   - **Attention Scores**:\n     \\[\n     A = \\text{softmax}\\left( \\frac{Q K^T}{\\sqrt{d_k}} \\right) V\n     \\]\n   - **Output**:\n     \\[\n     \\text{Attention}(Q, K, V) = A W_O\n     \\]\n\n3. **Efficient Attention for Long Sequences**:\n   - **Sparse Attention**: Reduce complexity from `O(T^2)` to `O(T \u221aT)`.\n   - **Low-Rank Approximation**: Factorize attention matrices (e.g., Linformer).\n   - **Memory-Compressed Attention** (e.g., Transformer-XL): Reuse hidden states from previous segments.\n\n#### **E. Permutations & Block Attention**\n- **Block Permutations (`\u03c0`)**:\n  - For `n` blocks, `\u03c0` is a permutation of `{0, ..., n-1}` defining which key blocks each query block attends to.\n  - **Number of Permutations**: `n!` (e.g., `5! = 120`).\n- **Masking Matrix `M`**:\n  \\[\n  M_{ij} = \\begin{cases}\n  1 & \\text{if } \\left\\lfloor \\frac{i n}{T} \\right\\rfloor = \\pi\\left( \\left\\lfloor \\frac{j n}{T} \\right\\rfloor \\right), \\\\\n  0 & \\text{otherwise.}\n  \\end{cases}\n  \\]\n\n---\n\n### **2. Key Equations**\n| **Concept**               | **Equation**                                                                 |\n|---------------------------|-----------------------------------------------------------------------------|\n| **Viterbi Tokenization**  | `Score(i) = max(Score(j) + log P(subword_{j+1:i}))`                          |\n| **Causal Mask**           | `M_{ij} = 0 if i \u2265 j, else -\u221e`                                             |\n| **Attention Scores**      | `A = softmax(Q K^T / \u221ad_k) V`                                              |\n| **Relative Position**     | `h_i = x_i + \u2211_j p_{(j-i)}`                                                |\n| **ALiBi Bias**            | `e_{ij} = Q K^T + m_h * (j - i)`, where `m_h = 1/2^h`                      |\n| **Top-p Sampling**        | Select smallest set where `\u2211 prob \u2265 p`                                     |\n| **Block Attention Mask**  | `M_{ij} = 1 if block(i) = \u03c0(block(j))`                                      |\n\n---\n\n### **3. Mermaid Knowledge Graphs**\n#### **Graph 1: Tokenization & Subword Models**\n```mermaid\ngraph TD\n    A[Input Text] --> B[Vocabulary]\n    B --> C[Subword Segmentation]\n    C --> D[Viterbi Algorithm]\n    D --> E[Optimal Tokenization]\n    E --> F[Log-Probability Sum]\n```\n\n#### **Graph 2: Attention Mechanisms**\n```mermaid\ngraph TD\n    A[Attention] --> B[Full Attention]\n    A --> C[Sparse Attention]\n    C --> D[Local Attention]\n    C --> E[Strided Attention]\n    C --> F[Block-Sparse Attention]\n    F --> G[Permutation \u03c0]\n    A --> H[Relative Position]\n    H --> I[Naive Embedding]\n    H --> J[ALiBi]\n```\n\n#### **Graph 3: Transformer Preprocessing**\n```mermaid\ngraph TD\n    A[Raw Text] --> B[Tokenization]\n    B --> C[Add Special Tokens]\n    C --> D[Subword Splitting]\n    D --> E[Positional Embeddings]\n    E --> F[Absolute Positions]\n    E --> G[Relative Positions]\n    G --> H[Clipping]\n```\n\n#### **Graph 4: Sampling Methods**\n```mermaid\ngraph TD\n    A[Probability Distribution] --> B[Top-p Sampling]\n    A --> C[Temperature Scaling]\n    B --> D[Sort Tokens]\n    D --> E[Cumulative Probability]\n    E --> F[Select Tokens]\n```\n\n#### **Graph 5: Efficient Attention**\n```mermaid\ngraph TD\n    A[Long Sequences] --> B[Sparse Attention]\n    A --> C[Low-Rank Approximation]\n    A --> D[Memory Compression]\n    B --> E[Strided Local]\n    B --> F[Block-Sparse]\n    F --> G[Permutation \u03c0]\n    D --> H[Transformer-XL]\n```\n\n---\n\n### **4. Exam Tips**\n1. **Tokenization**:\n   - Practice the Viterbi algorithm for subword segmentation (e.g., Question 2).\n   - Remember: **Higher log-probability (less negative) = better**.\n\n2. **Attention Masks**:\n   - **Causal masking**: Upper-triangular matrix with `-\u221e` for future tokens.\n   - **Sparse patterns**: Identify local/global/strided blocks (e.g., Question 4).\n\n3. **Relative Positions**:\n   - For token `i`, relative positions are `(j - i)` for all `j`.\n   - **ALiBi**: Add linear bias `m_h * (j - i)` to attention scores.\n\n4. **Sampling**:\n   - **Top-p**: Sort probabilities, cumulate until \u2265 `p`, then sample uniformly from the selected tokens.\n\n5. **Block Attention**:\n   - **Permutations**: For `n` blocks, there are `n!` possible `\u03c0`.\n   - **Sparsity**: `(n - 1)/n` of the attention matrix is zero (e.g., 80% for `n=5`).\n\n6. **Math-Heavy Questions**:\n   - **Attention computation**: Follow the steps:\n     1. Compute `Q`, `K`, `V` using `W_Q`, `W_K`, `W_V`.\n     2. Calculate `Q K^T / \u221ad_k`.\n     3. Apply softmax to get attention weights.\n     4. Multiply by `V` and then `W_O`.\n   - **Example**: Question 9 (sum of elements in the output vector for \"enjoy\").",
        "total_score": "40.00"
    },
    "url": "/question-paper/practise/85/ff60a8af-cf5",
    "version": "ee3d5d44299e610bd137ea6200db5ac2"
}