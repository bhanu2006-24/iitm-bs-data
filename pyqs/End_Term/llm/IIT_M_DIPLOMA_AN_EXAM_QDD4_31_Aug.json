{
    "component": "Quizpractise/PractiseQuestionPaper",
    "props": {
        "errors": {},
        "auth": {
            "user": null
        },
        "flash": {
            "error": []
        },
        "banner": null,
        "file_url": "https://saram.blr1.cdn.digitaloceanspaces.com",
        "file_do_url": "https://saram.blr1.cdn.digitaloceanspaces.com",
        "question_paper": {
            "id": 388,
            "group_id": 32,
            "exam_id": 3,
            "total_score": "1.00",
            "duration": 4,
            "created_at": "2025-12-13T07:04:18.000000Z",
            "updated_at": "2025-12-13T07:04:18.000000Z",
            "question_paper_name": "IIT M DIPLOMA AN EXAM QDD4 31 Aug",
            "question_paper_description": "2025 Aug31: IIT M AN EXAM QDD4",
            "uuid": "ff1fbf54-6d2",
            "year": 2025,
            "is_new": 0,
            "exam": {
                "id": 3,
                "exam_name": "End Term Quiz",
                "created_at": "2024-10-16T08:08:51.000000Z",
                "updated_at": "2024-10-16T08:08:51.000000Z",
                "uuid": "7a6ff569-f50c-40e7-a08b-f5c334392600",
                "en_id": "eyJpdiI6IlFRQ3hKL0ZGS0JDTGJkK3RuNEtnNGc9PSIsInZhbHVlIjoibHZ3K2dxOGdnUTRiL21vcTJKWjRVUT09IiwibWFjIjoiMWMxYmQ3YjFjMGNkZjI2MTQ2YWVlM2U2OGQwZTNiMTlhNjRlZTFjYjlhZjU4NTk2YjJhNzY5NDU4OWM1MzFiOCIsInRhZyI6IiJ9"
            },
            "questions": [
                {
                    "id": 120389,
                    "exam_id": 3,
                    "question_paper_id": 388,
                    "question_number": 202,
                    "question_text_1": "THIS IS QUESTION PAPER FOR THE SUBJECT <b>\"DEGREE LEVEL : LARGE LANGUAGE MODELS </b><b>(COMPUTER BASED EXAM)\"</b><b> </b> <b>ARE YOU SURE YOU HAVE TO WRITE EXAM FOR THIS SUBJECT? </b><b>CROSS CHECK YOUR HALL TICKET TO CONFIRM THE SUBJECTS TO BE WRITTEN. </b><b> </b><b>(IF IT IS NOT THE CORRECT SUBJECT, PLS CHECK THE SECTION AT THE TOP FOR THE SUBJECTS </b><b>REGISTERED BY YOU)</b>",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "0.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-12-13T07:04:20.000000Z",
                    "updated_at": "2025-12-13T07:04:20.000000Z",
                    "question_num_long": 6406531424285,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "0c84a23657b3a7f7b8de27d1ffddaae9",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "bd113924-964b-492d-8412-3881f5fe5c3b",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "THIS IS QUESTION PAPER FOR THE SUBJECT <b>\"DEGREE LEVEL : LARGE LANGUAGE MODELS </b><b>(COMPUTER BASED EXAM)\"</b><b> </b> <b>ARE YOU SURE YOU HAVE TO WRITE EXAM FOR THIS SUBJECT? </b><b>CROSS CHECK YOUR HALL TICKET TO CONFIRM THE SUBJECTS TO BE WRITTEN. </b><b> </b><b>(IF IT IS NOT THE CORRECT SUBJECT, PLS CHECK THE SECTION AT THE TOP FOR THE SUBJECTS </b><b>REGISTERED BY YOU)</b>"
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [
                        {
                            "id": 314361,
                            "question_id": 120389,
                            "option_text": "YES",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 1,
                            "created_at": "2025-12-13T07:04:20.000000Z",
                            "updated_at": "2025-12-13T07:04:20.000000Z",
                            "option_number": 6406534761286,
                            "option_image_url": null
                        },
                        {
                            "id": 314362,
                            "question_id": 120389,
                            "option_text": "NO",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:04:20.000000Z",
                            "updated_at": "2025-12-13T07:04:20.000000Z",
                            "option_number": 6406534761287,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 120390,
                    "exam_id": 3,
                    "question_paper_id": 388,
                    "question_number": 203,
                    "question_text_1": null,
                    "question_image_1": "sbn6LYQtyqVIjNbYaOyrX5urQmn8mWAr2cspuvlBV8DfJOpVMW.png",
                    "question_type": "MCQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-12-13T07:04:20.000000Z",
                    "updated_at": "2025-12-13T07:04:20.000000Z",
                    "question_num_long": 6406531424286,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "1a4a879055a916ba3819291ea98cf686",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "0b51ecd8-33a5-4b2c-9a24-b6fe40ed9fe3",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/sbn6LYQtyqVIjNbYaOyrX5urQmn8mWAr2cspuvlBV8DfJOpVMW.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [
                        {
                            "id": 314363,
                            "question_id": 120390,
                            "option_text": "",
                            "option_image": "a9xRZmm0RkDGYLT3t3T1PloSY7MS3vESFhyzkwqYCMjqjkQh42.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:04:20.000000Z",
                            "updated_at": "2025-12-13T07:04:20.000000Z",
                            "option_number": 6406534761288,
                            "option_image_url": "app/option_images/a9xRZmm0RkDGYLT3t3T1PloSY7MS3vESFhyzkwqYCMjqjkQh42.png"
                        },
                        {
                            "id": 314364,
                            "question_id": 120390,
                            "option_text": "",
                            "option_image": "uY2WGFjPwhBP5TJezdt8EK40rgzD8u41BdEvDv7oOFYzGbZUYU.png",
                            "score": "3.000",
                            "is_correct": 1,
                            "created_at": "2025-12-13T07:04:20.000000Z",
                            "updated_at": "2025-12-13T07:04:20.000000Z",
                            "option_number": 6406534761289,
                            "option_image_url": "app/option_images/uY2WGFjPwhBP5TJezdt8EK40rgzD8u41BdEvDv7oOFYzGbZUYU.png"
                        },
                        {
                            "id": 314365,
                            "question_id": 120390,
                            "option_text": "",
                            "option_image": "NOt8re3oIkL9hDF6gzoW1l9GFKat6UJGzzyQTrcEc5REpTI5w0.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:04:20.000000Z",
                            "updated_at": "2025-12-13T07:04:20.000000Z",
                            "option_number": 6406534761290,
                            "option_image_url": "app/option_images/NOt8re3oIkL9hDF6gzoW1l9GFKat6UJGzzyQTrcEc5REpTI5w0.png"
                        },
                        {
                            "id": 314366,
                            "question_id": 120390,
                            "option_text": "",
                            "option_image": "kdM2JCB3WUPvv1uB29MqcuRJBQYX3Ky6QpY5nxVHRXy4OhsBGY.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:04:20.000000Z",
                            "updated_at": "2025-12-13T07:04:20.000000Z",
                            "option_number": 6406534761291,
                            "option_image_url": "app/option_images/kdM2JCB3WUPvv1uB29MqcuRJBQYX3Ky6QpY5nxVHRXy4OhsBGY.png"
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 120391,
                    "exam_id": 3,
                    "question_paper_id": 388,
                    "question_number": 204,
                    "question_text_1": "A GPT model is trained using <b>causal language modeling</b>. During training, for a sequence of T = 4 tokens, which of the following correctly represents the <b>attention mask matrix</b> applied to the attention logits?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-12-13T07:04:20.000000Z",
                    "updated_at": "2025-12-13T07:04:20.000000Z",
                    "question_num_long": 6406531424287,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "c9a9ba3a57a97813dceb600b44c2fdfd",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "fb052d72-e167-45dd-b521-094ec1aea0b7",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "A GPT model is trained using <b>causal language modeling</b>. During training, for a sequence of T = 4 tokens, which of the following correctly represents the <b>attention mask matrix</b> applied to the attention logits?"
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [
                        {
                            "id": 314367,
                            "question_id": 120391,
                            "option_text": "",
                            "option_image": "qa2CdK3m6SiBF97DhJPfTBLENiGaY085HlJrrnMw78i1z6kcr8.png",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-12-13T07:04:20.000000Z",
                            "updated_at": "2025-12-13T07:04:20.000000Z",
                            "option_number": 6406534761292,
                            "option_image_url": "app/option_images/qa2CdK3m6SiBF97DhJPfTBLENiGaY085HlJrrnMw78i1z6kcr8.png"
                        },
                        {
                            "id": 314368,
                            "question_id": 120391,
                            "option_text": "",
                            "option_image": "yKgBttEIgL2UH7R0C72BdRe4wEV0n083mIjN97174fudthwQ8W.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:04:20.000000Z",
                            "updated_at": "2025-12-13T07:04:20.000000Z",
                            "option_number": 6406534761293,
                            "option_image_url": "app/option_images/yKgBttEIgL2UH7R0C72BdRe4wEV0n083mIjN97174fudthwQ8W.png"
                        },
                        {
                            "id": 314369,
                            "question_id": 120391,
                            "option_text": "",
                            "option_image": "bxusw9BhEBQFl6rN7QEdvZLIlrGw3vnNWm6ubSpeueCL9wOmLy.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:04:20.000000Z",
                            "updated_at": "2025-12-13T07:04:20.000000Z",
                            "option_number": 6406534761294,
                            "option_image_url": "app/option_images/bxusw9BhEBQFl6rN7QEdvZLIlrGw3vnNWm6ubSpeueCL9wOmLy.png"
                        },
                        {
                            "id": 314370,
                            "question_id": 120391,
                            "option_text": "",
                            "option_image": "10j4DChK1mgfo4UPRbT7jqsxB4yDumMf8oA4m6Wkyj573H59GS.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:04:20.000000Z",
                            "updated_at": "2025-12-13T07:04:20.000000Z",
                            "option_number": 6406534761295,
                            "option_image_url": "app/option_images/10j4DChK1mgfo4UPRbT7jqsxB4yDumMf8oA4m6Wkyj573H59GS.png"
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 120392,
                    "exam_id": 3,
                    "question_paper_id": 388,
                    "question_number": 205,
                    "question_text_1": null,
                    "question_image_1": "J9iypas2hAxF0ow7pgC04SGHHu1z7xu2HUfiL47NSEeubJaEB2.png",
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-12-13T07:04:20.000000Z",
                    "updated_at": "2025-12-13T07:04:20.000000Z",
                    "question_num_long": 6406531424288,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "5c6be3838d7ca06d81764d46a141c8bf",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "38a69ad7-e761-4ba2-ae22-20c7214d1773",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/J9iypas2hAxF0ow7pgC04SGHHu1z7xu2HUfiL47NSEeubJaEB2.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [
                        {
                            "id": 314371,
                            "question_id": 120392,
                            "option_text": "(a) : Random Local Attention,(b) : Strided Local Attention, (c) : Sparse Block Attention, (d) : Local + Global Attention",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:04:20.000000Z",
                            "updated_at": "2025-12-13T07:04:20.000000Z",
                            "option_number": 6406534761296,
                            "option_image_url": null
                        },
                        {
                            "id": 314372,
                            "question_id": 120392,
                            "option_text": "(a) : Strided Local Attention,(b) : Local + Global Attention, (c) : Random Local Attention, (d) : Sparse Block Attention",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-12-13T07:04:20.000000Z",
                            "updated_at": "2025-12-13T07:04:20.000000Z",
                            "option_number": 6406534761297,
                            "option_image_url": null
                        },
                        {
                            "id": 314373,
                            "question_id": 120392,
                            "option_text": "(a) : Strided Local Attention,(b) : Random Local Attention, (c) : Local + Global Attention, (d) : Sparse Block Attention",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:04:20.000000Z",
                            "updated_at": "2025-12-13T07:04:20.000000Z",
                            "option_number": 6406534761298,
                            "option_image_url": null
                        },
                        {
                            "id": 314374,
                            "question_id": 120392,
                            "option_text": "(a) : Sparse Block Attention,(b) : Local + Global Attention, (c) : Strided Local Attention, (d) : Random Local Attention",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:04:20.000000Z",
                            "updated_at": "2025-12-13T07:04:20.000000Z",
                            "option_number": 6406534761299,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 120393,
                    "exam_id": 3,
                    "question_paper_id": 388,
                    "question_number": 206,
                    "question_text_1": "Which of the following preprocessing steps are commonly used when preparing data for transformer models like BERT?",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-12-13T07:04:20.000000Z",
                    "updated_at": "2025-12-13T07:04:20.000000Z",
                    "question_num_long": 6406531424289,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "242c3711de99413b18b0a4a11c7286a8",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "d574becd-9d5b-4c34-85fd-31857a0c7d68",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following preprocessing steps are commonly used when preparing data for transformer models like BERT?"
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [
                        {
                            "id": 314375,
                            "question_id": 120393,
                            "option_text": "Adding special tokens such as [CLS] and [SEP] to the sequence",
                            "option_image": "",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2025-12-13T07:04:20.000000Z",
                            "updated_at": "2025-12-13T07:04:20.000000Z",
                            "option_number": 6406534761300,
                            "option_image_url": null
                        },
                        {
                            "id": 314376,
                            "question_id": 120393,
                            "option_text": "Splitting tokens into subword units using a model-specific tokenizer",
                            "option_image": "",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2025-12-13T07:04:20.000000Z",
                            "updated_at": "2025-12-13T07:04:20.000000Z",
                            "option_number": 6406534761301,
                            "option_image_url": null
                        },
                        {
                            "id": 314377,
                            "question_id": 120393,
                            "option_text": "Removing all punctuation marks to ensure cleaner embeddings",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:04:20.000000Z",
                            "updated_at": "2025-12-13T07:04:20.000000Z",
                            "option_number": 6406534761302,
                            "option_image_url": null
                        },
                        {
                            "id": 314378,
                            "question_id": 120393,
                            "option_text": "Adding positional information to each token embedding",
                            "option_image": "",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2025-12-13T07:04:20.000000Z",
                            "updated_at": "2025-12-13T07:04:20.000000Z",
                            "option_number": 6406534761303,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 120394,
                    "exam_id": 3,
                    "question_paper_id": 388,
                    "question_number": 207,
                    "question_text_1": "Which modifications are used in transformers to handle longer sequences efficiently?",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-12-13T07:04:20.000000Z",
                    "updated_at": "2025-12-13T07:04:20.000000Z",
                    "question_num_long": 6406531424290,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "7cb9798f1849fbb399382c94db09a47a",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "fadf296d-2759-4066-a402-cfa6cd6a9c76",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which modifications are used in transformers to handle longer sequences efficiently?"
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [
                        {
                            "id": 314379,
                            "question_id": 120394,
                            "option_text": "Using sparse attention patterns to reduce computational complexity",
                            "option_image": "",
                            "score": "1.500",
                            "is_correct": 1,
                            "created_at": "2025-12-13T07:04:20.000000Z",
                            "updated_at": "2025-12-13T07:04:20.000000Z",
                            "option_number": 6406534761304,
                            "option_image_url": null
                        },
                        {
                            "id": 314380,
                            "question_id": 120394,
                            "option_text": "Applying low-rank matrix factorization to approximate attention",
                            "option_image": "",
                            "score": "1.500",
                            "is_correct": 1,
                            "created_at": "2025-12-13T07:04:20.000000Z",
                            "updated_at": "2025-12-13T07:04:20.000000Z",
                            "option_number": 6406534761305,
                            "option_image_url": null
                        },
                        {
                            "id": 314381,
                            "question_id": 120394,
                            "option_text": "Increasing only the feed-forward network width without modifying attention",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:04:20.000000Z",
                            "updated_at": "2025-12-13T07:04:20.000000Z",
                            "option_number": 6406534761306,
                            "option_image_url": null
                        },
                        {
                            "id": 314382,
                            "question_id": 120394,
                            "option_text": "Replacing the softmax function in attention with other activation function forfaster training",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:04:20.000000Z",
                            "updated_at": "2025-12-13T07:04:20.000000Z",
                            "option_number": 6406534761307,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 120395,
                    "exam_id": 3,
                    "question_paper_id": 388,
                    "question_number": 208,
                    "question_text_1": "In Transformer models that use relative position embeddings (such as in Transformer-XL or T5), clipping is often applied to the relative position indices. Which of the following statements about clipping in relative position embeddings are correct?",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-12-13T07:04:20.000000Z",
                    "updated_at": "2025-12-13T07:04:20.000000Z",
                    "question_num_long": 6406531424291,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "90638b11b15df05d632dea7613653ea5",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "69760c51-23d4-4d59-b666-219cb010fd8f",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "In Transformer models that use relative position embeddings (such as in Transformer-XL or T5), clipping is often applied to the relative position indices. Which of the following statements about clipping in relative position embeddings are correct?"
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [
                        {
                            "id": 314383,
                            "question_id": 120395,
                            "option_text": "Clipping ensures that very large relative distances are mapped to a fixedmaximum distance.",
                            "option_image": "",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2025-12-13T07:04:20.000000Z",
                            "updated_at": "2025-12-13T07:04:20.000000Z",
                            "option_number": 6406534761308,
                            "option_image_url": null
                        },
                        {
                            "id": 314384,
                            "question_id": 120395,
                            "option_text": "Without clipping, the model would require embeddings for every possiblerelative distance, which is infeasible for long sequences.",
                            "option_image": "",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2025-12-13T07:04:20.000000Z",
                            "updated_at": "2025-12-13T07:04:20.000000Z",
                            "option_number": 6406534761309,
                            "option_image_url": null
                        },
                        {
                            "id": 314385,
                            "question_id": 120395,
                            "option_text": "Clipping increases the precision of embeddings for large relative distances.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:04:20.000000Z",
                            "updated_at": "2025-12-13T07:04:20.000000Z",
                            "option_number": 6406534761310,
                            "option_image_url": null
                        },
                        {
                            "id": 314386,
                            "question_id": 120395,
                            "option_text": "Clipping introduces an upper bound k such that all distances greater than kare mapped to the same index.",
                            "option_image": "",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2025-12-13T07:04:20.000000Z",
                            "updated_at": "2025-12-13T07:04:20.000000Z",
                            "option_number": 6406534761311,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 120396,
                    "exam_id": 3,
                    "question_paper_id": 388,
                    "question_number": 209,
                    "question_text_1": null,
                    "question_image_1": "iZcwc7Zq5QkRyJesULmp6ErT1ktFAsq73wy0r4xkc1ee1MOz2N.png",
                    "question_type": "SA",
                    "total_mark": "2.00",
                    "value_start": "6",
                    "value_end": null,
                    "created_at": "2025-12-13T07:04:20.000000Z",
                    "updated_at": "2025-12-13T07:04:20.000000Z",
                    "question_num_long": 6406531424292,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "35a88990e05bad17d59eca169ff6ccf5",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "e76215d9-1b96-4639-a978-6f14c21f3dc9",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/iZcwc7Zq5QkRyJesULmp6ErT1ktFAsq73wy0r4xkc1ee1MOz2N.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 120397,
                    "exam_id": 3,
                    "question_paper_id": 388,
                    "question_number": 0,
                    "question_text_1": null,
                    "question_image_1": "lfS2L6SCvef1MU35bjwEygamJgNO7zWsiri6wwhpPgUVnvpo8o.png",
                    "question_type": "COMPREHENSION",
                    "total_mark": "0.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-12-13T07:04:20.000000Z",
                    "updated_at": "2025-12-13T07:04:20.000000Z",
                    "question_num_long": 6406531424293,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 0,
                    "hash": "8e3417063afa6c2475443302b56f0051",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "a01c5d20-ffdb-4663-b63b-9def8575ebdc",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/lfS2L6SCvef1MU35bjwEygamJgNO7zWsiri6wwhpPgUVnvpo8o.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 120398,
                    "exam_id": 3,
                    "question_paper_id": 388,
                    "question_number": 210,
                    "question_text_1": "For the input \u201cyou enjoy tea often\u201d, compute the final representation of the word \u201cenjoy\u201d after the attention layer (i.e., after applying WQ, WK, WV , attention weights, and WO). Enter the sum of the elements in the resulting vector.",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "3.00",
                    "value_start": "0.92",
                    "value_end": "1.0",
                    "created_at": "2025-12-13T07:04:20.000000Z",
                    "updated_at": "2025-12-13T07:04:20.000000Z",
                    "question_num_long": 6406531424294,
                    "answer_type": "Range",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "83a8e085fc583041b333d4d975cde321",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 120397,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "ee650bec-7d9b-4ef4-b7f2-c2a87511bcff",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "For the input \u201cyou enjoy tea often\u201d, compute the final representation of the word \u201cenjoy\u201d after the attention layer (i.e., after applying WQ, WK, WV , attention weights, and WO). Enter the sum of the elements in the resulting vector."
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": {
                        "id": 120397,
                        "exam_id": 3,
                        "question_paper_id": 388,
                        "question_number": 0,
                        "question_text_1": null,
                        "question_image_1": "lfS2L6SCvef1MU35bjwEygamJgNO7zWsiri6wwhpPgUVnvpo8o.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2025-12-13T07:04:20.000000Z",
                        "updated_at": "2025-12-13T07:04:20.000000Z",
                        "question_num_long": 6406531424293,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "8e3417063afa6c2475443302b56f0051",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "a01c5d20-ffdb-4663-b63b-9def8575ebdc",
                        "question_image_url": [
                            "/question_images/lfS2L6SCvef1MU35bjwEygamJgNO7zWsiri6wwhpPgUVnvpo8o.png"
                        ],
                        "question_texts": null
                    }
                },
                {
                    "id": 120399,
                    "exam_id": 3,
                    "question_paper_id": 388,
                    "question_number": 211,
                    "question_text_1": "Suppose the input sentence is \u201ctea you enjoy often\u201d. Using the same matrices and processing method, what is the attention score (i.e., softmax entry from A) for the query word \u201ctea\u201d attending to key word \u201coften\u201d?",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "2.00",
                    "value_start": "0.04",
                    "value_end": "0.10",
                    "created_at": "2025-12-13T07:04:20.000000Z",
                    "updated_at": "2025-12-13T07:04:20.000000Z",
                    "question_num_long": 6406531424295,
                    "answer_type": "Range",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "dba843e519bb36138b5311cd61797da8",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 120397,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "ea2e905c-aeb8-4646-995e-610269cd71f2",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Suppose the input sentence is \u201ctea you enjoy often\u201d. Using the same matrices and processing method, what is the attention score (i.e., softmax entry from A) for the query word \u201ctea\u201d attending to key word \u201coften\u201d?"
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": {
                        "id": 120397,
                        "exam_id": 3,
                        "question_paper_id": 388,
                        "question_number": 0,
                        "question_text_1": null,
                        "question_image_1": "lfS2L6SCvef1MU35bjwEygamJgNO7zWsiri6wwhpPgUVnvpo8o.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2025-12-13T07:04:20.000000Z",
                        "updated_at": "2025-12-13T07:04:20.000000Z",
                        "question_num_long": 6406531424293,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "8e3417063afa6c2475443302b56f0051",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "a01c5d20-ffdb-4663-b63b-9def8575ebdc",
                        "question_image_url": [
                            "/question_images/lfS2L6SCvef1MU35bjwEygamJgNO7zWsiri6wwhpPgUVnvpo8o.png"
                        ],
                        "question_texts": null
                    }
                },
                {
                    "id": 120400,
                    "exam_id": 3,
                    "question_paper_id": 388,
                    "question_number": 0,
                    "question_text_1": "  Based on the above data, answer the given subquestions.",
                    "question_image_1": "M6Orzv1jnOcD36x9hufZAIfFFS5oCKztDH9MbHQgLLnRJ87D3C.png",
                    "question_type": "COMPREHENSION",
                    "total_mark": "0.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-12-13T07:04:20.000000Z",
                    "updated_at": "2025-12-13T07:04:20.000000Z",
                    "question_num_long": 6406531424302,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 0,
                    "hash": "eac62d1b2c493ac254652ce669eababf",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "397784b9-4153-4212-9d25-c894d18594d3",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/M6Orzv1jnOcD36x9hufZAIfFFS5oCKztDH9MbHQgLLnRJ87D3C.png"
                    ],
                    "question_texts": [
                        "  Based on the above data, answer the given subquestions."
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 120401,
                    "exam_id": 3,
                    "question_paper_id": 388,
                    "question_number": 212,
                    "question_text_1": "Choose the correct representation of \u03c0 for the given mask image.",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-12-13T07:04:20.000000Z",
                    "updated_at": "2025-12-13T07:04:20.000000Z",
                    "question_num_long": 6406531424303,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "5d05b6bfc13ed729afaf6fdc857d0bea",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 120400,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "ced366ca-308f-495e-a82d-27d6b5f93992",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Choose the correct representation of \u03c0 for the given mask image."
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [
                        {
                            "id": 314387,
                            "question_id": 120401,
                            "option_text": "\u03c0 = (2, 1, 3, 4, 0)",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:04:20.000000Z",
                            "updated_at": "2025-12-13T07:04:20.000000Z",
                            "option_number": 6406534761326,
                            "option_image_url": null
                        },
                        {
                            "id": 314388,
                            "question_id": 120401,
                            "option_text": "\u03c0 = (0, 4, 3, 1, 2)",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:04:20.000000Z",
                            "updated_at": "2025-12-13T07:04:20.000000Z",
                            "option_number": 6406534761327,
                            "option_image_url": null
                        },
                        {
                            "id": 314389,
                            "question_id": 120401,
                            "option_text": "\u03c0 = (0, 3, 4, 2, 1)",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-12-13T07:04:20.000000Z",
                            "updated_at": "2025-12-13T07:04:20.000000Z",
                            "option_number": 6406534761328,
                            "option_image_url": null
                        },
                        {
                            "id": 314390,
                            "question_id": 120401,
                            "option_text": "All of these",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:04:20.000000Z",
                            "updated_at": "2025-12-13T07:04:20.000000Z",
                            "option_number": 6406534761329,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": {
                        "id": 120400,
                        "exam_id": 3,
                        "question_paper_id": 388,
                        "question_number": 0,
                        "question_text_1": "  Based on the above data, answer the given subquestions.",
                        "question_image_1": "M6Orzv1jnOcD36x9hufZAIfFFS5oCKztDH9MbHQgLLnRJ87D3C.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2025-12-13T07:04:20.000000Z",
                        "updated_at": "2025-12-13T07:04:20.000000Z",
                        "question_num_long": 6406531424302,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "eac62d1b2c493ac254652ce669eababf",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "397784b9-4153-4212-9d25-c894d18594d3",
                        "question_image_url": [
                            "/question_images/M6Orzv1jnOcD36x9hufZAIfFFS5oCKztDH9MbHQgLLnRJ87D3C.png"
                        ],
                        "question_texts": [
                            "  Based on the above data, answer the given subquestions."
                        ]
                    }
                },
                {
                    "id": 120402,
                    "exam_id": 3,
                    "question_paper_id": 388,
                    "question_number": 213,
                    "question_text_1": "How many permutations of \u03c0 are possible for n = 5?",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "1.00",
                    "value_start": "120",
                    "value_end": null,
                    "created_at": "2025-12-13T07:04:20.000000Z",
                    "updated_at": "2025-12-13T07:04:20.000000Z",
                    "question_num_long": 6406531424304,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "321f9b968b49387b9b724789bd3f4002",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 120400,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "b1e6ee1f-a6b6-4f06-8434-2010ff7b72ed",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "How many permutations of \u03c0 are possible for n = 5?"
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": {
                        "id": 120400,
                        "exam_id": 3,
                        "question_paper_id": 388,
                        "question_number": 0,
                        "question_text_1": "  Based on the above data, answer the given subquestions.",
                        "question_image_1": "M6Orzv1jnOcD36x9hufZAIfFFS5oCKztDH9MbHQgLLnRJ87D3C.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2025-12-13T07:04:20.000000Z",
                        "updated_at": "2025-12-13T07:04:20.000000Z",
                        "question_num_long": 6406531424302,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "eac62d1b2c493ac254652ce669eababf",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "397784b9-4153-4212-9d25-c894d18594d3",
                        "question_image_url": [
                            "/question_images/M6Orzv1jnOcD36x9hufZAIfFFS5oCKztDH9MbHQgLLnRJ87D3C.png"
                        ],
                        "question_texts": [
                            "  Based on the above data, answer the given subquestions."
                        ]
                    }
                },
                {
                    "id": 120403,
                    "exam_id": 3,
                    "question_paper_id": 388,
                    "question_number": 214,
                    "question_text_1": "What percentage of entries in the attention matrix are zero (i.e., the sparsity)?",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "2.00",
                    "value_start": "80",
                    "value_end": null,
                    "created_at": "2025-12-13T07:04:20.000000Z",
                    "updated_at": "2025-12-13T07:04:20.000000Z",
                    "question_num_long": 6406531424305,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "9b53a6012fceeb1e1b5d869a59295cbb",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 120400,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "1dd458fa-09ab-4582-92b4-2a5c443c473b",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "What percentage of entries in the attention matrix are zero (i.e., the sparsity)?"
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": {
                        "id": 120400,
                        "exam_id": 3,
                        "question_paper_id": 388,
                        "question_number": 0,
                        "question_text_1": "  Based on the above data, answer the given subquestions.",
                        "question_image_1": "M6Orzv1jnOcD36x9hufZAIfFFS5oCKztDH9MbHQgLLnRJ87D3C.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2025-12-13T07:04:20.000000Z",
                        "updated_at": "2025-12-13T07:04:20.000000Z",
                        "question_num_long": 6406531424302,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "eac62d1b2c493ac254652ce669eababf",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "397784b9-4153-4212-9d25-c894d18594d3",
                        "question_image_url": [
                            "/question_images/M6Orzv1jnOcD36x9hufZAIfFFS5oCKztDH9MbHQgLLnRJ87D3C.png"
                        ],
                        "question_texts": [
                            "  Based on the above data, answer the given subquestions."
                        ]
                    }
                },
                {
                    "id": 120404,
                    "exam_id": 3,
                    "question_paper_id": 388,
                    "question_number": 0,
                    "question_text_1": "  Based on the above data, answer the given subquestions.",
                    "question_image_1": "3TmFOK32BMNcqMNcwZDHu3dEKmVXdqbdJvq4EMv8ylZNRL4g9x.png",
                    "question_type": "COMPREHENSION",
                    "total_mark": "0.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-12-13T07:04:20.000000Z",
                    "updated_at": "2025-12-13T07:04:20.000000Z",
                    "question_num_long": 6406531424296,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 0,
                    "hash": "f7ab4de1986238572b9c44c1f6025c97",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "42e203c0-a09c-4a29-841b-994c418eaf4f",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/3TmFOK32BMNcqMNcwZDHu3dEKmVXdqbdJvq4EMv8ylZNRL4g9x.png"
                    ],
                    "question_texts": [
                        "  Based on the above data, answer the given subquestions."
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 120405,
                    "exam_id": 3,
                    "question_paper_id": 388,
                    "question_number": 215,
                    "question_text_1": null,
                    "question_image_1": "cADYno8v836OXcwSpXx7gtgSdSKaKKwwIXu9ZHHm5UUfIEwc32.png",
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-12-13T07:04:20.000000Z",
                    "updated_at": "2025-12-13T07:04:20.000000Z",
                    "question_num_long": 6406531424297,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "221afedd6de6271101512d554c0ce03b",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 120404,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "46ec999d-7f0d-4082-b32e-45f7e01c6524",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/cADYno8v836OXcwSpXx7gtgSdSKaKKwwIXu9ZHHm5UUfIEwc32.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [
                        {
                            "id": 314391,
                            "question_id": 120405,
                            "option_text": "(0, 1, 2, 3, 4, 5)",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:04:20.000000Z",
                            "updated_at": "2025-12-13T07:04:20.000000Z",
                            "option_number": 6406534761315,
                            "option_image_url": null
                        },
                        {
                            "id": 314392,
                            "question_id": 120405,
                            "option_text": "(-1, 0, 1, 2, 3, 4)",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:04:20.000000Z",
                            "updated_at": "2025-12-13T07:04:20.000000Z",
                            "option_number": 6406534761316,
                            "option_image_url": null
                        },
                        {
                            "id": 314393,
                            "question_id": 120405,
                            "option_text": "(-3, -2, -1, 0, 1, 2)",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:04:20.000000Z",
                            "updated_at": "2025-12-13T07:04:20.000000Z",
                            "option_number": 6406534761317,
                            "option_image_url": null
                        },
                        {
                            "id": 314394,
                            "question_id": 120405,
                            "option_text": "(-2, -1, 0, 1, 2, 3)",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-12-13T07:04:20.000000Z",
                            "updated_at": "2025-12-13T07:04:20.000000Z",
                            "option_number": 6406534761318,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": {
                        "id": 120404,
                        "exam_id": 3,
                        "question_paper_id": 388,
                        "question_number": 0,
                        "question_text_1": "  Based on the above data, answer the given subquestions.",
                        "question_image_1": "3TmFOK32BMNcqMNcwZDHu3dEKmVXdqbdJvq4EMv8ylZNRL4g9x.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2025-12-13T07:04:20.000000Z",
                        "updated_at": "2025-12-13T07:04:20.000000Z",
                        "question_num_long": 6406531424296,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "f7ab4de1986238572b9c44c1f6025c97",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "42e203c0-a09c-4a29-841b-994c418eaf4f",
                        "question_image_url": [
                            "/question_images/3TmFOK32BMNcqMNcwZDHu3dEKmVXdqbdJvq4EMv8ylZNRL4g9x.png"
                        ],
                        "question_texts": [
                            "  Based on the above data, answer the given subquestions."
                        ]
                    }
                },
                {
                    "id": 120406,
                    "exam_id": 3,
                    "question_paper_id": 388,
                    "question_number": 216,
                    "question_text_1": null,
                    "question_image_1": "Ee1qOr0ZeUwKfZcSscVsgpA9wMg3orFFyA0Z5WrT8fUPFF7Xty.png",
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-12-13T07:04:20.000000Z",
                    "updated_at": "2025-12-13T07:04:20.000000Z",
                    "question_num_long": 6406531424298,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "691da25797773fb742e3ca8428cba524",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 120404,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "da9c0dbe-98c7-42ee-9e0d-c341f870b6b4",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/Ee1qOr0ZeUwKfZcSscVsgpA9wMg3orFFyA0Z5WrT8fUPFF7Xty.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [
                        {
                            "id": 314395,
                            "question_id": 120406,
                            "option_text": "[\u22120.4,\u22120.4,\u22120.4,\u22120.4]",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:04:20.000000Z",
                            "updated_at": "2025-12-13T07:04:20.000000Z",
                            "option_number": 6406534761319,
                            "option_image_url": null
                        },
                        {
                            "id": 314396,
                            "question_id": 120406,
                            "option_text": "[\u22120.1,\u22120.1,\u22120.1,\u22120.1]",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:04:20.000000Z",
                            "updated_at": "2025-12-13T07:04:20.000000Z",
                            "option_number": 6406534761320,
                            "option_image_url": null
                        },
                        {
                            "id": 314397,
                            "question_id": 120406,
                            "option_text": "[\u22120.8,\u22120.8,\u22120.8,\u22120.8]",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-12-13T07:04:20.000000Z",
                            "updated_at": "2025-12-13T07:04:20.000000Z",
                            "option_number": 6406534761321,
                            "option_image_url": null
                        },
                        {
                            "id": 314398,
                            "question_id": 120406,
                            "option_text": "[\u22120.2,\u22120.2,\u22120.2,\u22120.2]",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-12-13T07:04:20.000000Z",
                            "updated_at": "2025-12-13T07:04:20.000000Z",
                            "option_number": 6406534761322,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": {
                        "id": 120404,
                        "exam_id": 3,
                        "question_paper_id": 388,
                        "question_number": 0,
                        "question_text_1": "  Based on the above data, answer the given subquestions.",
                        "question_image_1": "3TmFOK32BMNcqMNcwZDHu3dEKmVXdqbdJvq4EMv8ylZNRL4g9x.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2025-12-13T07:04:20.000000Z",
                        "updated_at": "2025-12-13T07:04:20.000000Z",
                        "question_num_long": 6406531424296,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "f7ab4de1986238572b9c44c1f6025c97",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "42e203c0-a09c-4a29-841b-994c418eaf4f",
                        "question_image_url": [
                            "/question_images/3TmFOK32BMNcqMNcwZDHu3dEKmVXdqbdJvq4EMv8ylZNRL4g9x.png"
                        ],
                        "question_texts": [
                            "  Based on the above data, answer the given subquestions."
                        ]
                    }
                },
                {
                    "id": 120407,
                    "exam_id": 3,
                    "question_paper_id": 388,
                    "question_number": 217,
                    "question_text_1": null,
                    "question_image_1": "09v84HQpgRF4Y3dRtqtOuaoIjmOTVGzuAfmymV0OXZRSTM11sH.png",
                    "question_type": "SA",
                    "total_mark": "3.00",
                    "value_start": "15.2",
                    "value_end": null,
                    "created_at": "2025-12-13T07:04:20.000000Z",
                    "updated_at": "2025-12-13T07:04:20.000000Z",
                    "question_num_long": 6406531424299,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "1f02794f13cafa5e46a1092a00ea893c",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 120404,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "caad671e-ad06-420d-8220-042723298b81",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/09v84HQpgRF4Y3dRtqtOuaoIjmOTVGzuAfmymV0OXZRSTM11sH.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": {
                        "id": 120404,
                        "exam_id": 3,
                        "question_paper_id": 388,
                        "question_number": 0,
                        "question_text_1": "  Based on the above data, answer the given subquestions.",
                        "question_image_1": "3TmFOK32BMNcqMNcwZDHu3dEKmVXdqbdJvq4EMv8ylZNRL4g9x.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2025-12-13T07:04:20.000000Z",
                        "updated_at": "2025-12-13T07:04:20.000000Z",
                        "question_num_long": 6406531424296,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "f7ab4de1986238572b9c44c1f6025c97",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "42e203c0-a09c-4a29-841b-994c418eaf4f",
                        "question_image_url": [
                            "/question_images/3TmFOK32BMNcqMNcwZDHu3dEKmVXdqbdJvq4EMv8ylZNRL4g9x.png"
                        ],
                        "question_texts": [
                            "  Based on the above data, answer the given subquestions."
                        ]
                    }
                },
                {
                    "id": 120408,
                    "exam_id": 3,
                    "question_paper_id": 388,
                    "question_number": 218,
                    "question_text_1": null,
                    "question_image_1": "BkXslD4HUnC9a24h86cw7RVU11GEjQzXDoo4p6pcHu4NFiCAs5.png",
                    "question_type": "SA",
                    "total_mark": "2.00",
                    "value_start": "23.7",
                    "value_end": "24.3",
                    "created_at": "2025-12-13T07:04:20.000000Z",
                    "updated_at": "2025-12-13T07:04:20.000000Z",
                    "question_num_long": 6406531424300,
                    "answer_type": "Range",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "7d1b7d897f6c4e859bb216bfb5e5d9c5",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 120404,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "d962b5c5-b3f3-40cd-8cc2-568f06b7d3c3",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/BkXslD4HUnC9a24h86cw7RVU11GEjQzXDoo4p6pcHu4NFiCAs5.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": {
                        "id": 120404,
                        "exam_id": 3,
                        "question_paper_id": 388,
                        "question_number": 0,
                        "question_text_1": "  Based on the above data, answer the given subquestions.",
                        "question_image_1": "3TmFOK32BMNcqMNcwZDHu3dEKmVXdqbdJvq4EMv8ylZNRL4g9x.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2025-12-13T07:04:20.000000Z",
                        "updated_at": "2025-12-13T07:04:20.000000Z",
                        "question_num_long": 6406531424296,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "f7ab4de1986238572b9c44c1f6025c97",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "42e203c0-a09c-4a29-841b-994c418eaf4f",
                        "question_image_url": [
                            "/question_images/3TmFOK32BMNcqMNcwZDHu3dEKmVXdqbdJvq4EMv8ylZNRL4g9x.png"
                        ],
                        "question_texts": [
                            "  Based on the above data, answer the given subquestions."
                        ]
                    }
                },
                {
                    "id": 120409,
                    "exam_id": 3,
                    "question_paper_id": 388,
                    "question_number": 219,
                    "question_text_1": null,
                    "question_image_1": "YitvUHr2R544OxyiM4tL2rVSq7iDTSEn4X6U7ldOYKWezxLIJN.png",
                    "question_type": "SA",
                    "total_mark": "3.00",
                    "value_start": "39",
                    "value_end": null,
                    "created_at": "2025-12-13T07:04:20.000000Z",
                    "updated_at": "2025-12-13T07:04:20.000000Z",
                    "question_num_long": 6406531424301,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "2a315189ba0cf75d1dc5507a18808e33",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 120404,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "0e05f2b2-2631-4303-aa80-d00e2851226a",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/YitvUHr2R544OxyiM4tL2rVSq7iDTSEn4X6U7ldOYKWezxLIJN.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": {
                        "id": 120404,
                        "exam_id": 3,
                        "question_paper_id": 388,
                        "question_number": 0,
                        "question_text_1": "  Based on the above data, answer the given subquestions.",
                        "question_image_1": "3TmFOK32BMNcqMNcwZDHu3dEKmVXdqbdJvq4EMv8ylZNRL4g9x.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2025-12-13T07:04:20.000000Z",
                        "updated_at": "2025-12-13T07:04:20.000000Z",
                        "question_num_long": 6406531424296,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "f7ab4de1986238572b9c44c1f6025c97",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "42e203c0-a09c-4a29-841b-994c418eaf4f",
                        "question_image_url": [
                            "/question_images/3TmFOK32BMNcqMNcwZDHu3dEKmVXdqbdJvq4EMv8ylZNRL4g9x.png"
                        ],
                        "question_texts": [
                            "  Based on the above data, answer the given subquestions."
                        ]
                    }
                }
            ]
        },
        "summary": "Here\u2019s a structured summary of the **core topics, concepts, principles, and equations** for the **Large Language Models (LLM) exam**, along with **Mermaid knowledge graphs** to visualize relationships.\n\n---\n\n---\n\n### **1. Core Topics & Concepts**\n#### **A. Tokenization & Subword Models**\n- **Viterbi Algorithm for Tokenization**:\n  - Goal: Find the most probable segmentation of a word into subword tokens using **log-probabilities**.\n  - **Equation**:\n    \\[\n    \\text{Score(segmentation)} = \\sum \\text{log-probabilities of subwords}\n    \\]\n  - **Example**: For \"sunshine,\" the optimal segmentation is `[\"su\", \"nshine\"]` (log-prob = -0.3 + -0.4 = -0.7), which is better than `[\"sun\", \"shine\"]` (log-prob = -0.5 + -0.7 = -1.2).\n\n- **Subword Vocabulary**:\n  - Subwords are stored with associated log-probabilities (e.g., `sun: -0.5`, `shine: -0.7`).\n  - **SentencePiece Tokenizer**: Uses unigram or BPE (Byte Pair Encoding) for subword segmentation.\n\n---\n\n#### **B. Attention Mechanisms**\n##### **1. Causal Language Modeling (CLM)**\n- **Attention Mask for Autoregressive Models (e.g., GPT)**:\n  - Future tokens are masked (set to `-\u221e` or `0` in the attention matrix).\n  - **Mask Matrix (T=4)**:\n    \\[\n    \\begin{bmatrix}\n    0 & -\\infty & -\\infty & -\\infty \\\\\n    0 & 0 & -\\infty & -\\infty \\\\\n    0 & 0 & 0 & -\\infty \\\\\n    0 & 0 & 0 & 0\n    \\end{bmatrix}\n    \\]\n  - **Key Idea**: Each token can only attend to itself and previous tokens.\n\n##### **2. Attention Variants**\n| **Variant**               | **Description**                                                                 | **Mask Pattern**                                                                 |\n|---------------------------|---------------------------------------------------------------------------------|---------------------------------------------------------------------------------|\n| **Strided Local Attention** | Each token attends to a fixed window of nearby tokens.                          | Diagonal bands of `1`s.                                                         |\n| **Random Local Attention**  | Each token attends to a random subset of tokens.                                | Sparse, random `1`s.                                                            |\n| **Sparse Block Attention** | Tokens are divided into blocks; each block attends to a few other blocks.       | Block-diagonal `1`s.                                                            |\n| **Local + Global Attention** | Combines local attention with a few global tokens (e.g., [CLS]).              | Diagonal + global columns/rows of `1`s.                                         |\n\n##### **3. Block-Recursive Attention (e.g., Transformer-XL)**\n- **Relative Position Embeddings**:\n  - Instead of absolute positions, use **relative distances** (`j - i`).\n  - **Clipping**: Large relative distances are clipped to a maximum value `k` to limit vocabulary size.\n    - **Why?** Avoids an infinite number of embeddings for long sequences.\n  - **Equation**:\n    \\[\n    \\text{Clipped Relative Position} = \\text{min}(|j - i|, k)\n    \\]\n- **Block-Sparse Attention**:\n  - Divide sequence into `n` blocks.\n  - Each query block attends to a **permutation `\u03c0` of key blocks**.\n  - **Mask Matrix**:\n    \\[\n    M_{ij} = 1 \\text{ if } \\pi\\left(\\left\\lfloor \\frac{i \\cdot n}{T} \\right\\rfloor\\right) = \\left\\lfloor \\frac{j \\cdot n}{T} \\right\\rfloor\n    \\]\n  - **Sparsity**: Only `(T^2 / n)` entries are non-zero (reduces computation).\n\n---\n\n#### **C. Transformer Preprocessing**\n- **Special Tokens**:\n  - `[CLS]`: Classification token (used in BERT).\n  - `[SEP]`: Separator token (for sentence pairs).\n- **Subword Tokenization**:\n  - Use model-specific tokenizers (e.g., WordPiece for BERT, SentencePiece for T5).\n- **Positional Encodings**:\n  - Add positional information to token embeddings (absolute or relative).\n\n---\n\n#### **D. Sampling Methods**\n##### **1. Top-p (Nucleus) Sampling**\n- **Goal**: Sample from the smallest set of tokens whose cumulative probability \u2265 `p`.\n- **Steps**:\n  1. Sort token probabilities in descending order.\n  2. Select the smallest set where `sum(probabilities) \u2265 p`.\n  3. Sample uniformly from this set.\n- **Example**: For `p = 0.7` and probabilities `[0.06, 0.20, 0.14, 0.06, 0.09, 0.08, 0.05, 0.15, 0.06, 0.11]`, the nucleus includes the top 6 tokens (`sum = 0.79`).\n\n##### **2. Temperature Scaling**\n- **Equation**:\n  \\[\n  p_i = \\frac{\\exp(\\logits_i / T)}{\\sum_j \\exp(\\logits_j / T)}\n  \\]\n  - `T > 1`: Smoother distribution (more randomness).\n  - `T < 1`: Sharper distribution (more deterministic).\n\n---\n\n#### **E. Efficient Attention for Long Sequences**\n| **Method**               | **Description**                                                                 | **Complexity**       |\n|--------------------------|---------------------------------------------------------------------------------|----------------------|\n| **Sparse Attention**      | Only compute attention for a subset of tokens (e.g., local windows).            | `O(T \u00b7 k)`           |\n| **Low-Rank Attention**   | Approximate attention matrix with low-rank factorization.                       | `O(T \u00b7 r)`           |\n| **Memory-Compressed Attention** | Use past key-values (e.g., Transformer-XL).                                   | `O(T \u00b7 m)`           |\n| **Linformer**            | Project keys/values to a lower dimension.                                      | `O(T \u00b7 k)`           |\n\n---\n\n#### **F. Relative Position Embeddings**\n##### **1. Naive Relative Positional Embedding**\n- **Equation**:\n  \\[\n  \\boldsymbol{h}_i = \\boldsymbol{x}_i + \\sum_{j=0}^{T-1} \\boldsymbol{p}_{j-i}\n  \\]\n  - `x_i`: Token embedding.\n  - `p_{j-i}`: Relative position embedding for distance `(j - i)`.\n- **Example**: For token \"models\" (`i=1`), the relative positions are `[-1, 0, 1, 2, 3, 4]`.\n\n##### **2. ALiBi (Attention with Linear Biases)**\n- **Equation**:\n  \\[\n  e_{ij} = \\boldsymbol{x}_i W_Q (\\boldsymbol{x}_j W_K)^T + m_h \\cdot (j - i)\n  \\]\n  - `m_h`: Head-specific slope (`m_h = 1/2^h`).\n  - **Effect**: Penalizes attention to distant tokens linearly.\n\n---\n\n#### **G. Attention Computation**\n- **Scaled Dot-Product Attention**:\n  \\[\n  \\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right) V\n  \\]\n- **Multi-Head Attention**:\n  \\[\n  \\text{MultiHead}(Q, K, V) = \\text{Concat}(\\text{head}_1, ..., \\text{head}_h) W_O\n  \\]\n  - Each head computes attention independently.\n\n---\n\n---\n\n### **2. Key Equations**\n| **Concept**               | **Equation**                                                                 |\n|---------------------------|------------------------------------------------------------------------------|\n| **Viterbi Tokenization**  | \\(\\text{Score} = \\sum \\text{log-probabilities of subwords}\\)                 |\n| **Causal Mask**           | \\(M_{ij} = 0 \\text{ if } j > i, -\\infty \\text{ otherwise}\\)                  |\n| **Top-p Sampling**        | \\(\\text{Select smallest set where } \\sum p_i \\geq p\\)                        |\n| **Relative Position**     | \\(\\boldsymbol{h}_i = \\boldsymbol{x}_i + \\sum_{j} \\boldsymbol{p}_{j-i}\\)      |\n| **ALiBi Bias**            | \\(e_{ij} = QK^T + m_h \\cdot (j - i)\\)                                       |\n| **Block-Sparse Mask**     | \\(M_{ij} = 1 \\text{ if } \\pi(\\text{block}(i)) = \\text{block}(j)\\)             |\n| **Attention Score**       | \\(e_{ij} = \\boldsymbol{x}_i W_Q (\\boldsymbol{x}_j W_K + \\boldsymbol{p}_{j-i})^T\\) |\n\n---\n\n---\n\n### **3. Mermaid Knowledge Graphs**\n#### **Graph 1: Tokenization & Subword Models**\n```mermaid\ngraph TD\n    A[Input String] --> B[Subword Vocabulary]\n    B --> C[Log-Probabilities]\n    C --> D[Viterbi Algorithm]\n    D --> E[Optimal Segmentation]\n    E --> F[Token IDs]\n```\n\n#### **Graph 2: Attention Mechanisms**\n```mermaid\ngraph TD\n    A[Attention] --> B[Full Attention]\n    A --> C[Sparse Attention]\n    C --> D[Local Attention]\n    C --> E[Strided Attention]\n    C --> F[Block-Sparse Attention]\n    A --> G[Efficient Attention]\n    G --> H[Low-Rank]\n    G --> I[Memory-Compressed]\n    G --> J[Linformer]\n```\n\n#### **Graph 3: Relative Position Embeddings**\n```mermaid\ngraph TD\n    A[Token Embeddings] --> B[Add Relative Position]\n    B --> C[Naive Relative]\n    B --> D[ALiBi]\n    C --> E[Clipped Distances]\n    D --> F[Linear Bias per Head]\n```\n\n#### **Graph 4: Sampling Methods**\n```mermaid\ngraph TD\n    A[Model Output] --> B[Logits]\n    B --> C[Softmax]\n    C --> D[Top-p Sampling]\n    C --> E[Temperature Scaling]\n    D --> F[Nucleus Tokens]\n    F --> G[Sample Uniformly]\n```\n\n#### **Graph 5: Transformer Preprocessing**\n```mermaid\ngraph TD\n    A[Raw Text] --> B[Tokenization]\n    B --> C[Add Special Tokens]\n    C --> D[Subword Segmentation]\n    D --> E[Positional Encodings]\n    E --> F[Input Embeddings]\n```\n\n#### **Graph 6: Efficient Long-Sequence Attention**\n```mermaid\ngraph TD\n    A[Long Sequence] --> B[Sparse Attention]\n    B --> C[Local Windows]\n    B --> D[Block-Recursive]\n    B --> E[Low-Rank Approximation]\n    D --> F[Relative Positions]\n    F --> G[Clipping]\n```\n\n---\n\n---\n\n### **4. Exam Tips**\n1. **Tokenization**:\n   - Practice Viterbi segmentation with log-probabilities.\n   - Remember: **Lower total log-probability = better segmentation**.\n\n2. **Attention Masks**:\n   - **Causal LM**: Upper-triangular mask with `-\u221e` for future tokens.\n   - **Block-Sparse**: Permutation `\u03c0` defines which blocks attend to which.\n\n3. **Relative Positions**:\n   - For token `i`, relative positions are `(j - i)` for all `j`.\n   - **ALiBi**: Adds a linear bias `m_h * (j - i)` to attention scores.\n\n4. **Sampling**:\n   - **Top-p**: Sort probabilities, cumsum until \u2265 `p`, then sample uniformly.\n   - **Temperature**: Higher `T` = more random; lower `T` = more deterministic.\n\n5. **Efficient Attention**:\n   - **Sparse**: Reduces computation by limiting attention to subsets.\n   - **Low-Rank**: Approximates attention matrix with fewer parameters.\n\n6. **Clipping in Relative Positions**:\n   - Avoids infinite embeddings for long sequences.\n   - Maps distances > `k` to a fixed value.\n\n---\n**Good luck!** Let me know if you'd like deeper dives into any topic.",
        "total_score": "40.00"
    },
    "url": "/question-paper/practise/85/ff1fbf54-6d2",
    "version": "ee3d5d44299e610bd137ea6200db5ac2"
}