{
    "component": "Quizpractise/PractiseQuestionPaper",
    "props": {
        "errors": {},
        "auth": {
            "user": null
        },
        "flash": {
            "error": []
        },
        "banner": null,
        "file_url": "https://saram.blr1.cdn.digitaloceanspaces.com",
        "file_do_url": "https://saram.blr1.cdn.digitaloceanspaces.com",
        "question_paper": {
            "id": 153,
            "group_id": 19,
            "exam_id": 3,
            "total_score": "1.00",
            "duration": 4,
            "created_at": "2024-11-27T22:26:55.000000Z",
            "updated_at": "2024-11-27T22:26:55.000000Z",
            "question_paper_name": "IIT M DEGREE FN EXAM QDB2 28 Apr 2024",
            "question_paper_description": "2024 Apr28: IIT M FN EXAM QDB2",
            "uuid": "a257da7c-11d",
            "year": 2024,
            "is_new": 0,
            "exam": {
                "id": 3,
                "exam_name": "End Term Quiz",
                "created_at": "2024-10-16T08:08:51.000000Z",
                "updated_at": "2024-10-16T08:08:51.000000Z",
                "uuid": "7a6ff569-f50c-40e7-a08b-f5c334392600",
                "en_id": "eyJpdiI6ImlPRG0xSFQ3TC9OUWVxL1RQS1IxZWc9PSIsInZhbHVlIjoiTFhqNUVobmlwSm4yaXVrNmVxSjRwdz09IiwibWFjIjoiYTAxODRmNGFmODMwNDA3MWJiODljNDk4NmYzZTM2YTU4MzdjMWM1NTgzYmEwZmM0NmJmMmVmNzU1MzYyZDI5OSIsInRhZyI6IiJ9"
            },
            "questions": [
                {
                    "id": 45693,
                    "exam_id": 3,
                    "question_paper_id": 153,
                    "question_number": 196,
                    "question_text_1": "THIS IS QUESTION PAPER FOR THE SUBJECT \"DEGREE LEVEL : INTRODUCTION TO LARGE LANGUAGE MODELS (COMPUTER BASED EXAM)\"  ARE YOU SURE YOU HAVE TO WRITE EXAM FOR THIS SUBJECT? CROSS CHECK YOUR HALL TICKET TO CONFIRM THE SUBJECTS TO BE WRITTEN.  (IF IT IS NOT THE CORRECT SUBJECT, PLS CHECK THE SECTION AT THE TOP FOR THE SUBJECTS REGISTERED BY YOU)",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "0.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:56.000000Z",
                    "updated_at": "2024-11-27T22:26:56.000000Z",
                    "question_num_long": 640653821242,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "6a796eacea4331e04fe7e661dcc588b9",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "0961d0c5-b14e-4587-911d-ccf1c7595f87",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "THIS IS QUESTION PAPER FOR THE SUBJECT \"DEGREE LEVEL : INTRODUCTION TO LARGE LANGUAGE MODELS (COMPUTER BASED EXAM)\"  ARE YOU SURE YOU HAVE TO WRITE EXAM FOR THIS SUBJECT? CROSS CHECK YOUR HALL TICKET TO CONFIRM THE SUBJECTS TO BE WRITTEN.  (IF IT IS NOT THE CORRECT SUBJECT, PLS CHECK THE SECTION AT THE TOP FOR THE SUBJECTS REGISTERED BY YOU)"
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [
                        {
                            "id": 121911,
                            "question_id": 45693,
                            "option_text": "YES",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:56.000000Z",
                            "updated_at": "2024-11-27T22:26:56.000000Z",
                            "option_number": 6406532756327,
                            "option_image_url": null
                        },
                        {
                            "id": 121912,
                            "question_id": 45693,
                            "option_text": "NO",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:56.000000Z",
                            "updated_at": "2024-11-27T22:26:56.000000Z",
                            "option_number": 6406532756328,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 45694,
                    "exam_id": 3,
                    "question_paper_id": 153,
                    "question_number": 197,
                    "question_text_1": null,
                    "question_image_1": "OqweufcYyFJRotBL3tdM9Rh7rY08ds7K2oLRHNVz7oOkCKhyrA.png",
                    "question_type": "MCQ",
                    "total_mark": "0.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:56.000000Z",
                    "updated_at": "2024-11-27T22:26:56.000000Z",
                    "question_num_long": 640653821243,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "d237a681447763a94d6f1b0c31d85182",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "aa2291f6-01d5-4446-8873-ddff6a9d52ba",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/OqweufcYyFJRotBL3tdM9Rh7rY08ds7K2oLRHNVz7oOkCKhyrA.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [
                        {
                            "id": 121913,
                            "question_id": 45694,
                            "option_text": "Instruction has been mentioned above.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:56.000000Z",
                            "updated_at": "2024-11-27T22:26:56.000000Z",
                            "option_number": 6406532756329,
                            "option_image_url": null
                        },
                        {
                            "id": 121914,
                            "question_id": 45694,
                            "option_text": "This Instruction is just for a reference & not for an evaluation.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:56.000000Z",
                            "updated_at": "2024-11-27T22:26:56.000000Z",
                            "option_number": 6406532756330,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 45695,
                    "exam_id": 3,
                    "question_paper_id": 153,
                    "question_number": 198,
                    "question_text_1": "BERT stands for",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:56.000000Z",
                    "updated_at": "2024-11-27T22:26:56.000000Z",
                    "question_num_long": 640653821247,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "18443380a9c0d8c4d7fef9ce4b624c03",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "70c63dc8-fbfe-4648-8d15-ca7aa1cac90c",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "BERT stands for"
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [
                        {
                            "id": 121915,
                            "question_id": 45695,
                            "option_text": "Bidirectional Encoder Representation for Text",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:56.000000Z",
                            "updated_at": "2024-11-27T22:26:56.000000Z",
                            "option_number": 6406532756333,
                            "option_image_url": null
                        },
                        {
                            "id": 121916,
                            "question_id": 45695,
                            "option_text": "Bidirectional Encoder Representation from Transformer",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:56.000000Z",
                            "updated_at": "2024-11-27T22:26:56.000000Z",
                            "option_number": 6406532756334,
                            "option_image_url": null
                        },
                        {
                            "id": 121917,
                            "question_id": 45695,
                            "option_text": "Bidirectionaly Extracted Representation from Transformer",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:56.000000Z",
                            "updated_at": "2024-11-27T22:26:56.000000Z",
                            "option_number": 6406532756335,
                            "option_image_url": null
                        },
                        {
                            "id": 121918,
                            "question_id": 45695,
                            "option_text": "Bidirectionaly Extracted Representation of Text",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:56.000000Z",
                            "updated_at": "2024-11-27T22:26:56.000000Z",
                            "option_number": 6406532756336,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 45696,
                    "exam_id": 3,
                    "question_paper_id": 153,
                    "question_number": 199,
                    "question_text_1": "The statement that, in general, position information can also be injected into the attention layers of a transformer model instead of the embedding of input tokens is",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:56.000000Z",
                    "updated_at": "2024-11-27T22:26:56.000000Z",
                    "question_num_long": 640653821263,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "b00bd02566fd8264ecb0aabe2dae1087",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "96c30232-9239-4887-a397-1e8470fdd0cf",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "The statement that, in general, position information can also be injected into the attention layers of a transformer model instead of the embedding of input tokens is"
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [
                        {
                            "id": 121919,
                            "question_id": 45696,
                            "option_text": "TRUE",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:56.000000Z",
                            "updated_at": "2024-11-27T22:26:56.000000Z",
                            "option_number": 6406532756363,
                            "option_image_url": null
                        },
                        {
                            "id": 121920,
                            "question_id": 45696,
                            "option_text": "FALSE",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:56.000000Z",
                            "updated_at": "2024-11-27T22:26:56.000000Z",
                            "option_number": 6406532756364,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 45697,
                    "exam_id": 3,
                    "question_paper_id": 153,
                    "question_number": 200,
                    "question_text_1": null,
                    "question_image_1": "OKYJjxCQDMfU2qzxi8ieSBX83LGOyJon4zjBoTxxMW7uW7jDvj.png",
                    "question_type": "MCQ",
                    "total_mark": "4.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:56.000000Z",
                    "updated_at": "2024-11-27T22:26:56.000000Z",
                    "question_num_long": 640653821262,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "adfd5cfa5a60469bf31d6b27c1553607",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "278089f5-467a-4cba-ba54-923520cba354",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/OKYJjxCQDMfU2qzxi8ieSBX83LGOyJon4zjBoTxxMW7uW7jDvj.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [
                        {
                            "id": 121921,
                            "question_id": 45697,
                            "option_text": "",
                            "option_image": "0HacL1XoJDxbjT6nUCS1yD1tWCBsGwpDc6EE871ZgjXLbKzwim.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:56.000000Z",
                            "updated_at": "2024-11-27T22:26:56.000000Z",
                            "option_number": 6406532756359,
                            "option_image_url": "app/option_images/0HacL1XoJDxbjT6nUCS1yD1tWCBsGwpDc6EE871ZgjXLbKzwim.png"
                        },
                        {
                            "id": 121922,
                            "question_id": 45697,
                            "option_text": "",
                            "option_image": "CaQiAXRITvbg2u3l3sM4TIS5frCmX0zI7wJvbqGpKtv6BcGYsQ.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:56.000000Z",
                            "updated_at": "2024-11-27T22:26:56.000000Z",
                            "option_number": 6406532756360,
                            "option_image_url": "app/option_images/CaQiAXRITvbg2u3l3sM4TIS5frCmX0zI7wJvbqGpKtv6BcGYsQ.png"
                        },
                        {
                            "id": 121923,
                            "question_id": 45697,
                            "option_text": "",
                            "option_image": "UBeOMlTxY6c8JjYKwNtZOUr4UhozVs776q0Ei2z2XhNaV1dAjR.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:56.000000Z",
                            "updated_at": "2024-11-27T22:26:56.000000Z",
                            "option_number": 6406532756361,
                            "option_image_url": "app/option_images/UBeOMlTxY6c8JjYKwNtZOUr4UhozVs776q0Ei2z2XhNaV1dAjR.png"
                        },
                        {
                            "id": 121924,
                            "question_id": 45697,
                            "option_text": "",
                            "option_image": "nWeQCusvBL6JYvFfAHKCWxLfRs6Pt0CMxC17tvkKY0dX3L9XF7.png",
                            "score": "4.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:56.000000Z",
                            "updated_at": "2024-11-27T22:26:56.000000Z",
                            "option_number": 6406532756362,
                            "option_image_url": "app/option_images/nWeQCusvBL6JYvFfAHKCWxLfRs6Pt0CMxC17tvkKY0dX3L9XF7.png"
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 45698,
                    "exam_id": 3,
                    "question_paper_id": 153,
                    "question_number": 201,
                    "question_text_1": null,
                    "question_image_1": "Jph9fxYodbi28X5TafG4JczeMwbjC1V1pzi3iLCGubMsjpppHG.png",
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "somewhere something incredible is waiting be",
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:56.000000Z",
                    "updated_at": "2024-11-27T22:26:56.000000Z",
                    "question_num_long": 640653821258,
                    "answer_type": "Equal",
                    "response_type": "Alphanumeric",
                    "have_answers": 0,
                    "hash": "a43079fe3beb25d1d66dc469841a2511",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "0bdbe568-58f9-44f9-aa33-cbc84c4d745f",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/Jph9fxYodbi28X5TafG4JczeMwbjC1V1pzi3iLCGubMsjpppHG.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 45699,
                    "exam_id": 3,
                    "question_paper_id": 153,
                    "question_number": 0,
                    "question_text_1": "Suppose a GPT model is pre-trained using the Causal Language Modelling (CLM) objective and fine-tuned on a text summarization task. The context length T of the model was kept at 1024 during both pre-training and fine-tuning. Assume that the model uses Absolute Position Embedding (APE) with learnable parameters.  Based on the above data, answer the given subquestions.",
                    "question_image_1": null,
                    "question_type": "COMPREHENSION",
                    "total_mark": "0.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:56.000000Z",
                    "updated_at": "2024-11-27T22:26:56.000000Z",
                    "question_num_long": 640653821255,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 0,
                    "hash": "2f6b285e08141e1191b15b8e7c808e13",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "89323aaa-ec90-413c-89f8-b781699bb1b2",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Suppose a GPT model is pre-trained using the Causal Language Modelling (CLM) objective and fine-tuned on a text summarization task. The context length T of the model was kept at 1024 during both pre-training and fine-tuning. Assume that the model uses Absolute Position Embedding (APE) with learnable parameters.  Based on the above data, answer the given subquestions."
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 45700,
                    "exam_id": 3,
                    "question_paper_id": 153,
                    "question_number": 202,
                    "question_text_1": "A user runs inference on the model N times with an input text that contains 712 tokens (including the special [start] token), then which of the following could be the possible length of summarized text",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:56.000000Z",
                    "updated_at": "2024-11-27T22:26:56.000000Z",
                    "question_num_long": 640653821256,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "561a2c73369691187a3d0fe10a63b80f",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 45699,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "20a29887-7c62-47de-bfa9-bf16a2b1ee22",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "A user runs inference on the model N times with an input text that contains 712 tokens (including the special [start] token), then which of the following could be the possible length of summarized text"
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [
                        {
                            "id": 121925,
                            "question_id": 45700,
                            "option_text": "256",
                            "option_image": "",
                            "score": "1.500",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:56.000000Z",
                            "updated_at": "2024-11-27T22:26:56.000000Z",
                            "option_number": 6406532756347,
                            "option_image_url": null
                        },
                        {
                            "id": 121926,
                            "question_id": 45700,
                            "option_text": "16",
                            "option_image": "",
                            "score": "1.500",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:56.000000Z",
                            "updated_at": "2024-11-27T22:26:56.000000Z",
                            "option_number": 6406532756348,
                            "option_image_url": null
                        },
                        {
                            "id": 121927,
                            "question_id": 45700,
                            "option_text": "1024",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:56.000000Z",
                            "updated_at": "2024-11-27T22:26:56.000000Z",
                            "option_number": 6406532756349,
                            "option_image_url": null
                        },
                        {
                            "id": 121928,
                            "question_id": 45700,
                            "option_text": "512",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:56.000000Z",
                            "updated_at": "2024-11-27T22:26:56.000000Z",
                            "option_number": 6406532756350,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": {
                        "id": 45699,
                        "exam_id": 3,
                        "question_paper_id": 153,
                        "question_number": 0,
                        "question_text_1": "Suppose a GPT model is pre-trained using the Causal Language Modelling (CLM) objective and fine-tuned on a text summarization task. The context length T of the model was kept at 1024 during both pre-training and fine-tuning. Assume that the model uses Absolute Position Embedding (APE) with learnable parameters.  Based on the above data, answer the given subquestions.",
                        "question_image_1": null,
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2024-11-27T22:26:56.000000Z",
                        "updated_at": "2024-11-27T22:26:56.000000Z",
                        "question_num_long": 640653821255,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "2f6b285e08141e1191b15b8e7c808e13",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "89323aaa-ec90-413c-89f8-b781699bb1b2",
                        "question_image_url": null,
                        "question_texts": [
                            "Suppose a GPT model is pre-trained using the Causal Language Modelling (CLM) objective and fine-tuned on a text summarization task. The context length T of the model was kept at 1024 during both pre-training and fine-tuning. Assume that the model uses Absolute Position Embedding (APE) with learnable parameters.  Based on the above data, answer the given subquestions."
                        ]
                    }
                },
                {
                    "id": 45701,
                    "exam_id": 3,
                    "question_paper_id": 153,
                    "question_number": 203,
                    "question_text_1": "A user runs inference on the model N times with an input text that contains 712 tokens (including the special [start] token). However, the user observed that in each run the model generated the exact same summary. Based on this observation, select the decoding strategy that the model might be using",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:56.000000Z",
                    "updated_at": "2024-11-27T22:26:56.000000Z",
                    "question_num_long": 640653821257,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "040a44c9e861aa6aa8a8d50f368dbe25",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 45699,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "2a99c7ac-4c83-4568-8d07-8198e9e4f809",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "A user runs inference on the model N times with an input text that contains 712 tokens (including the special [start] token). However, the user observed that in each run the model generated the exact same summary. Based on this observation, select the decoding strategy that the model might be using"
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [
                        {
                            "id": 121929,
                            "question_id": 45701,
                            "option_text": "Greedy decoding strategy",
                            "option_image": "",
                            "score": "1.500",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:56.000000Z",
                            "updated_at": "2024-11-27T22:26:56.000000Z",
                            "option_number": 6406532756351,
                            "option_image_url": null
                        },
                        {
                            "id": 121930,
                            "question_id": 45701,
                            "option_text": "Beam search with beam size K > 2",
                            "option_image": "",
                            "score": "1.500",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:56.000000Z",
                            "updated_at": "2024-11-27T22:26:56.000000Z",
                            "option_number": 6406532756352,
                            "option_image_url": null
                        },
                        {
                            "id": 121931,
                            "question_id": 45701,
                            "option_text": "Top-k sampling with K > 3",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:56.000000Z",
                            "updated_at": "2024-11-27T22:26:56.000000Z",
                            "option_number": 6406532756353,
                            "option_image_url": null
                        },
                        {
                            "id": 121932,
                            "question_id": 45701,
                            "option_text": "Top-P sampling with p = 0.25",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:56.000000Z",
                            "updated_at": "2024-11-27T22:26:56.000000Z",
                            "option_number": 6406532756354,
                            "option_image_url": null
                        },
                        {
                            "id": 121933,
                            "question_id": 45701,
                            "option_text": "Greedy decoding by varying the temperature parameter T in the softmaxfunction for each run",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:56.000000Z",
                            "updated_at": "2024-11-27T22:26:56.000000Z",
                            "option_number": 6406532756355,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": {
                        "id": 45699,
                        "exam_id": 3,
                        "question_paper_id": 153,
                        "question_number": 0,
                        "question_text_1": "Suppose a GPT model is pre-trained using the Causal Language Modelling (CLM) objective and fine-tuned on a text summarization task. The context length T of the model was kept at 1024 during both pre-training and fine-tuning. Assume that the model uses Absolute Position Embedding (APE) with learnable parameters.  Based on the above data, answer the given subquestions.",
                        "question_image_1": null,
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2024-11-27T22:26:56.000000Z",
                        "updated_at": "2024-11-27T22:26:56.000000Z",
                        "question_num_long": 640653821255,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "2f6b285e08141e1191b15b8e7c808e13",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "89323aaa-ec90-413c-89f8-b781699bb1b2",
                        "question_image_url": null,
                        "question_texts": [
                            "Suppose a GPT model is pre-trained using the Causal Language Modelling (CLM) objective and fine-tuned on a text summarization task. The context length T of the model was kept at 1024 during both pre-training and fine-tuning. Assume that the model uses Absolute Position Embedding (APE) with learnable parameters.  Based on the above data, answer the given subquestions."
                        ]
                    }
                },
                {
                    "id": 45702,
                    "exam_id": 3,
                    "question_paper_id": 153,
                    "question_number": 0,
                    "question_text_1": "  Based on the above data, answer the given subquestions.",
                    "question_image_1": "ZEfKARTq6wF9by76syO8hPzwHKvNxJVihnDEAM8bJIDFqr42qw.png",
                    "question_type": "COMPREHENSION",
                    "total_mark": "0.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:56.000000Z",
                    "updated_at": "2024-11-27T22:26:56.000000Z",
                    "question_num_long": 640653821259,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 0,
                    "hash": "6e0bce493d190744da2519aac33db2f5",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "ebe56b8f-231e-4a40-b4f3-3dc9d0d8ce24",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/ZEfKARTq6wF9by76syO8hPzwHKvNxJVihnDEAM8bJIDFqr42qw.png"
                    ],
                    "question_texts": [
                        "  Based on the above data, answer the given subquestions."
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 45703,
                    "exam_id": 3,
                    "question_paper_id": 153,
                    "question_number": 204,
                    "question_text_1": "Suppose the input word to the tokenizer is \u201cSomeThing\u201d. Assume that input text is normalized before applying pre-tokenization. Enter the number of tokens returned by the tokenizer. Ignore the special token used to represent the boundary of the word/token.",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "3.00",
                    "value_start": "6",
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:56.000000Z",
                    "updated_at": "2024-11-27T22:26:56.000000Z",
                    "question_num_long": 640653821260,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "5cf4d6da8aaac9aba83ab6069f95efad",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 45702,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "a48102fc-a698-47d4-afa7-0a5119ff35e9",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Suppose the input word to the tokenizer is \u201cSomeThing\u201d. Assume that input text is normalized before applying pre-tokenization. Enter the number of tokens returned by the tokenizer. Ignore the special token used to represent the boundary of the word/token."
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": {
                        "id": 45702,
                        "exam_id": 3,
                        "question_paper_id": 153,
                        "question_number": 0,
                        "question_text_1": "  Based on the above data, answer the given subquestions.",
                        "question_image_1": "ZEfKARTq6wF9by76syO8hPzwHKvNxJVihnDEAM8bJIDFqr42qw.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2024-11-27T22:26:56.000000Z",
                        "updated_at": "2024-11-27T22:26:56.000000Z",
                        "question_num_long": 640653821259,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "6e0bce493d190744da2519aac33db2f5",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "ebe56b8f-231e-4a40-b4f3-3dc9d0d8ce24",
                        "question_image_url": [
                            "/question_images/ZEfKARTq6wF9by76syO8hPzwHKvNxJVihnDEAM8bJIDFqr42qw.png"
                        ],
                        "question_texts": [
                            "  Based on the above data, answer the given subquestions."
                        ]
                    }
                },
                {
                    "id": 45704,
                    "exam_id": 3,
                    "question_paper_id": 153,
                    "question_number": 205,
                    "question_text_1": "Suppose the input word to the tokenizer is \u201c1000000\u201d.Enter the number of tokens returned by the tokenizer.",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "3.00",
                    "value_start": "6",
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:56.000000Z",
                    "updated_at": "2024-11-27T22:26:56.000000Z",
                    "question_num_long": 640653821261,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "5cf4d6da8aaac9aba83ab6069f95efad",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 45702,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "3795c2ba-8c17-4876-9079-ffa7b9328eae",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Suppose the input word to the tokenizer is \u201c1000000\u201d.Enter the number of tokens returned by the tokenizer."
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": {
                        "id": 45702,
                        "exam_id": 3,
                        "question_paper_id": 153,
                        "question_number": 0,
                        "question_text_1": "  Based on the above data, answer the given subquestions.",
                        "question_image_1": "ZEfKARTq6wF9by76syO8hPzwHKvNxJVihnDEAM8bJIDFqr42qw.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2024-11-27T22:26:56.000000Z",
                        "updated_at": "2024-11-27T22:26:56.000000Z",
                        "question_num_long": 640653821259,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "6e0bce493d190744da2519aac33db2f5",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "ebe56b8f-231e-4a40-b4f3-3dc9d0d8ce24",
                        "question_image_url": [
                            "/question_images/ZEfKARTq6wF9by76syO8hPzwHKvNxJVihnDEAM8bJIDFqr42qw.png"
                        ],
                        "question_texts": [
                            "  Based on the above data, answer the given subquestions."
                        ]
                    }
                },
                {
                    "id": 45705,
                    "exam_id": 3,
                    "question_paper_id": 153,
                    "question_number": 0,
                    "question_text_1": "  Based on the above data, answer the given subquestions.",
                    "question_image_1": "dZzYZ55ENGGFBL96uwT6T9sN5CTmeOj55BmBJ8TeqGJCACyMoa.png",
                    "question_type": "COMPREHENSION",
                    "total_mark": "0.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:56.000000Z",
                    "updated_at": "2024-11-27T22:26:56.000000Z",
                    "question_num_long": 640653821248,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 0,
                    "hash": "711226bf61e73d512d0053dfb2e2ee1a",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "4ddf5750-2a82-4d95-80bc-52140eb86421",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/dZzYZ55ENGGFBL96uwT6T9sN5CTmeOj55BmBJ8TeqGJCACyMoa.png"
                    ],
                    "question_texts": [
                        "  Based on the above data, answer the given subquestions."
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 45706,
                    "exam_id": 3,
                    "question_paper_id": 153,
                    "question_number": 206,
                    "question_text_1": "Suppose the number of encoder layers N = 3. What is the total number of learnable parameters, including the parameters of the input and position embedding layers, in the model? Enter the final answer in thousands. For example, if the answer is 12,238, then enter 12 as the answer.",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "2566",
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:56.000000Z",
                    "updated_at": "2024-11-27T22:26:56.000000Z",
                    "question_num_long": 640653821249,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "d746f047571ccfe168bcb0a6966068bf",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 45705,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "908decea-550d-4b32-adb5-d1f16c3fa4ab",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Suppose the number of encoder layers N = 3. What is the total number of learnable parameters, including the parameters of the input and position embedding layers, in the model? Enter the final answer in thousands. For example, if the answer is 12,238, then enter 12 as the answer."
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": {
                        "id": 45705,
                        "exam_id": 3,
                        "question_paper_id": 153,
                        "question_number": 0,
                        "question_text_1": "  Based on the above data, answer the given subquestions.",
                        "question_image_1": "dZzYZ55ENGGFBL96uwT6T9sN5CTmeOj55BmBJ8TeqGJCACyMoa.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2024-11-27T22:26:56.000000Z",
                        "updated_at": "2024-11-27T22:26:56.000000Z",
                        "question_num_long": 640653821248,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "711226bf61e73d512d0053dfb2e2ee1a",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "4ddf5750-2a82-4d95-80bc-52140eb86421",
                        "question_image_url": [
                            "/question_images/dZzYZ55ENGGFBL96uwT6T9sN5CTmeOj55BmBJ8TeqGJCACyMoa.png"
                        ],
                        "question_texts": [
                            "  Based on the above data, answer the given subquestions."
                        ]
                    }
                },
                {
                    "id": 45707,
                    "exam_id": 3,
                    "question_paper_id": 153,
                    "question_number": 207,
                    "question_text_1": "Suppose we increase the context length from T = 256 to T = 512 keeping number of layers same (N = 3). How many parameters does the model need to learn additionally compared to the previous setting?",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "3.00",
                    "value_start": "0",
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:56.000000Z",
                    "updated_at": "2024-11-27T22:26:56.000000Z",
                    "question_num_long": 640653821250,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "27ab2ee264aa09f00a8c213026d4fb47",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 45705,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "c6b7fe27-2ac2-4bb0-b2a8-827a894330f8",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Suppose we increase the context length from T = 256 to T = 512 keeping number of layers same (N = 3). How many parameters does the model need to learn additionally compared to the previous setting?"
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": {
                        "id": 45705,
                        "exam_id": 3,
                        "question_paper_id": 153,
                        "question_number": 0,
                        "question_text_1": "  Based on the above data, answer the given subquestions.",
                        "question_image_1": "dZzYZ55ENGGFBL96uwT6T9sN5CTmeOj55BmBJ8TeqGJCACyMoa.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2024-11-27T22:26:56.000000Z",
                        "updated_at": "2024-11-27T22:26:56.000000Z",
                        "question_num_long": 640653821248,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "711226bf61e73d512d0053dfb2e2ee1a",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "4ddf5750-2a82-4d95-80bc-52140eb86421",
                        "question_image_url": [
                            "/question_images/dZzYZ55ENGGFBL96uwT6T9sN5CTmeOj55BmBJ8TeqGJCACyMoa.png"
                        ],
                        "question_texts": [
                            "  Based on the above data, answer the given subquestions."
                        ]
                    }
                },
                {
                    "id": 45708,
                    "exam_id": 3,
                    "question_paper_id": 153,
                    "question_number": 0,
                    "question_text_1": null,
                    "question_image_1": "dD1LI484GYF8n3soqCnKkHKtQymEqVWsf5PbsDAJuoB9otksZG.png",
                    "question_type": "COMPREHENSION",
                    "total_mark": "0.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:56.000000Z",
                    "updated_at": "2024-11-27T22:26:56.000000Z",
                    "question_num_long": 640653821244,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 0,
                    "hash": "4eecb7797d55dfcb5f1858b9abe8d8c3",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "8d6e371b-8623-4d6c-a5e2-77f479ac0f26",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/dD1LI484GYF8n3soqCnKkHKtQymEqVWsf5PbsDAJuoB9otksZG.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 45709,
                    "exam_id": 3,
                    "question_paper_id": 153,
                    "question_number": 208,
                    "question_text_1": "Compute the representation for the word \u201ccoffee\u201d and enter the sum of the elements in it.",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "1.75",
                    "value_end": "1.95",
                    "created_at": "2024-11-27T22:26:56.000000Z",
                    "updated_at": "2024-11-27T22:26:56.000000Z",
                    "question_num_long": 640653821245,
                    "answer_type": "Range",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "94dbc5bde1764ddabf235f9a4db36e7a",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 45708,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "196ca12e-6653-42bf-9c01-90d84e9a77ba",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Compute the representation for the word \u201ccoffee\u201d and enter the sum of the elements in it."
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": {
                        "id": 45708,
                        "exam_id": 3,
                        "question_paper_id": 153,
                        "question_number": 0,
                        "question_text_1": null,
                        "question_image_1": "dD1LI484GYF8n3soqCnKkHKtQymEqVWsf5PbsDAJuoB9otksZG.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2024-11-27T22:26:56.000000Z",
                        "updated_at": "2024-11-27T22:26:56.000000Z",
                        "question_num_long": 640653821244,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "4eecb7797d55dfcb5f1858b9abe8d8c3",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "8d6e371b-8623-4d6c-a5e2-77f479ac0f26",
                        "question_image_url": [
                            "/question_images/dD1LI484GYF8n3soqCnKkHKtQymEqVWsf5PbsDAJuoB9otksZG.png"
                        ],
                        "question_texts": null
                    }
                },
                {
                    "id": 45710,
                    "exam_id": 3,
                    "question_paper_id": 153,
                    "question_number": 209,
                    "question_text_1": "Suppose the input sentence is \u201ccoffee i like much\u201c. What is the attention score between the word \u201ccoffee\u201d with \u201cmuch\u201d?",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "0.53",
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:56.000000Z",
                    "updated_at": "2024-11-27T22:26:56.000000Z",
                    "question_num_long": 640653821246,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "ce25408ee63558fbfeb68aa138992425",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 45708,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "381d945f-69e9-476d-bccb-c037db7ac8cf",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Suppose the input sentence is \u201ccoffee i like much\u201c. What is the attention score between the word \u201ccoffee\u201d with \u201cmuch\u201d?"
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": {
                        "id": 45708,
                        "exam_id": 3,
                        "question_paper_id": 153,
                        "question_number": 0,
                        "question_text_1": null,
                        "question_image_1": "dD1LI484GYF8n3soqCnKkHKtQymEqVWsf5PbsDAJuoB9otksZG.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2024-11-27T22:26:56.000000Z",
                        "updated_at": "2024-11-27T22:26:56.000000Z",
                        "question_num_long": 640653821244,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "4eecb7797d55dfcb5f1858b9abe8d8c3",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "8d6e371b-8623-4d6c-a5e2-77f479ac0f26",
                        "question_image_url": [
                            "/question_images/dD1LI484GYF8n3soqCnKkHKtQymEqVWsf5PbsDAJuoB9otksZG.png"
                        ],
                        "question_texts": null
                    }
                },
                {
                    "id": 45711,
                    "exam_id": 3,
                    "question_paper_id": 153,
                    "question_number": 0,
                    "question_text_1": "  Based on the above data, answer the given subquestions.",
                    "question_image_1": "c6cDc2DxOKrs1vIx9982YUEtZnah1kQm9RqMfpoaxWlhfCEMY1.png",
                    "question_type": "COMPREHENSION",
                    "total_mark": "0.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:56.000000Z",
                    "updated_at": "2024-11-27T22:26:56.000000Z",
                    "question_num_long": 640653821251,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 0,
                    "hash": "609839dac457989e3aada16522215fc1",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "92c3580e-2b77-4097-96b2-5db0478f9d16",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/c6cDc2DxOKrs1vIx9982YUEtZnah1kQm9RqMfpoaxWlhfCEMY1.png"
                    ],
                    "question_texts": [
                        "  Based on the above data, answer the given subquestions."
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 45712,
                    "exam_id": 3,
                    "question_paper_id": 153,
                    "question_number": 210,
                    "question_text_1": "What is the input sequence length that would have generated this matrix?",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "3.00",
                    "value_start": "8",
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:56.000000Z",
                    "updated_at": "2024-11-27T22:26:56.000000Z",
                    "question_num_long": 640653821252,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "555e23d305f47b9a246569ad152e366f",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 45711,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "4fde65f8-09c9-4de8-9b3e-8ebec5303660",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "What is the input sequence length that would have generated this matrix?"
                    ],
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": {
                        "id": 45711,
                        "exam_id": 3,
                        "question_paper_id": 153,
                        "question_number": 0,
                        "question_text_1": "  Based on the above data, answer the given subquestions.",
                        "question_image_1": "c6cDc2DxOKrs1vIx9982YUEtZnah1kQm9RqMfpoaxWlhfCEMY1.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2024-11-27T22:26:56.000000Z",
                        "updated_at": "2024-11-27T22:26:56.000000Z",
                        "question_num_long": 640653821251,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "609839dac457989e3aada16522215fc1",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "92c3580e-2b77-4097-96b2-5db0478f9d16",
                        "question_image_url": [
                            "/question_images/c6cDc2DxOKrs1vIx9982YUEtZnah1kQm9RqMfpoaxWlhfCEMY1.png"
                        ],
                        "question_texts": [
                            "  Based on the above data, answer the given subquestions."
                        ]
                    }
                },
                {
                    "id": 45713,
                    "exam_id": 3,
                    "question_paper_id": 153,
                    "question_number": 211,
                    "question_text_1": null,
                    "question_image_1": "M635mnfzYQVq1xLO1UCNZzNcPD38mWSwelcWChZvPjIaxdVWQp.png",
                    "question_type": "MSQ",
                    "total_mark": "4.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:56.000000Z",
                    "updated_at": "2024-11-27T22:26:56.000000Z",
                    "question_num_long": 640653821253,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "a61b4b76d67ae6e09762bc560385cf8f",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 45711,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "4d9422b4-b678-4840-ba9c-b941f86b71ce",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/M635mnfzYQVq1xLO1UCNZzNcPD38mWSwelcWChZvPjIaxdVWQp.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [
                        {
                            "id": 121934,
                            "question_id": 45713,
                            "option_text": "(8,8)",
                            "option_image": "",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:56.000000Z",
                            "updated_at": "2024-11-27T22:26:56.000000Z",
                            "option_number": 6406532756340,
                            "option_image_url": null
                        },
                        {
                            "id": 121935,
                            "question_id": 45713,
                            "option_text": "(64,64)",
                            "option_image": "",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:56.000000Z",
                            "updated_at": "2024-11-27T22:26:56.000000Z",
                            "option_number": 6406532756341,
                            "option_image_url": null
                        },
                        {
                            "id": 121936,
                            "question_id": 45713,
                            "option_text": "(32,32)",
                            "option_image": "",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:56.000000Z",
                            "updated_at": "2024-11-27T22:26:56.000000Z",
                            "option_number": 6406532756342,
                            "option_image_url": null
                        },
                        {
                            "id": 121937,
                            "question_id": 45713,
                            "option_text": "(16,16)",
                            "option_image": "",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2024-11-27T22:26:56.000000Z",
                            "updated_at": "2024-11-27T22:26:56.000000Z",
                            "option_number": 6406532756343,
                            "option_image_url": null
                        },
                        {
                            "id": 121938,
                            "question_id": 45713,
                            "option_text": "(8,16)",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:56.000000Z",
                            "updated_at": "2024-11-27T22:26:56.000000Z",
                            "option_number": 6406532756344,
                            "option_image_url": null
                        },
                        {
                            "id": 121939,
                            "question_id": 45713,
                            "option_text": "(16,8)",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-27T22:26:56.000000Z",
                            "updated_at": "2024-11-27T22:26:56.000000Z",
                            "option_number": 6406532756345,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": {
                        "id": 45711,
                        "exam_id": 3,
                        "question_paper_id": 153,
                        "question_number": 0,
                        "question_text_1": "  Based on the above data, answer the given subquestions.",
                        "question_image_1": "c6cDc2DxOKrs1vIx9982YUEtZnah1kQm9RqMfpoaxWlhfCEMY1.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2024-11-27T22:26:56.000000Z",
                        "updated_at": "2024-11-27T22:26:56.000000Z",
                        "question_num_long": 640653821251,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "609839dac457989e3aada16522215fc1",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "92c3580e-2b77-4097-96b2-5db0478f9d16",
                        "question_image_url": [
                            "/question_images/c6cDc2DxOKrs1vIx9982YUEtZnah1kQm9RqMfpoaxWlhfCEMY1.png"
                        ],
                        "question_texts": [
                            "  Based on the above data, answer the given subquestions."
                        ]
                    }
                },
                {
                    "id": 45714,
                    "exam_id": 3,
                    "question_paper_id": 153,
                    "question_number": 212,
                    "question_text_1": null,
                    "question_image_1": "vCwDrWl366e2KI7dYxqPPZcFa3oyAfkSq0LFRC91IPoXgsutiu.png",
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "3",
                    "value_end": null,
                    "created_at": "2024-11-27T22:26:56.000000Z",
                    "updated_at": "2024-11-27T22:26:56.000000Z",
                    "question_num_long": 640653821254,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "56e79ba0efb0d72727191608a57b5f6a",
                    "course_id": 85,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 45711,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "20ba6e95-1d74-4406-a2c2-02f3de322f4d",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/vCwDrWl366e2KI7dYxqPPZcFa3oyAfkSq0LFRC91IPoXgsutiu.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 85,
                        "course_name": "LLM",
                        "course_code": "LLM",
                        "created_at": "2024-10-29T12:29:16.000000Z",
                        "updated_at": "2024-10-29T12:29:16.000000Z",
                        "program_id": 1,
                        "uuid": "5dee317d-ef80-4b86-921a-549e0cf9f948"
                    },
                    "options": [],
                    "parent_question": {
                        "id": 45711,
                        "exam_id": 3,
                        "question_paper_id": 153,
                        "question_number": 0,
                        "question_text_1": "  Based on the above data, answer the given subquestions.",
                        "question_image_1": "c6cDc2DxOKrs1vIx9982YUEtZnah1kQm9RqMfpoaxWlhfCEMY1.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2024-11-27T22:26:56.000000Z",
                        "updated_at": "2024-11-27T22:26:56.000000Z",
                        "question_num_long": 640653821251,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "609839dac457989e3aada16522215fc1",
                        "course_id": 85,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "92c3580e-2b77-4097-96b2-5db0478f9d16",
                        "question_image_url": [
                            "/question_images/c6cDc2DxOKrs1vIx9982YUEtZnah1kQm9RqMfpoaxWlhfCEMY1.png"
                        ],
                        "question_texts": [
                            "  Based on the above data, answer the given subquestions."
                        ]
                    }
                }
            ]
        },
        "summary": "Here\u2019s a structured summary of the core topics, concepts, principles, and equations essential for the exam on **\"Introduction to Large Language Models (LLMs)\"**, along with a knowledge graph in Mermaid syntax.\n\n---\n\n### **Core Topics & Concepts**\n#### **1. Foundations of LLMs**\n- **Transformer Architecture**:\n  - Encoder-decoder structure (though LLMs like GPT are decoder-only).\n  - Self-attention mechanism: \\( \\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V \\).\n  - Multi-head attention: Concatenation of multiple attention heads.\n  - Positional encoding (absolute vs. relative).\n    - Absolute Position Embedding (APE): Fixed (sinusoidal) or learnable.\n    - Relative Position Embedding (RPE): Learns pairwise relationships.\n  - Layer normalization and residual connections.\n  - Feed-forward neural networks (FFN) in transformers: Typically \\( \\text{ReLU}(xW_1 + b_1)W_2 + b_2 \\).\n\n- **Key Equations**:\n  - Self-attention score: \\( A = \\text{softmax}(QK^T) \\).\n  - Scaled dot-product attention: \\( \\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V \\).\n  - Output of multi-head attention:\n    \\( \\text{MultiHead}(Q, K, V) = \\text{Concat}(\\text{head}_1, ..., \\text{head}_h)W^O \\),\n    where \\( \\text{head}_i = \\text{Attention}(QW_i^Q, KW_i^K, VW_i^V) \\).\n\n#### **2. Tokenization**\n- **Byte Pair Encoding (BPE)**:\n  - Starts with a base vocabulary (e.g., characters, digits).\n  - Iteratively merges frequent pairs into new tokens.\n  - Example: \"SomeThing\" \u2192 Tokenized as `[\"Some\", \"Thing\"]` (depends on vocabulary).\n- **Subword Tokenization**:\n  - Handles rare words by breaking them into subwords (e.g., \"1000000\" \u2192 `[\"10\", \"00\", \"00\", \"0\"]` if \"10\" is in the vocabulary).\n  - Special tokens: `[start]`, `[end]`, `[unk]` (unknown).\n\n#### **3. Model Objectives**\n- **Causal Language Modeling (CLM)**:\n  - Predicts next token given previous tokens (autoregressive).\n  - Loss: Cross-entropy over predicted token probabilities.\n- **Masked Language Modeling (MLM)**:\n  - Used in BERT; masks tokens and predicts them (not directly tested here).\n- **Fine-Tuning**:\n  - Adapting pre-trained models (e.g., GPT) to downstream tasks like summarization.\n  - Context length \\( T \\) must be consistent during pre-training and fine-tuning.\n\n#### **4. Decoding Strategies**\n- **Greedy Decoding**:\n  - Selects the token with the highest probability at each step.\n  - Deterministic; always produces the same output for the same input.\n- **Beam Search**:\n  - Keeps top-\\( k \\) sequences (beams) at each step.\n  - Can produce the same output as greedy if \\( k = 1 \\).\n- **Sampling Methods**:\n  - **Top-\\( k \\) Sampling**: Samples from the top-\\( k \\) most probable tokens.\n  - **Top-\\( p \\) (Nucleus) Sampling**: Samples from the smallest set of tokens whose cumulative probability exceeds \\( p \\).\n  - **Temperature**: Scales logits before softmax to control randomness:\n    \\( \\text{softmax}(z_i / T) \\), where \\( T \\) is temperature.\n\n#### **5. Attention Variants**\n- **Sparse Attention**:\n  - Reduces computational complexity by limiting attention to local blocks or patterns.\n  - Example: Block-wise sparse attention with 4 identity blocks reduces complexity to \\( O(T^2 / 16) \\).\n- **Efficiency**:\n  - Full attention: \\( O(T^2) \\).\n  - Sparse attention: \\( O(T \\sqrt{T}) \\) or better (e.g., \\( O(T^2 / \\text{block size}^2) \\)).\n\n#### **6. Parameter Counting**\n- **Transformer Parameters**:\n  - Embedding layers: \\( d_{\\text{embed}} \\times |\\mathcal{V}| \\) (input) + \\( d_{\\text{embed}} \\times |\\mathcal{V}| \\) (output, if not shared).\n  - Position embeddings: \\( T \\times d_{\\text{embed}} \\) (learnable APE) or fixed (sinusoidal).\n  - Attention layers (per head):\n    - \\( W_Q, W_K, W_V \\): Each \\( d_{\\text{embed}} \\times d_q \\) (or \\( d_k, d_v \\)).\n    - \\( W_O \\): \\( n_h \\times d_v \\times d_{\\text{embed}} \\).\n  - Feed-forward layers: \\( 2 \\times (d_{\\text{embed}} \\times d_{ff} + d_{ff}) \\) (weights + biases).\n- **Total Parameters**:\n  - For \\( N \\) layers: Sum of embedding, position, attention, and FFN parameters across all layers.\n\n#### **7. Attention Matrices**\n- **Causal Masking**:\n  - In CLM, future tokens are masked (upper triangular matrix in \\( QK^T \\)).\n  - Example: For input length 8, \\( QK^T \\) is \\( 8 \\times 8 \\) with upper triangle zeroed out.\n- **Attention Scores**:\n  - Softmax of \\( QK^T \\) gives attention weights (rows sum to 1).\n  - Example: Attention score of \"coffee\" \u2192 \"much\" is the softmax value at the corresponding \\( QK^T \\) entry.\n\n#### **8. Computational Complexity**\n- **Self-Attention**:\n  - Naive: \\( O(T^2 \\cdot d) \\) (for \\( QK^T \\) and \\( AV \\)).\n  - With sparsity (e.g., block-sparse): \\( O(T^2 / \\text{num blocks}) \\).\n- **Memory**:\n  - \\( O(T \\cdot d) \\) for activations (key issue for long sequences).\n\n---\n\n### **Key Equations**\n1. **Self-Attention**:\n   \\[\n   A = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right), \\quad \\text{Attention}(Q, K, V) = AV\n   \\]\n2. **Multi-Head Attention**:\n   \\[\n   \\text{MultiHead}(Q, K, V) = \\text{Concat}(\\text{head}_1, ..., \\text{head}_h)W^O, \\quad \\text{head}_i = \\text{Attention}(QW_i^Q, KW_i^K, VW_i^V)\n   \\]\n3. **Positional Encoding (Sinusoidal)**:\n   \\[\n   PE_{(pos, 2i)} = \\sin\\left(\\frac{pos}{10000^{2i/d_{\\text{model}}}}\\right), \\quad PE_{(pos, 2i+1)} = \\cos\\left(\\frac{pos}{10000^{2i/d_{\\text{model}}}}\\right)\n   \\]\n4. **Parameter Count for One Layer**:\n   - Attention: \\( 4 \\times (d_{\\text{embed}} \\times d_q \\times n_h) + d_{\\text{embed}} \\times d_{\\text{embed}} \\) (for \\( W_Q, W_K, W_V, W_O \\)).\n   - FFN: \\( 2 \\times (d_{\\text{embed}} \\times d_{ff} + d_{ff}) \\).\n5. **Greedy Decoding**:\n   \\[\n   y_t = \\arg\\max_p P(y_t | y_{<t}, x)\n   \\]\n6. **Sparse Attention Complexity**:\n   \\[\n   O\\left(\\frac{T^2}{\\text{num blocks}}\\right) \\quad \\text{(e.g., 4 blocks \u2192 } O(T^2 / 16))\n   \\]\n\n---\n\n### **Mermaid Knowledge Graphs**\n\n#### **Graph 1: Core Components of LLMs**\n```mermaid\ngraph TD\n    A[Large Language Models] --> B[Transformer Architecture]\n    A --> C[Tokenization]\n    A --> D[Training Objectives]\n    A --> E[Decoding Strategies]\n    A --> F[Attention Variants]\n\n    B --> B1[Self-Attention]\n    B --> B2[Multi-Head Attention]\n    B --> B3[Positional Encoding]\n    B --> B4[Feed-Forward Networks]\n    B --> B5[Layer Normalization]\n\n    C --> C1[Byte Pair Encoding]\n    C --> C2[Subword Tokenization]\n    C --> C3[Special Tokens]\n\n    D --> D1[Causal Language Modeling]\n    D --> D2[Masked Language Modeling]\n    D --> D3[Fine-Tuning]\n\n    E --> E1[Greedy Decoding]\n    E --> E2[Beam Search]\n    E --> E3[Top-k Sampling]\n    E --> E4[Top-p Sampling]\n\n    F --> F1[Sparse Attention]\n    F --> F2[Full Attention]\n    F --> F3[Block-Sparse Attention]\n```\n\n#### **Graph 2: Attention Mechanism**\n```mermaid\ngraph TD\n    A[Attention Mechanism] --> B[Query, Key, Value]\n    A --> C[Softmax]\n    A --> D[Scaled Dot-Product]\n\n    B --> B1[Q = X * W_Q]\n    B --> B2[K = X * W_K]\n    B --> B3[V = X * W_V]\n\n    C --> C1[softmax(QK_T / sqrt(d_k))]\n    D --> D1[Attention = softmax(QK_T) * V]\n\n    A --> E[Multi-Head Attention]\n    E --> E1[Split into Heads]\n    E --> E2[Concatenate Heads]\n    E --> E3[Linear Projection]\n```\n\n#### **Graph 3: Decoding Strategies**\n```mermaid\ngraph TD\n    A[Decoding Strategies] --> B[Greedy]\n    A --> C[Beam Search]\n    A --> D[Sampling]\n\n    B --> B1[Deterministic]\n    B --> B2[Fast]\n\n    C --> C1[Beam Size K]\n    C --> C2[Trade-off: Quality vs Speed]\n\n    D --> D1[Top-k Sampling]\n    D --> D2[Top-p Sampling]\n    D --> D3[Temperature]\n```\n\n#### **Graph 4: Tokenization Process**\n```mermaid\ngraph TD\n    A[Tokenization] --> B[Input Text]\n    A --> C[Preprocessing]\n    A --> D[Tokenization Algorithm]\n\n    B --> B1[Normalization]\n    B --> B2[Lowercasing]\n\n    C --> C1[Byte Pair Encoding]\n    C --> C2[WordPiece]\n\n    D --> D1[Vocabulary Lookup]\n    D --> D2[Unknown Token Handling]\n    D --> D3[Special Tokens]\n```\n\n#### **Graph 5: Parameter Counting**\n```mermaid\ngraph TD\n    A[Parameter Counting] --> B[Embedding Layers]\n    A --> C[Attention Layers]\n    A --> D[Feed-Forward Layers]\n    A --> E[Position Embeddings]\n\n    B --> B1[Token Embeddings]\n    B --> B2[Output Embeddings]\n\n    C --> C1[Query/Key/Value Projections]\n    C --> C2[Output Projection]\n\n    D --> D1[Weights]\n    D --> D2[Biases]\n\n    E --> E1[Learnable]\n    E --> E2[Fixed Sinusoidal]\n```\n\n---\n\n### **Exam-Specific Notes**\n1. **BERT vs. GPT**:\n   - BERT: Bidirectional (MLM), uses `[mask]` tokens.\n   - GPT: Unidirectional (CLM), no masking during inference.\n2. **Position Embeddings**:\n   - Absolute: Fixed or learnable (adds \\( T \\times d_{\\text{embed}} \\) parameters if learnable).\n   - Relative: More complex but generalizes better to longer sequences.\n3. **Sparse Attention**:\n   - Block-sparse with 4 blocks \u2192 \\( O(T^2 / 16) \\).\n4. **Decoding Determinism**:\n   - Greedy and beam search (with \\( K=1 \\)) are deterministic.\n   - Sampling methods (Top-\\( k \\), Top-\\( p \\), temperature) introduce randomness.\n5. **Parameter Calculation**:\n   - For \\( N=3 \\) layers, \\( T=256 \\), \\( d_{\\text{embed}}=256 \\), etc., total parameters ~2.5M (2566 in thousands).\n   - Increasing \\( T \\) to 512 with fixed sinusoidal positional encoding adds **0** learnable parameters.",
        "total_score": "50.00"
    },
    "url": "/question-paper/practise/85/a257da7c-11d",
    "version": "ee3d5d44299e610bd137ea6200db5ac2"
}