{
    "component": "Quizpractise/PractiseQuestionPaper",
    "props": {
        "errors": {},
        "auth": {
            "user": null
        },
        "flash": {
            "error": []
        },
        "banner": null,
        "file_url": "https://saram.blr1.cdn.digitaloceanspaces.com",
        "file_do_url": "https://saram.blr1.cdn.digitaloceanspaces.com",
        "question_paper": {
            "id": 306,
            "group_id": 29,
            "exam_id": 1,
            "total_score": "1.00",
            "duration": 4,
            "created_at": "2025-07-15T13:58:18.000000Z",
            "updated_at": "2025-07-15T13:58:18.000000Z",
            "question_paper_name": "IIT M IMPROVEMENT AN EXAM QIP3 13 July",
            "question_paper_description": "2025 Jul13: IIT M AN EXAM QIP3",
            "uuid": "1e3f441b-c5a",
            "year": 2025,
            "is_new": 0,
            "exam": {
                "id": 1,
                "exam_name": "Quiz 1",
                "created_at": "2024-10-16T08:08:51.000000Z",
                "updated_at": "2024-10-16T08:08:51.000000Z",
                "uuid": "9251bc3a-e33e-45e0-bcf0-b16a0ea5b5fa",
                "en_id": "eyJpdiI6IjhVUHRwVjhFZXNhSXdYaVVDdEhwMUE9PSIsInZhbHVlIjoiaEg2RW9RWmk4U0dFWnFaVTFFYTFkQT09IiwibWFjIjoiMDEyOWRlYzQ1MDIwYzhjYjdkZmQ3MTIyMDlkNWJjNDIyMTk0OTIwM2VhYjdiYmE5MzM5OTY1YTA4ZjJjNjUwYyIsInRhZyI6IiJ9"
            },
            "questions": [
                {
                    "id": 95620,
                    "exam_id": 1,
                    "question_paper_id": 306,
                    "question_number": 160,
                    "question_text_1": "THIS IS QUESTION PAPER FOR THE SUBJECT <b>\"DEGREE LEVEL : DEEP LEARNING PRACTICE </b><b>(COMPUTER BASED EXAM)\"</b><b> </b><b> </b><b>ARE YOU SURE YOU HAVE TO WRITE EXAM FOR THIS SUBJECT? </b><b>CROSS CHECK YOUR HALL TICKET TO CONFIRM THE SUBJECTS TO BE WRITTEN. </b><b> </b><b>(IF IT IS NOT THE CORRECT SUBJECT, PLS CHECK THE SECTION AT THE TOP FOR THE SUBJECTS </b><b>REGISTERED BY YOU)</b>",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "0.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-07-15T13:58:19.000000Z",
                    "updated_at": "2025-07-15T13:58:19.000000Z",
                    "question_num_long": 6406531302197,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "1c80c635ff08334e973a3628aaa4b04f",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "37bc8c13-4d63-4aa7-8ac5-d9030538d38c",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "THIS IS QUESTION PAPER FOR THE SUBJECT <b>\"DEGREE LEVEL : DEEP LEARNING PRACTICE </b><b>(COMPUTER BASED EXAM)\"</b><b> </b><b> </b><b>ARE YOU SURE YOU HAVE TO WRITE EXAM FOR THIS SUBJECT? </b><b>CROSS CHECK YOUR HALL TICKET TO CONFIRM THE SUBJECTS TO BE WRITTEN. </b><b> </b><b>(IF IT IS NOT THE CORRECT SUBJECT, PLS CHECK THE SECTION AT THE TOP FOR THE SUBJECTS </b><b>REGISTERED BY YOU)</b>"
                    ],
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [
                        {
                            "id": 252804,
                            "question_id": 95620,
                            "option_text": "YES",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 1,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375661,
                            "option_image_url": null
                        },
                        {
                            "id": 252805,
                            "question_id": 95620,
                            "option_text": "NO",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375662,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 95621,
                    "exam_id": 1,
                    "question_paper_id": 306,
                    "question_number": 161,
                    "question_text_1": "A start-up is building a new language model for a low-resource language with many compound words and complex morphology. They are debating tokenization strategies. Which of the following approaches is most likely to offer the best balance between vocabulary size, handling OOV words, and capturing morphological variants effectively for this scenario?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-07-15T13:58:19.000000Z",
                    "updated_at": "2025-07-15T13:58:19.000000Z",
                    "question_num_long": 6406531302198,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "9e23c87caa8413cafe598dc30c11e62f",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "b887a36f-d2a8-4eed-afbb-39df2cffcac6",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "A start-up is building a new language model for a low-resource language with many compound words and complex morphology. They are debating tokenization strategies. Which of the following approaches is most likely to offer the best balance between vocabulary size, handling OOV words, and capturing morphological variants effectively for this scenario?"
                    ],
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [
                        {
                            "id": 252806,
                            "question_id": 95621,
                            "option_text": "Character-level tokenization",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375663,
                            "option_image_url": null
                        },
                        {
                            "id": 252807,
                            "question_id": 95621,
                            "option_text": "Word-level tokenization with a fixed vocabulary of 50,000 common words.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375664,
                            "option_image_url": null
                        },
                        {
                            "id": 252808,
                            "question_id": 95621,
                            "option_text": "Subword tokenization (e.g., BPE or SentencePiece) trained on the availablecorpus.",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375665,
                            "option_image_url": null
                        },
                        {
                            "id": 252809,
                            "question_id": 95621,
                            "option_text": "Using only pre-defined special tokens and treating all other text as raw bytesequences.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375666,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 95622,
                    "exam_id": 1,
                    "question_paper_id": 306,
                    "question_number": 162,
                    "question_text_1": "When fully fine-tuning a large pre-trained Transformer model (e.g., >1 Billion parameters), which of the following contributes LEAST significantly to the GPU memory bottleneck compared to the others?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-07-15T13:58:19.000000Z",
                    "updated_at": "2025-07-15T13:58:19.000000Z",
                    "question_num_long": 6406531302200,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "4e2ac860e7b209ab32f97b6f90125b9e",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "accc0003-5699-46bc-8659-a272a7b40f3d",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "When fully fine-tuning a large pre-trained Transformer model (e.g., >1 Billion parameters), which of the following contributes LEAST significantly to the GPU memory bottleneck compared to the others?"
                    ],
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [
                        {
                            "id": 252810,
                            "question_id": 95622,
                            "option_text": "Storing the model parameters themselves.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375671,
                            "option_image_url": null
                        },
                        {
                            "id": 252811,
                            "question_id": 95622,
                            "option_text": "Storing the gradients for each parameter.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375672,
                            "option_image_url": null
                        },
                        {
                            "id": 252812,
                            "question_id": 95622,
                            "option_text": "Storing the optimizer states (e.g., momentum and variance for Adam).",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375673,
                            "option_image_url": null
                        },
                        {
                            "id": 252813,
                            "question_id": 95622,
                            "option_text": "Storing the input batch data (token IDs).",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375674,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 95623,
                    "exam_id": 1,
                    "question_paper_id": 306,
                    "question_number": 163,
                    "question_text_1": "A research team wants their pre-trained language model to generate more helpful and harmless responses without extensive task-specific dataset collection. They have a collection of prompts and human-preferred responses. Which of the following techniques directly aligns with this goal and data?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-07-15T13:58:19.000000Z",
                    "updated_at": "2025-07-15T13:58:19.000000Z",
                    "question_num_long": 6406531302201,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "fd1332f74ebd5e193810faeb3eb1007d",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "bc350bf2-6647-4513-8cfb-00c443d9c22f",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "A research team wants their pre-trained language model to generate more helpful and harmless responses without extensive task-specific dataset collection. They have a collection of prompts and human-preferred responses. Which of the following techniques directly aligns with this goal and data?"
                    ],
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [
                        {
                            "id": 252814,
                            "question_id": 95623,
                            "option_text": "Pre-training the model on a larger, more diverse text corpus.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375675,
                            "option_image_url": null
                        },
                        {
                            "id": 252815,
                            "question_id": 95623,
                            "option_text": "Full fine-tuning on multiple downstream classification tasks.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375676,
                            "option_image_url": null
                        },
                        {
                            "id": 252816,
                            "question_id": 95623,
                            "option_text": "Instruction Tuning using prompt-completion pairs or reformatting existingdatasets into an instructional format.",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375677,
                            "option_image_url": null
                        },
                        {
                            "id": 252817,
                            "question_id": 95623,
                            "option_text": "Implementing Parameter-Efficient Fine-Tuning (PEFT) techniques like LoRa.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375678,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 95624,
                    "exam_id": 1,
                    "question_paper_id": 306,
                    "question_number": 164,
                    "question_text_1": null,
                    "question_image_1": "cRP1QOfPHlxqfEmtkgm4ZPmJArMgKnalDAkGEehk58j817f2l3.png",
                    "question_type": "MCQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-07-15T13:58:19.000000Z",
                    "updated_at": "2025-07-15T13:58:19.000000Z",
                    "question_num_long": 6406531302199,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "8058b5518b34c6eb112b068d71bda903",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "7861a8a3-3ecd-4d7a-a830-4061d1482810",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/cRP1QOfPHlxqfEmtkgm4ZPmJArMgKnalDAkGEehk58j817f2l3.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [
                        {
                            "id": 252818,
                            "question_id": 95624,
                            "option_text": "",
                            "option_image": "GCbVGBVHvBzHs0czrYL47A1CtVpZUOLWDP7jb6Pd1rgaTvrkwa.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375667,
                            "option_image_url": "app/option_images/GCbVGBVHvBzHs0czrYL47A1CtVpZUOLWDP7jb6Pd1rgaTvrkwa.png"
                        },
                        {
                            "id": 252819,
                            "question_id": 95624,
                            "option_text": "",
                            "option_image": "9P1gMebdN4fKO1kiYCR3OPaSfcQKYf58bf6Kx0yDvpLPa5HtTH.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375668,
                            "option_image_url": "app/option_images/9P1gMebdN4fKO1kiYCR3OPaSfcQKYf58bf6Kx0yDvpLPa5HtTH.png"
                        },
                        {
                            "id": 252820,
                            "question_id": 95624,
                            "option_text": "",
                            "option_image": "QhxcoWtGs9BTxd2blGCivBJZWhEZ6oVAzr3gcaqFkzVU6XZR3d.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375669,
                            "option_image_url": "app/option_images/QhxcoWtGs9BTxd2blGCivBJZWhEZ6oVAzr3gcaqFkzVU6XZR3d.png"
                        },
                        {
                            "id": 252821,
                            "question_id": 95624,
                            "option_text": "",
                            "option_image": "LwODGssVy26oIOv0ZyLTjjS2sCY7vArEMtB3KudYLAvEiyOunw.png",
                            "score": "3.000",
                            "is_correct": 1,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375670,
                            "option_image_url": "app/option_images/LwODGssVy26oIOv0ZyLTjjS2sCY7vArEMtB3KudYLAvEiyOunw.png"
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 95625,
                    "exam_id": 1,
                    "question_paper_id": 306,
                    "question_number": 165,
                    "question_text_1": null,
                    "question_image_1": "2absx6zwb6mrn5jMnuyH7uxyR1KikFNL5fdEtNimG3Y0wck3Bm.png",
                    "question_type": "MCQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-07-15T13:58:19.000000Z",
                    "updated_at": "2025-07-15T13:58:19.000000Z",
                    "question_num_long": 6406531302202,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "ac506d74b5e7b996ac5f6540efc4b511",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "43d47296-f1fd-4e91-aa21-b8c683271d87",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/2absx6zwb6mrn5jMnuyH7uxyR1KikFNL5fdEtNimG3Y0wck3Bm.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [
                        {
                            "id": 252822,
                            "question_id": 95625,
                            "option_text": "",
                            "option_image": "tvXeOUr0oL8R7WduMb38ttgDlARVhyee73pmVdgfOE3PPW23V2.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375679,
                            "option_image_url": "app/option_images/tvXeOUr0oL8R7WduMb38ttgDlARVhyee73pmVdgfOE3PPW23V2.png"
                        },
                        {
                            "id": 252823,
                            "question_id": 95625,
                            "option_text": "",
                            "option_image": "qBUz27Fg6CCkFFkf6182KGf6abceuTPj68EiHmouYUSI633gsL.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375680,
                            "option_image_url": "app/option_images/qBUz27Fg6CCkFFkf6182KGf6abceuTPj68EiHmouYUSI633gsL.png"
                        },
                        {
                            "id": 252824,
                            "question_id": 95625,
                            "option_text": "",
                            "option_image": "WNPZqGWe2jLIQ3gFD51lvaC2DV5wc1XHgcw0fBmhYuIAwD10ST.png",
                            "score": "3.000",
                            "is_correct": 1,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375681,
                            "option_image_url": "app/option_images/WNPZqGWe2jLIQ3gFD51lvaC2DV5wc1XHgcw0fBmhYuIAwD10ST.png"
                        },
                        {
                            "id": 252825,
                            "question_id": 95625,
                            "option_text": "",
                            "option_image": "vec7XaSE2NGcYVwbBL450wlDZOq0uHPRwTBmotiaAkWIRjQBmX.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375682,
                            "option_image_url": "app/option_images/vec7XaSE2NGcYVwbBL450wlDZOq0uHPRwTBmotiaAkWIRjQBmX.png"
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 95626,
                    "exam_id": 1,
                    "question_paper_id": 306,
                    "question_number": 166,
                    "question_text_1": "Which of the following statements accurately describe common characteristics or goals of subword tokenization algorithms like BPE, WordPiece, or SentencePiece? (Select ALL that apply)",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "4.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-07-15T13:58:19.000000Z",
                    "updated_at": "2025-07-15T13:58:19.000000Z",
                    "question_num_long": 6406531302203,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "6303f9e9736ac4afa7e0c779694b0b7e",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "54429084-fd4e-4237-ac30-369bf8e4047a",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following statements accurately describe common characteristics or goals of subword tokenization algorithms like BPE, WordPiece, or SentencePiece? (Select ALL that apply)"
                    ],
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [
                        {
                            "id": 252826,
                            "question_id": 95626,
                            "option_text": "They aim to significantly reduce the vocabulary size compared to character-level tokenization.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375683,
                            "option_image_url": null
                        },
                        {
                            "id": 252827,
                            "question_id": 95626,
                            "option_text": "They can handle out-of-vocabulary (OOV) words by breaking them into knownsubword units.",
                            "option_image": "",
                            "score": "1.333",
                            "is_correct": 1,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375684,
                            "option_image_url": null
                        },
                        {
                            "id": 252828,
                            "question_id": 95626,
                            "option_text": "They primarily rely on merging the least frequent character or subword pairsto build the vocabulary.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375685,
                            "option_image_url": null
                        },
                        {
                            "id": 252829,
                            "question_id": 95626,
                            "option_text": "They can represent common words as single tokens and rare words assequences of subword tokens.",
                            "option_image": "",
                            "score": "1.333",
                            "is_correct": 1,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375686,
                            "option_image_url": null
                        },
                        {
                            "id": 252830,
                            "question_id": 95626,
                            "option_text": "SentencePiece is designed to be language-agnostic, not requiring pre-segmentation based on spaces.",
                            "option_image": "",
                            "score": "1.333",
                            "is_correct": 1,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375687,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 95627,
                    "exam_id": 1,
                    "question_paper_id": 306,
                    "question_number": 167,
                    "question_text_1": "A team has a powerful pre-trained language model (e.g., a GPT-3 class model). They want to adapt it for a new summarization task but have very limited labeled summarization data and limited compute for full fine-tuning. Which of the following strategies could be viable and effective? (Select ALL that apply)",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "4.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-07-15T13:58:19.000000Z",
                    "updated_at": "2025-07-15T13:58:19.000000Z",
                    "question_num_long": 6406531302204,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "02d6fa72f84555b3ced54af788bed1e2",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "356f115d-4000-4b9b-9ef1-5f4f12aab202",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "A team has a powerful pre-trained language model (e.g., a GPT-3 class model). They want to adapt it for a new summarization task but have very limited labeled summarization data and limited compute for full fine-tuning. Which of the following strategies could be viable and effective? (Select ALL that apply)"
                    ],
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [
                        {
                            "id": 252831,
                            "question_id": 95627,
                            "option_text": "Zero-shot prompting by providing the text and an instruction like \"Summarizethis:\".",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375688,
                            "option_image_url": null
                        },
                        {
                            "id": 252832,
                            "question_id": 95627,
                            "option_text": "Few-shot prompting (in-context learning) by providing a few examples of textand their summaries in the prompt before the target text.",
                            "option_image": "",
                            "score": "1.333",
                            "is_correct": 1,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375689,
                            "option_image_url": null
                        },
                        {
                            "id": 252833,
                            "question_id": 95627,
                            "option_text": "Full supervised fine-tuning of all model parameters on the small labeleddataset.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375690,
                            "option_image_url": null
                        },
                        {
                            "id": 252834,
                            "question_id": 95627,
                            "option_text": "Using a Parameter-Efficient Fine-Tuning (PEFT) method like LoRA on the smalllabeled dataset.",
                            "option_image": "",
                            "score": "1.333",
                            "is_correct": 1,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375691,
                            "option_image_url": null
                        },
                        {
                            "id": 252835,
                            "question_id": 95627,
                            "option_text": "Collecting a much larger unlabeled corpus related to the summarizationdomain and continuing pre-training.",
                            "option_image": "",
                            "score": "1.333",
                            "is_correct": 1,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375692,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 95628,
                    "exam_id": 1,
                    "question_paper_id": 306,
                    "question_number": 168,
                    "question_text_1": null,
                    "question_image_1": "Dl1KiZBPKvYAhumVqdyFVUIZv7PWH9JceEhLZrxjz9MXIugl0q.png",
                    "question_type": "MSQ",
                    "total_mark": "4.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-07-15T13:58:19.000000Z",
                    "updated_at": "2025-07-15T13:58:19.000000Z",
                    "question_num_long": 6406531302205,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "64e3f9a9aa0582a603dd2a5f1fd109d7",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "71f7777a-2366-4dea-9fd2-da4a375fc5a5",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/Dl1KiZBPKvYAhumVqdyFVUIZv7PWH9JceEhLZrxjz9MXIugl0q.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [
                        {
                            "id": 252836,
                            "question_id": 95628,
                            "option_text": "",
                            "option_image": "hXyy6BhTtdjrI0RJ7r5naaTsfalv4FRRV2acJXnT3hxSdCH9pz.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375693,
                            "option_image_url": "app/option_images/hXyy6BhTtdjrI0RJ7r5naaTsfalv4FRRV2acJXnT3hxSdCH9pz.png"
                        },
                        {
                            "id": 252837,
                            "question_id": 95628,
                            "option_text": "",
                            "option_image": "3XRN0AlktdtVAFvOyrQeZzJSDa8NIQ0GZIDT9bkR3fpmgt0bxr.png",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375694,
                            "option_image_url": "app/option_images/3XRN0AlktdtVAFvOyrQeZzJSDa8NIQ0GZIDT9bkR3fpmgt0bxr.png"
                        },
                        {
                            "id": 252838,
                            "question_id": 95628,
                            "option_text": "",
                            "option_image": "PsK5YOblUTw9GfXl2rIRuk7Z2jRaTtvKOnLwV2nqyiyxhleHte.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375695,
                            "option_image_url": "app/option_images/PsK5YOblUTw9GfXl2rIRuk7Z2jRaTtvKOnLwV2nqyiyxhleHte.png"
                        },
                        {
                            "id": 252839,
                            "question_id": 95628,
                            "option_text": "",
                            "option_image": "Wnv9DW7q6Dap52s4GJFQ7yLn3JWNgNk1fbLtqyH7aNa7Itkeem.png",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375696,
                            "option_image_url": "app/option_images/Wnv9DW7q6Dap52s4GJFQ7yLn3JWNgNk1fbLtqyH7aNa7Itkeem.png"
                        },
                        {
                            "id": 252840,
                            "question_id": 95628,
                            "option_text": "",
                            "option_image": "wwQop0DOk8QzlUzgJ7tKe6gIdhhkMTZZiw6j9mf91Vc0Mobhd2.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375697,
                            "option_image_url": "app/option_images/wwQop0DOk8QzlUzgJ7tKe6gIdhhkMTZZiw6j9mf91Vc0Mobhd2.png"
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 95629,
                    "exam_id": 1,
                    "question_paper_id": 306,
                    "question_number": 169,
                    "question_text_1": null,
                    "question_image_1": "85YEXjnEDmeQO2D7LNugeyFzYpe9U6qAJepO3hakhk1JL62SJP.png",
                    "question_type": "SA",
                    "total_mark": "3.00",
                    "value_start": "5",
                    "value_end": null,
                    "created_at": "2025-07-15T13:58:19.000000Z",
                    "updated_at": "2025-07-15T13:58:19.000000Z",
                    "question_num_long": 6406531302206,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "0d7d2a57a7d04e462b0750508a94e6f5",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "a644aa63-f34c-43e5-8ae4-049dea19edd2",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/85YEXjnEDmeQO2D7LNugeyFzYpe9U6qAJepO3hakhk1JL62SJP.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 95630,
                    "exam_id": 1,
                    "question_paper_id": 306,
                    "question_number": 170,
                    "question_text_1": null,
                    "question_image_1": "zBgC9YCDNprDZTJtRRs1tuiLxglgj02W25UcakBGoj9hQkqRIu.png",
                    "question_type": "SA",
                    "total_mark": "3.00",
                    "value_start": "2",
                    "value_end": null,
                    "created_at": "2025-07-15T13:58:19.000000Z",
                    "updated_at": "2025-07-15T13:58:19.000000Z",
                    "question_num_long": 6406531302208,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "cdb96dc3ed3a170d6f1833f50af50925",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "3584770b-27b2-4dfd-b7cf-44bc5bb55caa",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/zBgC9YCDNprDZTJtRRs1tuiLxglgj02W25UcakBGoj9hQkqRIu.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 95631,
                    "exam_id": 1,
                    "question_paper_id": 306,
                    "question_number": 171,
                    "question_text_1": null,
                    "question_image_1": "NqGinlIbhDZLmdZgqC1yxX3q5aZ0omX6SSg4wC9DaWxDLGt0vE.png",
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "4.6",
                    "value_end": "4.8",
                    "created_at": "2025-07-15T13:58:19.000000Z",
                    "updated_at": "2025-07-15T13:58:19.000000Z",
                    "question_num_long": 6406531302207,
                    "answer_type": "Range",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "2b971749eb96dbaae7ef5eb351912679",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "f9eb8e61-18da-48bc-a05c-677c6aa25016",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/NqGinlIbhDZLmdZgqC1yxX3q5aZ0omX6SSg4wC9DaWxDLGt0vE.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 95632,
                    "exam_id": 1,
                    "question_paper_id": 306,
                    "question_number": 0,
                    "question_text_1": "  Based on the above data, answer the given subquestions.",
                    "question_image_1": "0azgWLycQqABEO0x8730MwuwYb1zosxfNYuSFdRAYLhqXNPNFD.png",
                    "question_type": "COMPREHENSION",
                    "total_mark": "0.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-07-15T13:58:19.000000Z",
                    "updated_at": "2025-07-15T13:58:19.000000Z",
                    "question_num_long": 6406531302209,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 0,
                    "hash": "35a123d043ab686a585b99560b3c856b",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "2f8862a0-50d8-4cb1-ad8c-883f2eccb413",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/0azgWLycQqABEO0x8730MwuwYb1zosxfNYuSFdRAYLhqXNPNFD.png"
                    ],
                    "question_texts": [
                        "  Based on the above data, answer the given subquestions."
                    ],
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 95633,
                    "exam_id": 1,
                    "question_paper_id": 306,
                    "question_number": 172,
                    "question_text_1": null,
                    "question_image_1": "9LtCMDRGHmEio4MCR7my78besZfD0K6e8tCUWmzTlxMFONKvhY.png",
                    "question_type": "MCQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-07-15T13:58:19.000000Z",
                    "updated_at": "2025-07-15T13:58:19.000000Z",
                    "question_num_long": 6406531302210,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "2c4d78d6c73b25c72309b21659380df5",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 95632,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "95a7697b-dfaa-48a4-9da5-b7279339e803",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/9LtCMDRGHmEio4MCR7my78besZfD0K6e8tCUWmzTlxMFONKvhY.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [
                        {
                            "id": 252841,
                            "question_id": 95633,
                            "option_text": "",
                            "option_image": "0Rq0TgW4hw8oVtp6fvt0qnV4YoJC1Q1DYv0uHuoblrbrUlIVBo.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375701,
                            "option_image_url": "app/option_images/0Rq0TgW4hw8oVtp6fvt0qnV4YoJC1Q1DYv0uHuoblrbrUlIVBo.png"
                        },
                        {
                            "id": 252842,
                            "question_id": 95633,
                            "option_text": "",
                            "option_image": "uHoKmMhHnDbC9YjZ27A723kSNfivovO9GSddUuUFZEkEWhD8Z7.png",
                            "score": "3.000",
                            "is_correct": 1,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375702,
                            "option_image_url": "app/option_images/uHoKmMhHnDbC9YjZ27A723kSNfivovO9GSddUuUFZEkEWhD8Z7.png"
                        },
                        {
                            "id": 252843,
                            "question_id": 95633,
                            "option_text": "",
                            "option_image": "SgttXE7mGwUuNzHvg0UOe95LCKN9Vqn6cipiu5PlDXHimxDBeR.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375703,
                            "option_image_url": "app/option_images/SgttXE7mGwUuNzHvg0UOe95LCKN9Vqn6cipiu5PlDXHimxDBeR.png"
                        },
                        {
                            "id": 252844,
                            "question_id": 95633,
                            "option_text": "",
                            "option_image": "38z8PZyUXFWrRJhBXBoVyeqSJIsXaUuWEQpHl9REjt33feiO6e.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375704,
                            "option_image_url": "app/option_images/38z8PZyUXFWrRJhBXBoVyeqSJIsXaUuWEQpHl9REjt33feiO6e.png"
                        }
                    ],
                    "parent_question": {
                        "id": 95632,
                        "exam_id": 1,
                        "question_paper_id": 306,
                        "question_number": 0,
                        "question_text_1": "  Based on the above data, answer the given subquestions.",
                        "question_image_1": "0azgWLycQqABEO0x8730MwuwYb1zosxfNYuSFdRAYLhqXNPNFD.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2025-07-15T13:58:19.000000Z",
                        "updated_at": "2025-07-15T13:58:19.000000Z",
                        "question_num_long": 6406531302209,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "35a123d043ab686a585b99560b3c856b",
                        "course_id": 86,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "2f8862a0-50d8-4cb1-ad8c-883f2eccb413",
                        "question_image_url": [
                            "/question_images/0azgWLycQqABEO0x8730MwuwYb1zosxfNYuSFdRAYLhqXNPNFD.png"
                        ],
                        "question_texts": [
                            "  Based on the above data, answer the given subquestions."
                        ]
                    }
                },
                {
                    "id": 95634,
                    "exam_id": 1,
                    "question_paper_id": 306,
                    "question_number": 173,
                    "question_text_1": "Based on the provided configuration, calculate the total number of parameters in the model\u2019s embedding layer (token embeddings) in millions. Enter your answer rounded to one decimal place.",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "32.7",
                    "value_end": "32.9",
                    "created_at": "2025-07-15T13:58:19.000000Z",
                    "updated_at": "2025-07-15T13:58:19.000000Z",
                    "question_num_long": 6406531302211,
                    "answer_type": "Range",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "47ec40da47239be4bcfe9b27f60967e0",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 95632,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "768c46f6-920d-4f42-8674-99a0c3862f9b",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Based on the provided configuration, calculate the total number of parameters in the model\u2019s embedding layer (token embeddings) in millions. Enter your answer rounded to one decimal place."
                    ],
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [],
                    "parent_question": {
                        "id": 95632,
                        "exam_id": 1,
                        "question_paper_id": 306,
                        "question_number": 0,
                        "question_text_1": "  Based on the above data, answer the given subquestions.",
                        "question_image_1": "0azgWLycQqABEO0x8730MwuwYb1zosxfNYuSFdRAYLhqXNPNFD.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2025-07-15T13:58:19.000000Z",
                        "updated_at": "2025-07-15T13:58:19.000000Z",
                        "question_num_long": 6406531302209,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "35a123d043ab686a585b99560b3c856b",
                        "course_id": 86,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "2f8862a0-50d8-4cb1-ad8c-883f2eccb413",
                        "question_image_url": [
                            "/question_images/0azgWLycQqABEO0x8730MwuwYb1zosxfNYuSFdRAYLhqXNPNFD.png"
                        ],
                        "question_texts": [
                            "  Based on the above data, answer the given subquestions."
                        ]
                    }
                },
                {
                    "id": 95635,
                    "exam_id": 1,
                    "question_paper_id": 306,
                    "question_number": 174,
                    "question_text_1": "Based on the provided configuration, what is a primary characteristic of this language model\u2019s architecture and training paradigm?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-07-15T13:58:19.000000Z",
                    "updated_at": "2025-07-15T13:58:19.000000Z",
                    "question_num_long": 6406531302212,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "8285334d9fd8fee44fe176f95691a7f7",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 95632,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "16828a76-d2f1-4865-b967-1a2bcdb953a7",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Based on the provided configuration, what is a primary characteristic of this language model\u2019s architecture and training paradigm?"
                    ],
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [
                        {
                            "id": 252845,
                            "question_id": 95635,
                            "option_text": "It\u2019s an encoder-decoder model designed for sequence-to-sequence tasks liketranslation.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375706,
                            "option_image_url": null
                        },
                        {
                            "id": 252846,
                            "question_id": 95635,
                            "option_text": "It\u2019s an encoder-only model, likely using Masked Language Modeling for pre-training.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375707,
                            "option_image_url": null
                        },
                        {
                            "id": 252847,
                            "question_id": 95635,
                            "option_text": "It\u2019s a decoder-only model, pre-trained using a Causal Language Modelingobjective.",
                            "option_image": "",
                            "score": "3.000",
                            "is_correct": 1,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375708,
                            "option_image_url": null
                        },
                        {
                            "id": 252848,
                            "question_id": 95635,
                            "option_text": "It\u2019s a small model primarily intended for edge devices due to its limitedcontext length.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375709,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": {
                        "id": 95632,
                        "exam_id": 1,
                        "question_paper_id": 306,
                        "question_number": 0,
                        "question_text_1": "  Based on the above data, answer the given subquestions.",
                        "question_image_1": "0azgWLycQqABEO0x8730MwuwYb1zosxfNYuSFdRAYLhqXNPNFD.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2025-07-15T13:58:19.000000Z",
                        "updated_at": "2025-07-15T13:58:19.000000Z",
                        "question_num_long": 6406531302209,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "35a123d043ab686a585b99560b3c856b",
                        "course_id": 86,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "2f8862a0-50d8-4cb1-ad8c-883f2eccb413",
                        "question_image_url": [
                            "/question_images/0azgWLycQqABEO0x8730MwuwYb1zosxfNYuSFdRAYLhqXNPNFD.png"
                        ],
                        "question_texts": [
                            "  Based on the above data, answer the given subquestions."
                        ]
                    }
                },
                {
                    "id": 95636,
                    "exam_id": 1,
                    "question_paper_id": 306,
                    "question_number": 175,
                    "question_text_1": "Considering the Adam optimizer stores 2 floating-point values per model parameter and parameters are 32-bit floats (4 bytes), if the total number of trainable parameters in the model is exactly 350 Million, how much GPU memory (in Gigabytes, GB) would be required just for the optimizer states? (Assume 1 GB = 109 bytes). Enter your answer rounded to one decimal place.",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "2.7",
                    "value_end": "2.9",
                    "created_at": "2025-07-15T13:58:19.000000Z",
                    "updated_at": "2025-07-15T13:58:19.000000Z",
                    "question_num_long": 6406531302213,
                    "answer_type": "Range",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "4a2e5d4f42b3a0332c8c2b64f0560f2a",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 95632,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "d2143e74-fe17-4785-95bd-4bddcd6e20df",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Considering the Adam optimizer stores 2 floating-point values per model parameter and parameters are 32-bit floats (4 bytes), if the total number of trainable parameters in the model is exactly 350 Million, how much GPU memory (in Gigabytes, GB) would be required just for the optimizer states? (Assume 1 GB = 109 bytes). Enter your answer rounded to one decimal place."
                    ],
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [],
                    "parent_question": {
                        "id": 95632,
                        "exam_id": 1,
                        "question_paper_id": 306,
                        "question_number": 0,
                        "question_text_1": "  Based on the above data, answer the given subquestions.",
                        "question_image_1": "0azgWLycQqABEO0x8730MwuwYb1zosxfNYuSFdRAYLhqXNPNFD.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2025-07-15T13:58:19.000000Z",
                        "updated_at": "2025-07-15T13:58:19.000000Z",
                        "question_num_long": 6406531302209,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "35a123d043ab686a585b99560b3c856b",
                        "course_id": 86,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "2f8862a0-50d8-4cb1-ad8c-883f2eccb413",
                        "question_image_url": [
                            "/question_images/0azgWLycQqABEO0x8730MwuwYb1zosxfNYuSFdRAYLhqXNPNFD.png"
                        ],
                        "question_texts": [
                            "  Based on the above data, answer the given subquestions."
                        ]
                    }
                },
                {
                    "id": 95637,
                    "exam_id": 1,
                    "question_paper_id": 306,
                    "question_number": 176,
                    "question_text_1": "The configuration states the model uses Byte Pair Encoding (BPE). What is a key implication of this choice for handling text from diverse sources during inference?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-07-15T13:58:19.000000Z",
                    "updated_at": "2025-07-15T13:58:19.000000Z",
                    "question_num_long": 6406531302214,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "5ae014c8fc89abbcdf2007e01ea6394c",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 95632,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "3b85dc51-255f-43b6-884a-1ccfbe533b49",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "The configuration states the model uses Byte Pair Encoding (BPE). What is a key implication of this choice for handling text from diverse sources during inference?"
                    ],
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [
                        {
                            "id": 252849,
                            "question_id": 95637,
                            "option_text": "The model will be unable to process any words not seen during BPEvocabulary training, leading to frequent errors.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375711,
                            "option_image_url": null
                        },
                        {
                            "id": 252850,
                            "question_id": 95637,
                            "option_text": "All input words will be tokenized into individual characters, increasingsequence length significantly.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375712,
                            "option_image_url": null
                        },
                        {
                            "id": 252851,
                            "question_id": 95637,
                            "option_text": "Out-of-vocabulary words can be represented as sequences of known subwordunits, allowing the model to process them.",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375713,
                            "option_image_url": null
                        },
                        {
                            "id": 252852,
                            "question_id": 95637,
                            "option_text": "BPE ensures that every language will have roughly the same number of tokensfor a text of similar semantic content.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:58:19.000000Z",
                            "updated_at": "2025-07-15T13:58:19.000000Z",
                            "option_number": 6406534375714,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": {
                        "id": 95632,
                        "exam_id": 1,
                        "question_paper_id": 306,
                        "question_number": 0,
                        "question_text_1": "  Based on the above data, answer the given subquestions.",
                        "question_image_1": "0azgWLycQqABEO0x8730MwuwYb1zosxfNYuSFdRAYLhqXNPNFD.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2025-07-15T13:58:19.000000Z",
                        "updated_at": "2025-07-15T13:58:19.000000Z",
                        "question_num_long": 6406531302209,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "35a123d043ab686a585b99560b3c856b",
                        "course_id": 86,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "2f8862a0-50d8-4cb1-ad8c-883f2eccb413",
                        "question_image_url": [
                            "/question_images/0azgWLycQqABEO0x8730MwuwYb1zosxfNYuSFdRAYLhqXNPNFD.png"
                        ],
                        "question_texts": [
                            "  Based on the above data, answer the given subquestions."
                        ]
                    }
                }
            ]
        },
        "summary": "### Summary of Core Topics, Concepts, Principles, and Equations\n\n#### Core Topics and Concepts\n\n1. **Tokenization Strategies**\n   - **Character-level Tokenization**\n   - **Word-level Tokenization**\n   - **Subword Tokenization (BPE, WordPiece, SentencePiece)**\n   - **Handling Out-of-Vocabulary (OOV) Words**\n\n2. **Transformer Models and Fine-Tuning**\n   - **Pre-trained Language Models**\n   - **Full Fine-Tuning vs. Parameter-Efficient Fine-Tuning (PEFT)**\n   - **Instruction Tuning**\n   - **GPU Memory Bottlenecks**\n\n3. **Model Configuration and Initialization**\n   - **Hugging Face Transformers**\n   - **Model Configurations (BertConfig, GPT2Config, T5Config)**\n   - **Embedding Layers and Parameter Calculation**\n\n4. **Optimization and Memory Management**\n   - **Adam Optimizer and Memory Requirements**\n   - **GPU Memory Usage for Optimizer States**\n\n5. **Subword Tokenization Algorithms**\n   - **Byte Pair Encoding (BPE)**\n   - **WordPiece**\n   - **SentencePiece**\n\n6. **Model Architectures**\n   - **Causal Language Models**\n   - **Encoder-Decoder Models**\n   - **Encoder-Only Models**\n\n7. **Data Handling and Filtering**\n   - **Dataset Filtering**\n   - **Handling Text Data**\n\n#### Important Principles\n\n1. **Tokenization**\n   - Subword tokenization algorithms like BPE, WordPiece, and SentencePiece are effective for handling complex morphology and OOV words.\n   - Character-level tokenization can handle OOV words but may increase sequence length.\n   - Word-level tokenization with a fixed vocabulary may not handle OOV words effectively.\n\n2. **Fine-Tuning**\n   - Full fine-tuning of large pre-trained models can be resource-intensive.\n   - Parameter-Efficient Fine-Tuning (PEFT) techniques like LoRA can be effective with limited labeled data.\n   - Instruction tuning can align models with specific tasks using prompt-completion pairs.\n\n3. **Model Configuration**\n   - Different model configurations (BertConfig, GPT2Config, T5Config) are used for different types of models.\n   - Embedding layer parameters can be calculated based on vocabulary size and embedding dimension.\n\n4. **Optimization**\n   - The Adam optimizer requires significant GPU memory for storing optimizer states.\n   - Memory requirements can be calculated based on the number of parameters and the size of floating-point values.\n\n#### Key Equations\n\n1. **Parameter Calculation for Embedding Layer**\n   \\[\n   \\text{Total parameters} = \\text{vocab\\_size} \\times \\text{embedding\\_dimension}\n   \\]\n   Example: For a vocabulary size of 32,000 and embedding dimension of 1024,\n   \\[\n   \\text{Total parameters} = 32,000 \\times 1024 = 32,768,000 \\approx 32.8 \\text{ million}\n   \\]\n\n2. **Parameter Calculation for FFN Block**\n   \\[\n   \\text{Total parameters} = (d_{\\text{model}} \\times \\text{hidden\\_size} + \\text{hidden\\_size}) + (\\text{hidden\\_size} \\times d_{\\text{model}} + d_{\\text{model}})\n   \\]\n   Example: For \\(d_{\\text{model}} = 768\\) and hidden size = 3072,\n   \\[\n   \\text{Total parameters} = (768 \\times 3072 + 3072) + (3072 \\times 768 + 768) = 4,722,432 \\approx 4.7 \\text{ million}\n   \\]\n\n3. **GPU Memory for Optimizer States**\n   \\[\n   \\text{GPU Memory (GB)} = \\frac{\\text{Total parameters} \\times 2 \\times 4 \\text{ bytes}}{10^9}\n   \\]\n   Example: For 350 million parameters,\n   \\[\n   \\text{GPU Memory (GB)} = \\frac{350,000,000 \\times 2 \\times 4}{10^9} = 2.8 \\text{ GB}\n   \\]\n\n### Knowledge Graph \n\n```mermaid\ngraph TD;\n    A[Deep Learning Practice] --> B[Tokenization Strategies];\n    A --> C[Transformer Models and Fine-Tuning];\n    A --> D[Model Configuration and Initialization];\n    A --> E[Optimization and Memory Management];\n    A --> F[Subword Tokenization Algorithms];\n    A --> G[Model Architectures];\n    A --> H[Data Handling and Filtering];\n\n    B --> B1[Character-level Tokenization];\n    B --> B2[Word-level Tokenization];\n    B --> B3[Subword Tokenization];\n\n    C --> C1[Pre-trained Language Models];\n    C --> C2[Full Fine-Tuning];\n    C --> C3[Parameter-Efficient Fine-Tuning];\n    C --> C4[Instruction Tuning];\n\n    D --> D1[Hugging Face Transformers];\n    D --> D2[Model Configurations];\n    D --> D3[Embedding Layers];\n\n    E --> E1[Adam Optimizer];\n    E --> E2[GPU Memory Usage];\n\n    F --> F1[Byte Pair Encoding];\n    F --> F2[WordPiece];\n    F --> F3[SentencePiece];\n\n    G --> G1[Causal Language Models];\n    G --> G2[Encoder-Decoder Models];\n    G --> G3[Encoder-Only Models];\n\n    H --> H1[Dataset Filtering];\n    H --> H2[Handling Text Data];\n```\n\n```mermaid\ngraph TD;\n    Tokenization --> CharacterLevel;\n    Tokenization --> WordLevel;\n    Tokenization --> Subword;\n    Subword --> BPE;\n    Subword --> WordPiece;\n    Subword --> SentencePiece;\n\n    Models --> PreTrained;\n    Models --> FineTuning;\n    FineTuning --> Full;\n    FineTuning --> PEFT;\n    FineTuning --> Instruction;\n\n    Config --> HuggingFace;\n    Config --> Embedding;\n\n    Optimization --> Adam;\n    Optimization --> Memory;\n\n    Architectures --> Causal;\n    Architectures --> EncoderDecoder;\n    Architectures --> EncoderOnly;\n\n    Data --> Filtering;\n    Data --> TextHandling;\n```\n\nThis summary and knowledge graph should help you understand the core topics, concepts, principles, and equations essential for the exam.",
        "total_score": "50.00"
    },
    "url": "/question-paper/practise/86/1e3f441b-c5a",
    "version": "ee3d5d44299e610bd137ea6200db5ac2"
}