{
    "component": "Quizpractise/PractiseQuestionPaper",
    "props": {
        "errors": {},
        "auth": {
            "user": null
        },
        "flash": {
            "error": []
        },
        "banner": null,
        "file_url": "https://saram.blr1.cdn.digitaloceanspaces.com",
        "file_do_url": "https://saram.blr1.cdn.digitaloceanspaces.com",
        "question_paper": {
            "id": 297,
            "group_id": 29,
            "exam_id": 1,
            "total_score": "1.00",
            "duration": 4,
            "created_at": "2025-07-15T13:56:05.000000Z",
            "updated_at": "2025-07-15T13:56:05.000000Z",
            "question_paper_name": "IIT M DEGREE AN EXAM QDB4 13 July 2025",
            "question_paper_description": "2025 Jul13: IIT M AN EXAM QDB4",
            "uuid": "35770b5e-40f",
            "year": 2025,
            "is_new": 0,
            "exam": {
                "id": 1,
                "exam_name": "Quiz 1",
                "created_at": "2024-10-16T08:08:51.000000Z",
                "updated_at": "2024-10-16T08:08:51.000000Z",
                "uuid": "9251bc3a-e33e-45e0-bcf0-b16a0ea5b5fa",
                "en_id": "eyJpdiI6ImJURnFlOGx6YklsVWJlMEF0RXhaNXc9PSIsInZhbHVlIjoiODNqSmtnSXpQU1BBRm5zb2Rla0RDZz09IiwibWFjIjoiYTVhNDVmMmE1Y2QzZDYyNDRjYTY3MDk0M2NiYjRlMDQ4MzlhN2U2NjMyM2QxZWY3Nzg3NWU1NjJmZjVkMmUzNyIsInRhZyI6IiJ9"
            },
            "questions": [
                {
                    "id": 92625,
                    "exam_id": 1,
                    "question_paper_id": 297,
                    "question_number": 212,
                    "question_text_1": "THIS IS QUESTION PAPER FOR THE SUBJECT <b>\"DEGREE LEVEL : DEEP LEARNING PRACTICE </b><b>(COMPUTER BASED EXAM)\"</b><b> </b><b> </b><b>ARE YOU SURE YOU HAVE TO WRITE EXAM FOR THIS SUBJECT? </b><b>CROSS CHECK YOUR HALL TICKET TO CONFIRM THE SUBJECTS TO BE WRITTEN. </b><b> </b><b>(IF IT IS NOT THE CORRECT SUBJECT, PLS CHECK THE SECTION AT THE TOP FOR THE SUBJECTS </b><b>REGISTERED BY YOU)</b>",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "0.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-07-15T13:56:07.000000Z",
                    "updated_at": "2025-07-15T13:56:07.000000Z",
                    "question_num_long": 6406531293505,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "edc3aae55f01dbcc205f74a54ac6c5d1",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "928e6146-19c6-45d5-9950-27d5ea9593eb",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "THIS IS QUESTION PAPER FOR THE SUBJECT <b>\"DEGREE LEVEL : DEEP LEARNING PRACTICE </b><b>(COMPUTER BASED EXAM)\"</b><b> </b><b> </b><b>ARE YOU SURE YOU HAVE TO WRITE EXAM FOR THIS SUBJECT? </b><b>CROSS CHECK YOUR HALL TICKET TO CONFIRM THE SUBJECTS TO BE WRITTEN. </b><b> </b><b>(IF IT IS NOT THE CORRECT SUBJECT, PLS CHECK THE SECTION AT THE TOP FOR THE SUBJECTS </b><b>REGISTERED BY YOU)</b>"
                    ],
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [
                        {
                            "id": 246373,
                            "question_id": 92625,
                            "option_text": "YES",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 1,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352260,
                            "option_image_url": null
                        },
                        {
                            "id": 246374,
                            "question_id": 92625,
                            "option_text": "NO",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352261,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 92626,
                    "exam_id": 1,
                    "question_paper_id": 297,
                    "question_number": 213,
                    "question_text_1": "A start-up is building a new language model for a low-resource language with many compound words and complex morphology. They are debating tokenization strategies. Which of the following approaches is most likely to offer the best balance between vocabulary size, handling OOV words, and capturing morphological variants effectively for this scenario?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-07-15T13:56:07.000000Z",
                    "updated_at": "2025-07-15T13:56:07.000000Z",
                    "question_num_long": 6406531293506,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "660c51da57e4e483d4998811df327af2",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "04eebd8d-3e89-4abc-aaa1-96fb71385ba8",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "A start-up is building a new language model for a low-resource language with many compound words and complex morphology. They are debating tokenization strategies. Which of the following approaches is most likely to offer the best balance between vocabulary size, handling OOV words, and capturing morphological variants effectively for this scenario?"
                    ],
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [
                        {
                            "id": 246375,
                            "question_id": 92626,
                            "option_text": "Character-level tokenization",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352262,
                            "option_image_url": null
                        },
                        {
                            "id": 246376,
                            "question_id": 92626,
                            "option_text": "Word-level tokenization with a fixed vocabulary of 50,000 common words.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352263,
                            "option_image_url": null
                        },
                        {
                            "id": 246377,
                            "question_id": 92626,
                            "option_text": "Subword tokenization (e.g., BPE or SentencePiece) trained on the availablecorpus.",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352264,
                            "option_image_url": null
                        },
                        {
                            "id": 246378,
                            "question_id": 92626,
                            "option_text": "Using only pre-defined special tokens and treating all other text as raw bytesequences.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352265,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 92627,
                    "exam_id": 1,
                    "question_paper_id": 297,
                    "question_number": 214,
                    "question_text_1": "When fully fine-tuning a large pre-trained Transformer model (e.g., >1 Billion parameters), which of the following contributes LEAST significantly to the GPU memory bottleneck compared to the others?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-07-15T13:56:07.000000Z",
                    "updated_at": "2025-07-15T13:56:07.000000Z",
                    "question_num_long": 6406531293508,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "d0262b55cba2106882d18885469fe6f8",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "1ebeea03-6c38-48f0-a102-028b77a2b72a",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "When fully fine-tuning a large pre-trained Transformer model (e.g., >1 Billion parameters), which of the following contributes LEAST significantly to the GPU memory bottleneck compared to the others?"
                    ],
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [
                        {
                            "id": 246379,
                            "question_id": 92627,
                            "option_text": "Storing the model parameters themselves.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352270,
                            "option_image_url": null
                        },
                        {
                            "id": 246380,
                            "question_id": 92627,
                            "option_text": "Storing the gradients for each parameter.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352271,
                            "option_image_url": null
                        },
                        {
                            "id": 246381,
                            "question_id": 92627,
                            "option_text": "Storing the optimizer states (e.g., momentum and variance for Adam).",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352272,
                            "option_image_url": null
                        },
                        {
                            "id": 246382,
                            "question_id": 92627,
                            "option_text": "Storing the input batch data (token IDs).",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352273,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 92628,
                    "exam_id": 1,
                    "question_paper_id": 297,
                    "question_number": 215,
                    "question_text_1": "A research team wants their pre-trained language model to generate more helpful and harmless responses without extensive task-specific dataset collection. They have a collection of prompts and human-preferred responses. Which of the following techniques directly aligns with this goal and data?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-07-15T13:56:07.000000Z",
                    "updated_at": "2025-07-15T13:56:07.000000Z",
                    "question_num_long": 6406531293509,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "505f641e97785ad67d7dc7ad4f6e659e",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "2fea881e-e2ad-4e32-9134-32a3bdc5e30b",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "A research team wants their pre-trained language model to generate more helpful and harmless responses without extensive task-specific dataset collection. They have a collection of prompts and human-preferred responses. Which of the following techniques directly aligns with this goal and data?"
                    ],
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [
                        {
                            "id": 246383,
                            "question_id": 92628,
                            "option_text": "Pre-training the model on a larger, more diverse text corpus.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352274,
                            "option_image_url": null
                        },
                        {
                            "id": 246384,
                            "question_id": 92628,
                            "option_text": "Full fine-tuning on multiple downstream classification tasks.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352275,
                            "option_image_url": null
                        },
                        {
                            "id": 246385,
                            "question_id": 92628,
                            "option_text": "Instruction Tuning using prompt-completion pairs or reformatting existingdatasets into an instructional format.",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352276,
                            "option_image_url": null
                        },
                        {
                            "id": 246386,
                            "question_id": 92628,
                            "option_text": "Implementing Parameter-Efficient Fine-Tuning (PEFT) techniques like LoRa.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352277,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 92629,
                    "exam_id": 1,
                    "question_paper_id": 297,
                    "question_number": 216,
                    "question_text_1": null,
                    "question_image_1": "FZ4zgtey975uDt3AvoVVfCHHnBmrL35w84UxiSFlaD8ANoR7Vs.png",
                    "question_type": "MCQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-07-15T13:56:07.000000Z",
                    "updated_at": "2025-07-15T13:56:07.000000Z",
                    "question_num_long": 6406531293507,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "6b3e027dd03f8d32ddf0297c8ed2bf50",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "a96238d1-41b7-42e6-92d3-279a4a0a1a99",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/FZ4zgtey975uDt3AvoVVfCHHnBmrL35w84UxiSFlaD8ANoR7Vs.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [
                        {
                            "id": 246387,
                            "question_id": 92629,
                            "option_text": "",
                            "option_image": "XxM0scf3LrytJQS3sAYGVXLwMNzCx7mVgYFHrPlifD1f6cdCnA.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352266,
                            "option_image_url": "app/option_images/XxM0scf3LrytJQS3sAYGVXLwMNzCx7mVgYFHrPlifD1f6cdCnA.png"
                        },
                        {
                            "id": 246388,
                            "question_id": 92629,
                            "option_text": "",
                            "option_image": "TYBwoleBmgavZzsWdM1r6GtPp4tv1Kv9mkP1yn1mvLCX76x5Zm.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352267,
                            "option_image_url": "app/option_images/TYBwoleBmgavZzsWdM1r6GtPp4tv1Kv9mkP1yn1mvLCX76x5Zm.png"
                        },
                        {
                            "id": 246389,
                            "question_id": 92629,
                            "option_text": "",
                            "option_image": "688j7esF7mhIa0GQ5ROlqiR4amkjThDBfIWR6CB5mO3cTK9sWK.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352268,
                            "option_image_url": "app/option_images/688j7esF7mhIa0GQ5ROlqiR4amkjThDBfIWR6CB5mO3cTK9sWK.png"
                        },
                        {
                            "id": 246390,
                            "question_id": 92629,
                            "option_text": "",
                            "option_image": "h9QQGVoIHdbyIRfOr62NcDNydWDxo4iHGRpe1ON1RvP5LaeBgB.png",
                            "score": "3.000",
                            "is_correct": 1,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352269,
                            "option_image_url": "app/option_images/h9QQGVoIHdbyIRfOr62NcDNydWDxo4iHGRpe1ON1RvP5LaeBgB.png"
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 92630,
                    "exam_id": 1,
                    "question_paper_id": 297,
                    "question_number": 217,
                    "question_text_1": null,
                    "question_image_1": "V1Bk4DwCVprnXF11jzHiCdGKuK84oV5MhAFgtAC62UhBtrea0R.png",
                    "question_type": "MCQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-07-15T13:56:07.000000Z",
                    "updated_at": "2025-07-15T13:56:07.000000Z",
                    "question_num_long": 6406531293510,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "d880e30f7d05b1d19450b82c858f6cf2",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "72189f90-a803-468b-9c59-eeb5cbd06662",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/V1Bk4DwCVprnXF11jzHiCdGKuK84oV5MhAFgtAC62UhBtrea0R.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [
                        {
                            "id": 246391,
                            "question_id": 92630,
                            "option_text": "",
                            "option_image": "NNiQJlpvAmzpLOhEWMZZ4kszyEUjwndRbO7b7nX03CY4wuFtEY.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352278,
                            "option_image_url": "app/option_images/NNiQJlpvAmzpLOhEWMZZ4kszyEUjwndRbO7b7nX03CY4wuFtEY.png"
                        },
                        {
                            "id": 246392,
                            "question_id": 92630,
                            "option_text": "",
                            "option_image": "XWllVRITjaF5AhTcnDkdVxRLizzp4oehXrTOTRnVenGzFrgYX2.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352279,
                            "option_image_url": "app/option_images/XWllVRITjaF5AhTcnDkdVxRLizzp4oehXrTOTRnVenGzFrgYX2.png"
                        },
                        {
                            "id": 246393,
                            "question_id": 92630,
                            "option_text": "",
                            "option_image": "JYJmVZbKdofoVKGNVWZJERkMa1o6EyFVRmnaLd4vTbsvDxwsym.png",
                            "score": "3.000",
                            "is_correct": 1,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352280,
                            "option_image_url": "app/option_images/JYJmVZbKdofoVKGNVWZJERkMa1o6EyFVRmnaLd4vTbsvDxwsym.png"
                        },
                        {
                            "id": 246394,
                            "question_id": 92630,
                            "option_text": "",
                            "option_image": "W8VixZCYizKB2nDdnO9Ut8PXh4luvN8eLzjdLQtpGO3bUqcjsU.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352281,
                            "option_image_url": "app/option_images/W8VixZCYizKB2nDdnO9Ut8PXh4luvN8eLzjdLQtpGO3bUqcjsU.png"
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 92631,
                    "exam_id": 1,
                    "question_paper_id": 297,
                    "question_number": 218,
                    "question_text_1": "Which of the following statements accurately describe common characteristics or goals of subword tokenization algorithms like BPE, WordPiece, or SentencePiece? (Select ALL that apply)",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "4.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-07-15T13:56:07.000000Z",
                    "updated_at": "2025-07-15T13:56:07.000000Z",
                    "question_num_long": 6406531293511,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "f7ea52e0d58afb499503e5214adacd5f",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "1230f2de-c487-4ada-8354-8771ccd29981",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following statements accurately describe common characteristics or goals of subword tokenization algorithms like BPE, WordPiece, or SentencePiece? (Select ALL that apply)"
                    ],
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [
                        {
                            "id": 246395,
                            "question_id": 92631,
                            "option_text": "They aim to significantly reduce the vocabulary size compared to character-level tokenization.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352282,
                            "option_image_url": null
                        },
                        {
                            "id": 246396,
                            "question_id": 92631,
                            "option_text": "They can handle out-of-vocabulary (OOV) words by breaking them into knownsubword units.",
                            "option_image": "",
                            "score": "1.333",
                            "is_correct": 1,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352283,
                            "option_image_url": null
                        },
                        {
                            "id": 246397,
                            "question_id": 92631,
                            "option_text": "They primarily rely on merging the least frequent character or subword pairsto build the vocabulary.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352284,
                            "option_image_url": null
                        },
                        {
                            "id": 246398,
                            "question_id": 92631,
                            "option_text": "They can represent common words as single tokens and rare words assequences of subword tokens.",
                            "option_image": "",
                            "score": "1.333",
                            "is_correct": 1,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352285,
                            "option_image_url": null
                        },
                        {
                            "id": 246399,
                            "question_id": 92631,
                            "option_text": "SentencePiece is designed to be language-agnostic, not requiring pre-segmentation based on spaces.",
                            "option_image": "",
                            "score": "1.333",
                            "is_correct": 1,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352286,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 92632,
                    "exam_id": 1,
                    "question_paper_id": 297,
                    "question_number": 219,
                    "question_text_1": "A team has a powerful pre-trained language model (e.g., a GPT-3 class model). They want to adapt it for a new summarization task but have very limited labeled summarization data and limited compute for full fine-tuning. Which of the following strategies could be viable and effective? (Select ALL that apply)",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "4.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-07-15T13:56:07.000000Z",
                    "updated_at": "2025-07-15T13:56:07.000000Z",
                    "question_num_long": 6406531293512,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "75ba921be1647efac5935ee39c361117",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "ff07a2b5-2ee7-463f-a283-4cdf5f3fc8b7",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "A team has a powerful pre-trained language model (e.g., a GPT-3 class model). They want to adapt it for a new summarization task but have very limited labeled summarization data and limited compute for full fine-tuning. Which of the following strategies could be viable and effective? (Select ALL that apply)"
                    ],
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [
                        {
                            "id": 246400,
                            "question_id": 92632,
                            "option_text": "Zero-shot prompting by providing the text and an instruction like \"Summarizethis:\".",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352287,
                            "option_image_url": null
                        },
                        {
                            "id": 246401,
                            "question_id": 92632,
                            "option_text": "Few-shot prompting (in-context learning) by providing a few examples of textand their summaries in the prompt before the target text.",
                            "option_image": "",
                            "score": "1.333",
                            "is_correct": 1,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352288,
                            "option_image_url": null
                        },
                        {
                            "id": 246402,
                            "question_id": 92632,
                            "option_text": "Full supervised fine-tuning of all model parameters on the small labeleddataset.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352289,
                            "option_image_url": null
                        },
                        {
                            "id": 246403,
                            "question_id": 92632,
                            "option_text": "Using a Parameter-Efficient Fine-Tuning (PEFT) method like LoRA on the smalllabeled dataset.",
                            "option_image": "",
                            "score": "1.333",
                            "is_correct": 1,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352290,
                            "option_image_url": null
                        },
                        {
                            "id": 246404,
                            "question_id": 92632,
                            "option_text": "Collecting a much larger unlabeled corpus related to the summarizationdomain and continuing pre-training.",
                            "option_image": "",
                            "score": "1.333",
                            "is_correct": 1,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352291,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 92633,
                    "exam_id": 1,
                    "question_paper_id": 297,
                    "question_number": 220,
                    "question_text_1": null,
                    "question_image_1": "yx0HbrjXjhyeg1Lybp5hYZbnKPXlrzVWJi2KGw5PGcATNQ3Y35.png",
                    "question_type": "MSQ",
                    "total_mark": "4.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-07-15T13:56:07.000000Z",
                    "updated_at": "2025-07-15T13:56:07.000000Z",
                    "question_num_long": 6406531293513,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "4ad8b7632e3f6f5c6a4f41a0f6be5674",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "e8cc7a4d-d2ac-4d28-bc8b-14cd0a7d1d57",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/yx0HbrjXjhyeg1Lybp5hYZbnKPXlrzVWJi2KGw5PGcATNQ3Y35.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [
                        {
                            "id": 246405,
                            "question_id": 92633,
                            "option_text": "",
                            "option_image": "Q8bb0dOAR7u2RbstfVxbBwdN3P5wAbWgzLasvKoNPd8ID5YX2m.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352292,
                            "option_image_url": "app/option_images/Q8bb0dOAR7u2RbstfVxbBwdN3P5wAbWgzLasvKoNPd8ID5YX2m.png"
                        },
                        {
                            "id": 246406,
                            "question_id": 92633,
                            "option_text": "",
                            "option_image": "qh2LbRGyeUMiKzZymK7GlYEaFDmn9HeV6ROnF5WMRJQmgNsj1U.png",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352293,
                            "option_image_url": "app/option_images/qh2LbRGyeUMiKzZymK7GlYEaFDmn9HeV6ROnF5WMRJQmgNsj1U.png"
                        },
                        {
                            "id": 246407,
                            "question_id": 92633,
                            "option_text": "",
                            "option_image": "gLNFxJGpbUnqK89lcdsn2PUNeXpxSUur9VnMobv88VnLfgMLTH.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352294,
                            "option_image_url": "app/option_images/gLNFxJGpbUnqK89lcdsn2PUNeXpxSUur9VnMobv88VnLfgMLTH.png"
                        },
                        {
                            "id": 246408,
                            "question_id": 92633,
                            "option_text": "",
                            "option_image": "n5cgd94MoGv138qIdsQjiEuIBgWGzIslP3nUTjMnujXz2MOt3Q.png",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352295,
                            "option_image_url": "app/option_images/n5cgd94MoGv138qIdsQjiEuIBgWGzIslP3nUTjMnujXz2MOt3Q.png"
                        },
                        {
                            "id": 246409,
                            "question_id": 92633,
                            "option_text": "",
                            "option_image": "PutCFDrh3UMx0SU9tJcIFJX0Ih0VO1hcUloHGmm561Voo7Zifc.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352296,
                            "option_image_url": "app/option_images/PutCFDrh3UMx0SU9tJcIFJX0Ih0VO1hcUloHGmm561Voo7Zifc.png"
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 92634,
                    "exam_id": 1,
                    "question_paper_id": 297,
                    "question_number": 221,
                    "question_text_1": null,
                    "question_image_1": "CpqAAQgtB1ayQosLDeL42Ofu3olis4VJDq6lvkWjuClXyRD41N.png",
                    "question_type": "SA",
                    "total_mark": "3.00",
                    "value_start": "5",
                    "value_end": null,
                    "created_at": "2025-07-15T13:56:07.000000Z",
                    "updated_at": "2025-07-15T13:56:07.000000Z",
                    "question_num_long": 6406531293514,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "0d7d2a57a7d04e462b0750508a94e6f5",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "ece80803-64b5-4ee8-8565-9d5acb0b0998",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/CpqAAQgtB1ayQosLDeL42Ofu3olis4VJDq6lvkWjuClXyRD41N.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 92635,
                    "exam_id": 1,
                    "question_paper_id": 297,
                    "question_number": 222,
                    "question_text_1": null,
                    "question_image_1": "XoQgAJNhwS4LfsnwGQ6Utu40jWzbeecQOXWkZzuPww43IU6aQm.png",
                    "question_type": "SA",
                    "total_mark": "3.00",
                    "value_start": "2",
                    "value_end": null,
                    "created_at": "2025-07-15T13:56:07.000000Z",
                    "updated_at": "2025-07-15T13:56:07.000000Z",
                    "question_num_long": 6406531293516,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "cdb96dc3ed3a170d6f1833f50af50925",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "245584e0-0dd6-487b-af39-2be4a0b98c22",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/XoQgAJNhwS4LfsnwGQ6Utu40jWzbeecQOXWkZzuPww43IU6aQm.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 92636,
                    "exam_id": 1,
                    "question_paper_id": 297,
                    "question_number": 223,
                    "question_text_1": null,
                    "question_image_1": "Q9xo3Fdu5cTRAkRUhDPOYzDX6wn2MCuFBpp7k4kDIcjzxTVRlB.png",
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "4.6",
                    "value_end": "4.8",
                    "created_at": "2025-07-15T13:56:07.000000Z",
                    "updated_at": "2025-07-15T13:56:07.000000Z",
                    "question_num_long": 6406531293515,
                    "answer_type": "Range",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "2b971749eb96dbaae7ef5eb351912679",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "1e635b04-495a-499f-9a2f-780bd7f799b6",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/Q9xo3Fdu5cTRAkRUhDPOYzDX6wn2MCuFBpp7k4kDIcjzxTVRlB.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 92637,
                    "exam_id": 1,
                    "question_paper_id": 297,
                    "question_number": 0,
                    "question_text_1": "  Based on the above data, answer the given subquestions.",
                    "question_image_1": "ZlO97mBrxphLhfALDAiodkLyaDsYOAB5N0oKC8SUfaI83zqinJ.png",
                    "question_type": "COMPREHENSION",
                    "total_mark": "0.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-07-15T13:56:07.000000Z",
                    "updated_at": "2025-07-15T13:56:07.000000Z",
                    "question_num_long": 6406531293517,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 0,
                    "hash": "35a123d043ab686a585b99560b3c856b",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "ee70a97c-d082-4463-9028-10de9e4f6893",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/ZlO97mBrxphLhfALDAiodkLyaDsYOAB5N0oKC8SUfaI83zqinJ.png"
                    ],
                    "question_texts": [
                        "  Based on the above data, answer the given subquestions."
                    ],
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 92638,
                    "exam_id": 1,
                    "question_paper_id": 297,
                    "question_number": 224,
                    "question_text_1": null,
                    "question_image_1": "FQI8Xf2bK7Kz0SPxejWsJff8COFSpTDVbz4Vtge6ws2bUVfgWV.png",
                    "question_type": "MCQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-07-15T13:56:07.000000Z",
                    "updated_at": "2025-07-15T13:56:07.000000Z",
                    "question_num_long": 6406531293518,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "3f139927db19327a8f64d4e4044a1760",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 92637,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "02076abd-a391-488a-9bc7-6313fb89a707",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/FQI8Xf2bK7Kz0SPxejWsJff8COFSpTDVbz4Vtge6ws2bUVfgWV.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [
                        {
                            "id": 246410,
                            "question_id": 92638,
                            "option_text": "",
                            "option_image": "4f3gEa29CXGyViTgDKopG7QXcwojGIb4MemVrSVzODdbN7hXeK.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352300,
                            "option_image_url": "app/option_images/4f3gEa29CXGyViTgDKopG7QXcwojGIb4MemVrSVzODdbN7hXeK.png"
                        },
                        {
                            "id": 246411,
                            "question_id": 92638,
                            "option_text": "",
                            "option_image": "EGIqFIX9nGuE494mFaBQw5nsVREmmL3ytKDrZZesfNhHxUWqW3.png",
                            "score": "3.000",
                            "is_correct": 1,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352301,
                            "option_image_url": "app/option_images/EGIqFIX9nGuE494mFaBQw5nsVREmmL3ytKDrZZesfNhHxUWqW3.png"
                        },
                        {
                            "id": 246412,
                            "question_id": 92638,
                            "option_text": "",
                            "option_image": "P8LZstwbgiwjRLbvI1UDwZcsDiontWwwOrPXvW5yhhsWpzcck9.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352302,
                            "option_image_url": "app/option_images/P8LZstwbgiwjRLbvI1UDwZcsDiontWwwOrPXvW5yhhsWpzcck9.png"
                        },
                        {
                            "id": 246413,
                            "question_id": 92638,
                            "option_text": "",
                            "option_image": "GHUYKLH2JNC9dPrl2fJQ74yK2N2fPPOTAM7JCJQNuYgHfGDAXF.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352303,
                            "option_image_url": "app/option_images/GHUYKLH2JNC9dPrl2fJQ74yK2N2fPPOTAM7JCJQNuYgHfGDAXF.png"
                        }
                    ],
                    "parent_question": {
                        "id": 92637,
                        "exam_id": 1,
                        "question_paper_id": 297,
                        "question_number": 0,
                        "question_text_1": "  Based on the above data, answer the given subquestions.",
                        "question_image_1": "ZlO97mBrxphLhfALDAiodkLyaDsYOAB5N0oKC8SUfaI83zqinJ.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2025-07-15T13:56:07.000000Z",
                        "updated_at": "2025-07-15T13:56:07.000000Z",
                        "question_num_long": 6406531293517,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "35a123d043ab686a585b99560b3c856b",
                        "course_id": 86,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "ee70a97c-d082-4463-9028-10de9e4f6893",
                        "question_image_url": [
                            "/question_images/ZlO97mBrxphLhfALDAiodkLyaDsYOAB5N0oKC8SUfaI83zqinJ.png"
                        ],
                        "question_texts": [
                            "  Based on the above data, answer the given subquestions."
                        ]
                    }
                },
                {
                    "id": 92639,
                    "exam_id": 1,
                    "question_paper_id": 297,
                    "question_number": 225,
                    "question_text_1": "Based on the provided configuration, calculate the total number of parameters in the model\u2019s embedding layer (token embeddings) in millions. Enter your answer rounded to one decimal place.",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "32.7",
                    "value_end": "32.9",
                    "created_at": "2025-07-15T13:56:07.000000Z",
                    "updated_at": "2025-07-15T13:56:07.000000Z",
                    "question_num_long": 6406531293519,
                    "answer_type": "Range",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "47ec40da47239be4bcfe9b27f60967e0",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 92637,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "178eb8f4-7840-4886-8372-3ea10447706a",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Based on the provided configuration, calculate the total number of parameters in the model\u2019s embedding layer (token embeddings) in millions. Enter your answer rounded to one decimal place."
                    ],
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [],
                    "parent_question": {
                        "id": 92637,
                        "exam_id": 1,
                        "question_paper_id": 297,
                        "question_number": 0,
                        "question_text_1": "  Based on the above data, answer the given subquestions.",
                        "question_image_1": "ZlO97mBrxphLhfALDAiodkLyaDsYOAB5N0oKC8SUfaI83zqinJ.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2025-07-15T13:56:07.000000Z",
                        "updated_at": "2025-07-15T13:56:07.000000Z",
                        "question_num_long": 6406531293517,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "35a123d043ab686a585b99560b3c856b",
                        "course_id": 86,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "ee70a97c-d082-4463-9028-10de9e4f6893",
                        "question_image_url": [
                            "/question_images/ZlO97mBrxphLhfALDAiodkLyaDsYOAB5N0oKC8SUfaI83zqinJ.png"
                        ],
                        "question_texts": [
                            "  Based on the above data, answer the given subquestions."
                        ]
                    }
                },
                {
                    "id": 92640,
                    "exam_id": 1,
                    "question_paper_id": 297,
                    "question_number": 226,
                    "question_text_1": "Based on the provided configuration, what is a primary characteristic of this language model\u2019s architecture and training paradigm?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-07-15T13:56:07.000000Z",
                    "updated_at": "2025-07-15T13:56:07.000000Z",
                    "question_num_long": 6406531293520,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "2e9b15eedb0901f1e23dcb931fe76a23",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 92637,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "c3f4d414-f177-4139-8b96-04cbd7b7e88b",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Based on the provided configuration, what is a primary characteristic of this language model\u2019s architecture and training paradigm?"
                    ],
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [
                        {
                            "id": 246414,
                            "question_id": 92640,
                            "option_text": "It\u2019s an encoder-decoder model designed for sequence-to-sequence tasks liketranslation.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352305,
                            "option_image_url": null
                        },
                        {
                            "id": 246415,
                            "question_id": 92640,
                            "option_text": "It\u2019s an encoder-only model, likely using Masked Language Modeling for pre-training.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352306,
                            "option_image_url": null
                        },
                        {
                            "id": 246416,
                            "question_id": 92640,
                            "option_text": "It\u2019s a decoder-only model, pre-trained using a Causal Language Modelingobjective.",
                            "option_image": "",
                            "score": "3.000",
                            "is_correct": 1,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352307,
                            "option_image_url": null
                        },
                        {
                            "id": 246417,
                            "question_id": 92640,
                            "option_text": "It\u2019s a small model primarily intended for edge devices due to its limitedcontext length.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352308,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": {
                        "id": 92637,
                        "exam_id": 1,
                        "question_paper_id": 297,
                        "question_number": 0,
                        "question_text_1": "  Based on the above data, answer the given subquestions.",
                        "question_image_1": "ZlO97mBrxphLhfALDAiodkLyaDsYOAB5N0oKC8SUfaI83zqinJ.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2025-07-15T13:56:07.000000Z",
                        "updated_at": "2025-07-15T13:56:07.000000Z",
                        "question_num_long": 6406531293517,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "35a123d043ab686a585b99560b3c856b",
                        "course_id": 86,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "ee70a97c-d082-4463-9028-10de9e4f6893",
                        "question_image_url": [
                            "/question_images/ZlO97mBrxphLhfALDAiodkLyaDsYOAB5N0oKC8SUfaI83zqinJ.png"
                        ],
                        "question_texts": [
                            "  Based on the above data, answer the given subquestions."
                        ]
                    }
                },
                {
                    "id": 92641,
                    "exam_id": 1,
                    "question_paper_id": 297,
                    "question_number": 227,
                    "question_text_1": "Considering the Adam optimizer stores 2 floating-point values per model parameter and parameters are 32-bit floats (4 bytes), if the total number of trainable parameters in the model is exactly 350 Million, how much GPU memory (in Gigabytes, GB) would be required just for the optimizer states? (Assume 1 GB = 109 bytes). Enter your answer rounded to one decimal place.",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "2.7",
                    "value_end": "2.9",
                    "created_at": "2025-07-15T13:56:07.000000Z",
                    "updated_at": "2025-07-15T13:56:07.000000Z",
                    "question_num_long": 6406531293521,
                    "answer_type": "Range",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "4a2e5d4f42b3a0332c8c2b64f0560f2a",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 92637,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "2c77a013-4335-47b1-8f1c-2ac7bc67af2e",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Considering the Adam optimizer stores 2 floating-point values per model parameter and parameters are 32-bit floats (4 bytes), if the total number of trainable parameters in the model is exactly 350 Million, how much GPU memory (in Gigabytes, GB) would be required just for the optimizer states? (Assume 1 GB = 109 bytes). Enter your answer rounded to one decimal place."
                    ],
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [],
                    "parent_question": {
                        "id": 92637,
                        "exam_id": 1,
                        "question_paper_id": 297,
                        "question_number": 0,
                        "question_text_1": "  Based on the above data, answer the given subquestions.",
                        "question_image_1": "ZlO97mBrxphLhfALDAiodkLyaDsYOAB5N0oKC8SUfaI83zqinJ.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2025-07-15T13:56:07.000000Z",
                        "updated_at": "2025-07-15T13:56:07.000000Z",
                        "question_num_long": 6406531293517,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "35a123d043ab686a585b99560b3c856b",
                        "course_id": 86,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "ee70a97c-d082-4463-9028-10de9e4f6893",
                        "question_image_url": [
                            "/question_images/ZlO97mBrxphLhfALDAiodkLyaDsYOAB5N0oKC8SUfaI83zqinJ.png"
                        ],
                        "question_texts": [
                            "  Based on the above data, answer the given subquestions."
                        ]
                    }
                },
                {
                    "id": 92642,
                    "exam_id": 1,
                    "question_paper_id": 297,
                    "question_number": 228,
                    "question_text_1": "The configuration states the model uses Byte Pair Encoding (BPE). What is a key implication of this choice for handling text from diverse sources during inference?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-07-15T13:56:07.000000Z",
                    "updated_at": "2025-07-15T13:56:07.000000Z",
                    "question_num_long": 6406531293522,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "04c6fb767bca4c1cf72293ee47b79a3d",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": 92637,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "aeb6fe04-eddc-473e-bc7b-d777d3950894",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "The configuration states the model uses Byte Pair Encoding (BPE). What is a key implication of this choice for handling text from diverse sources during inference?"
                    ],
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [
                        {
                            "id": 246418,
                            "question_id": 92642,
                            "option_text": "The model will be unable to process any words not seen during BPEvocabulary training, leading to frequent errors.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352310,
                            "option_image_url": null
                        },
                        {
                            "id": 246419,
                            "question_id": 92642,
                            "option_text": "All input words will be tokenized into individual characters, increasingsequence length significantly.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352311,
                            "option_image_url": null
                        },
                        {
                            "id": 246420,
                            "question_id": 92642,
                            "option_text": "Out-of-vocabulary words can be represented as sequences of known subwordunits, allowing the model to process them.",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352312,
                            "option_image_url": null
                        },
                        {
                            "id": 246421,
                            "question_id": 92642,
                            "option_text": "BPE ensures that every language will have roughly the same number of tokensfor a text of similar semantic content.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-07-15T13:56:07.000000Z",
                            "updated_at": "2025-07-15T13:56:07.000000Z",
                            "option_number": 6406534352313,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": {
                        "id": 92637,
                        "exam_id": 1,
                        "question_paper_id": 297,
                        "question_number": 0,
                        "question_text_1": "  Based on the above data, answer the given subquestions.",
                        "question_image_1": "ZlO97mBrxphLhfALDAiodkLyaDsYOAB5N0oKC8SUfaI83zqinJ.png",
                        "question_type": "COMPREHENSION",
                        "total_mark": "0.00",
                        "value_start": null,
                        "value_end": null,
                        "created_at": "2025-07-15T13:56:07.000000Z",
                        "updated_at": "2025-07-15T13:56:07.000000Z",
                        "question_num_long": 6406531293517,
                        "answer_type": null,
                        "response_type": null,
                        "have_answers": 0,
                        "hash": "35a123d043ab686a585b99560b3c856b",
                        "course_id": 86,
                        "is_markdown": 0,
                        "question_text_2": null,
                        "question_image_2": null,
                        "question_image_3": null,
                        "question_image_4": null,
                        "question_image_5": null,
                        "question_image_7": null,
                        "question_image_8": null,
                        "question_image_9": null,
                        "question_image_10": null,
                        "parent_question_id": null,
                        "question_text_3": null,
                        "question_text_4": null,
                        "question_text_5": null,
                        "uuid": "ee70a97c-d082-4463-9028-10de9e4f6893",
                        "question_image_url": [
                            "/question_images/ZlO97mBrxphLhfALDAiodkLyaDsYOAB5N0oKC8SUfaI83zqinJ.png"
                        ],
                        "question_texts": [
                            "  Based on the above data, answer the given subquestions."
                        ]
                    }
                }
            ]
        },
        "summary": "### Summary of Core Topics, Concepts, Principles, and Equations\n\n#### Core Topics and Concepts\n\n1. **Tokenization Strategies**\n   - **Character-level Tokenization**: Breaking text into individual characters.\n   - **Word-level Tokenization**: Breaking text into words based on a fixed vocabulary.\n   - **Subword Tokenization**: Algorithms like BPE (Byte Pair Encoding), WordPiece, and SentencePiece that break text into subword units.\n   - **Handling OOV Words**: Using subword tokenization to handle out-of-vocabulary words by breaking them into known subword units.\n\n2. **Model Fine-Tuning and Training**\n   - **Full Fine-Tuning**: Adjusting all parameters of a pre-trained model.\n   - **Parameter-Efficient Fine-Tuning (PEFT)**: Techniques like LoRA (Low-Rank Adaptation) that fine-tune a subset of parameters.\n   - **Instruction Tuning**: Using prompt-completion pairs to fine-tune models for specific tasks.\n   - **GPU Memory Bottlenecks**: Understanding the contributions of model parameters, gradients, optimizer states, and input batch data to GPU memory usage.\n\n3. **Model Architectures**\n   - **Transformer Models**: Understanding the architecture of models like GPT, BERT, and T5.\n   - **Embedding Layers**: Calculating the number of parameters in embedding layers.\n   - **Feed-Forward Networks (FFN)**: Calculating the number of parameters in FFN layers.\n\n4. **Optimizers and Memory Usage**\n   - **Adam Optimizer**: Understanding the memory requirements for storing optimizer states.\n   - **GPU Memory Calculation**: Calculating the memory required for optimizer states based on the number of parameters.\n\n5. **Data Handling and Processing**\n   - **Dataset Filtering**: Using functions to filter datasets based on specific conditions.\n   - **Tokenization Process**: Understanding the steps involved in tokenization, including normalization, pre-tokenization, and post-processing.\n\n6. **Model Configuration and Initialization**\n   - **Hugging Face Transformers**: Initializing model configurations using Hugging Face's `transformers` library.\n   - **Model Configurations**: Understanding the parameters involved in model configurations, such as `vocab_size`, `hidden_size`, `num_hidden_layers`, and `num_attention_heads`.\n\n#### Important Equations\n\n1. **Total Parameters in FFN Block**\n   \\[\n   \\text{Total parameters} = (d_{\\text{model}} \\times \\text{hidden size} + \\text{hidden size}) + (\\text{hidden size} \\times d_{\\text{model}} + d_{\\text{model}})\n   \\]\n   Where \\(d_{\\text{model}}\\) is the embedding dimension and \\(\\text{hidden size}\\) is the size of the hidden layer.\n\n2. **GPU Memory for Optimizer States**\n   \\[\n   \\text{GPU Memory (GB)} = \\frac{\\text{Number of Parameters} \\times 2 \\times 4 \\text{ bytes}}{10^9}\n   \\]\n   This equation calculates the GPU memory required for storing optimizer states, assuming 2 floating-point values per parameter and 4 bytes per floating-point value.\n\n3. **Vocabulary Size After BPE Merge**\n   \\[\n   \\text{New Vocabulary Size} = \\text{Initial Vocabulary Size} + 1\n   \\]\n   This equation accounts for the addition of a new token after performing a BPE merge operation.\n\n4. **Total Parameters in Embedding Layer**\n   \\[\n   \\text{Total parameters} = \\text{vocab\\_size} \\times d_{\\text{model}}\n   \\]\n   This equation calculates the total number of parameters in the embedding layer, where \\(\\text{vocab\\_size}\\) is the size of the vocabulary and \\(d_{\\text{model}}\\) is the embedding dimension.\n\n### Mermaid Knowledge Graph\n\n```mermaid\ngraph TD;\n    A[Deep Learning Practice] --> B[Tokenization Strategies];\n    A --> C[Model Fine-Tuning and Training];\n    A --> D[Model Architectures];\n    A --> E[Optimizers and Memory Usage];\n    A --> F[Data Handling and Processing];\n    A --> G[Model Configuration and Initialization];\n\n    B --> B1[Character-level Tokenization];\n    B --> B2[Word-level Tokenization];\n    B --> B3[Subword Tokenization];\n    B --> B4[Handling OOV Words];\n\n    C --> C1[Full Fine-Tuning];\n    C --> C2[Parameter-Efficient Fine-Tuning];\n    C --> C3[Instruction Tuning];\n    C --> C4[GPU Memory Bottlenecks];\n\n    D --> D1[Transformer Models];\n    D --> D2[Embedding Layers];\n    D --> D3[Feed-Forward Networks];\n\n    E --> E1[Adam Optimizer];\n    E --> E2[GPU Memory Calculation];\n\n    F --> F1[Dataset Filtering];\n    F --> F2[Tokenization Process];\n\n    G --> G1[Hugging Face Transformers];\n    G --> G2[Model Configurations];\n```\n\n```mermaid\ngraph TD;\n    B[Tokenization Strategies] --> B1[Character-level Tokenization];\n    B --> B2[Word-level Tokenization];\n    B --> B3[Subword Tokenization];\n    B --> B4[Handling OOV Words];\n\n    C[Model Fine-Tuning and Training] --> C1[Full Fine-Tuning];\n    C --> C2[Parameter-Efficient Fine-Tuning];\n    C --> C3[Instruction Tuning];\n    C --> C4[GPU Memory Bottlenecks];\n\n    D[Model Architectures] --> D1[Transformer Models];\n    D --> D2[Embedding Layers];\n    D --> D3[Feed-Forward Networks];\n\n    E[Optimizers and Memory Usage] --> E1[Adam Optimizer];\n    E --> E2[GPU Memory Calculation];\n\n    F[Data Handling and Processing] --> F1[Dataset Filtering];\n    F --> F2[Tokenization Process];\n\n    G[Model Configuration and Initialization] --> G1[Hugging Face Transformers];\n    G --> G2[Model Configurations];\n```\n\nThese graphs provide a visual representation of the relationships between the core topics, concepts, and principles essential for the exam.",
        "total_score": "50.00"
    },
    "url": "/question-paper/practise/86/35770b5e-40f",
    "version": "ee3d5d44299e610bd137ea6200db5ac2"
}