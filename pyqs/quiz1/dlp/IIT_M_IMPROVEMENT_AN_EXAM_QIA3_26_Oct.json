{
    "component": "Quizpractise/PractiseQuestionPaper",
    "props": {
        "errors": {},
        "auth": {
            "user": null
        },
        "flash": {
            "error": []
        },
        "banner": null,
        "file_url": "https://saram.blr1.cdn.digitaloceanspaces.com",
        "file_do_url": "https://saram.blr1.cdn.digitaloceanspaces.com",
        "question_paper": {
            "id": 366,
            "group_id": 31,
            "exam_id": 1,
            "total_score": "1.00",
            "duration": 4,
            "created_at": "2025-11-16T14:11:37.000000Z",
            "updated_at": "2025-11-16T14:11:37.000000Z",
            "question_paper_name": "IIT M IMPROVEMENT AN EXAM QIA3 26 Oct",
            "question_paper_description": "2025 Oct26: IIT M AN EXAM QIA3",
            "uuid": "e45173cc-382",
            "year": 2025,
            "is_new": 0,
            "exam": {
                "id": 1,
                "exam_name": "Quiz 1",
                "created_at": "2024-10-16T08:08:51.000000Z",
                "updated_at": "2024-10-16T08:08:51.000000Z",
                "uuid": "9251bc3a-e33e-45e0-bcf0-b16a0ea5b5fa",
                "en_id": "eyJpdiI6IndqWmJWcEZzd0t2dHo4aTBDUCtmM2c9PSIsInZhbHVlIjoia2Q4UGl3dWsvSHZBQTZKUWF5Y2Fwdz09IiwibWFjIjoiOGRmYjk2NTE3MGU3ODg3OGRhMjFjMWRlNjIwOWU0NDI5Y2Q5Mzg4MDUzYjcwMTA0NzgwNmM1NzRlYjA0ZmZjZSIsInRhZyI6IiJ9"
            },
            "questions": [
                {
                    "id": 114448,
                    "exam_id": 1,
                    "question_paper_id": 366,
                    "question_number": 100,
                    "question_text_1": "THIS IS QUESTION PAPER FOR THE SUBJECT <b>\"DEGREE LEVEL : DEEP LEARNING PRACTICE </b><b>(COMPUTER BASED EXAM)\"</b><b> </b><b> </b><b>ARE YOU SURE YOU HAVE TO WRITE EXAM FOR THIS SUBJECT? </b><b>CROSS CHECK YOUR HALL TICKET TO CONFIRM THE SUBJECTS TO BE WRITTEN. </b><b> </b><b>(IF IT IS NOT THE CORRECT SUBJECT, PLS CHECK THE SECTION AT THE TOP FOR THE SUBJECTS </b><b>REGISTERED BY YOU)</b>",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "0.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-11-16T14:11:38.000000Z",
                    "updated_at": "2025-11-16T14:11:38.000000Z",
                    "question_num_long": 6406531534579,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "48a74a3ec0b46c309f1dc7e80b4665f4",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "0ad8a24d-132d-4566-bf19-f1c3605357b4",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "THIS IS QUESTION PAPER FOR THE SUBJECT <b>\"DEGREE LEVEL : DEEP LEARNING PRACTICE </b><b>(COMPUTER BASED EXAM)\"</b><b> </b><b> </b><b>ARE YOU SURE YOU HAVE TO WRITE EXAM FOR THIS SUBJECT? </b><b>CROSS CHECK YOUR HALL TICKET TO CONFIRM THE SUBJECTS TO BE WRITTEN. </b><b> </b><b>(IF IT IS NOT THE CORRECT SUBJECT, PLS CHECK THE SECTION AT THE TOP FOR THE SUBJECTS </b><b>REGISTERED BY YOU)</b>"
                    ],
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [
                        {
                            "id": 299441,
                            "question_id": 114448,
                            "option_text": "YES",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 1,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134634,
                            "option_image_url": null
                        },
                        {
                            "id": 299442,
                            "question_id": 114448,
                            "option_text": "NO",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134635,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 114449,
                    "exam_id": 1,
                    "question_paper_id": 366,
                    "question_number": 101,
                    "question_text_1": "Which of the following statements best describes the primary advantage of the SentencePiece tokenizer compared to a standard BPE implementation?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-11-16T14:11:38.000000Z",
                    "updated_at": "2025-11-16T14:11:38.000000Z",
                    "question_num_long": 6406531534580,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "db8e543fc476675717060a75b15bab64",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "a337fdc6-4994-439f-bcf0-b82f704bcd6d",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following statements best describes the primary advantage of the SentencePiece tokenizer compared to a standard BPE implementation?"
                    ],
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [
                        {
                            "id": 299443,
                            "question_id": 114449,
                            "option_text": "It is significantly faster to train because it does not need to count pairs.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134636,
                            "option_image_url": null
                        },
                        {
                            "id": 299444,
                            "question_id": 114449,
                            "option_text": "It results in a smaller vocabulary size by always merging the shortest tokensfirst.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134637,
                            "option_image_url": null
                        },
                        {
                            "id": 299445,
                            "question_id": 114449,
                            "option_text": "It is inherently language-agnostic, treating text as a raw stream of Unicodecharacters, which is ideal for languages without clear word delimiters like Japanese or Thai.",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134638,
                            "option_image_url": null
                        },
                        {
                            "id": 299446,
                            "question_id": 114449,
                            "option_text": "It is deterministic and always produces the same tokenization for a givenstring,unlike BPE which can be probabilistic.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134639,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 114450,
                    "exam_id": 1,
                    "question_paper_id": 366,
                    "question_number": 102,
                    "question_text_1": "When performing full fine-tuning of a large language model (e.g., 10B parameters) using Adam, which component consumes the most GPU memory?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-11-16T14:11:38.000000Z",
                    "updated_at": "2025-11-16T14:11:38.000000Z",
                    "question_num_long": 6406531534581,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "57d80e81bfbd06fdcbaac49166abe252",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "48f95759-eb91-4758-9d70-23a2a7279389",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "When performing full fine-tuning of a large language model (e.g., 10B parameters) using Adam, which component consumes the most GPU memory?"
                    ],
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [
                        {
                            "id": 299447,
                            "question_id": 114450,
                            "option_text": "The model\u2019s weights (parameters).",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134640,
                            "option_image_url": null
                        },
                        {
                            "id": 299448,
                            "question_id": 114450,
                            "option_text": "The gradients calculated for each parameter.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134641,
                            "option_image_url": null
                        },
                        {
                            "id": 299449,
                            "question_id": 114450,
                            "option_text": "The optimizer states (e.g., momentum and variance).",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134642,
                            "option_image_url": null
                        },
                        {
                            "id": 299450,
                            "question_id": 114450,
                            "option_text": "The vocabulary and embedding matrix.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134643,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 114451,
                    "exam_id": 1,
                    "question_paper_id": 366,
                    "question_number": 103,
                    "question_text_1": "A company wants to align its chatbot with values of being helpful, harmless, and honest. Human labelers provide ideal responses and rank AI-generated outputs. Which adaptation technique is designed for this?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-11-16T14:11:38.000000Z",
                    "updated_at": "2025-11-16T14:11:38.000000Z",
                    "question_num_long": 6406531534582,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "5c63779f8fd9735ae3deaaf610ee1e24",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "64ac801e-483d-4ce6-aae1-5fd1e0162989",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "A company wants to align its chatbot with values of being helpful, harmless, and honest. Human labelers provide ideal responses and rank AI-generated outputs. Which adaptation technique is designed for this?"
                    ],
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [
                        {
                            "id": 299451,
                            "question_id": 114451,
                            "option_text": "Instruction Tuning",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134644,
                            "option_image_url": null
                        },
                        {
                            "id": 299452,
                            "question_id": 114451,
                            "option_text": "Zero-shot prompting",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134645,
                            "option_image_url": null
                        },
                        {
                            "id": 299453,
                            "question_id": 114451,
                            "option_text": "Reinforcement Learning from Human Feedback (RLHF)",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134646,
                            "option_image_url": null
                        },
                        {
                            "id": 299454,
                            "question_id": 114451,
                            "option_text": "Continued pre-training",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134647,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 114452,
                    "exam_id": 1,
                    "question_paper_id": 366,
                    "question_number": 104,
                    "question_text_1": null,
                    "question_image_1": "ktPWct7w93lqbRSYsG0pmuvA0qJume0gdIJtbRGZ3zGvWnvqV2.png",
                    "question_type": "MCQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-11-16T14:11:38.000000Z",
                    "updated_at": "2025-11-16T14:11:38.000000Z",
                    "question_num_long": 6406531534583,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "467473a09d5907cb40f696ad1b8d6c97",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "d8c7f496-1ea1-40f9-b183-35a239d3e278",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/ktPWct7w93lqbRSYsG0pmuvA0qJume0gdIJtbRGZ3zGvWnvqV2.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [
                        {
                            "id": 299455,
                            "question_id": 114452,
                            "option_text": "",
                            "option_image": "kWCYp92KoEo7cMPWnLq4potbll3cbLst2JTNZrLGpwNDfMDeE6.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134648,
                            "option_image_url": "app/option_images/kWCYp92KoEo7cMPWnLq4potbll3cbLst2JTNZrLGpwNDfMDeE6.png"
                        },
                        {
                            "id": 299456,
                            "question_id": 114452,
                            "option_text": "",
                            "option_image": "8t6advANpFZvKbhuAHkuYBgp6mdDTC7MtZVYUktfKhaInJgSsO.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134649,
                            "option_image_url": "app/option_images/8t6advANpFZvKbhuAHkuYBgp6mdDTC7MtZVYUktfKhaInJgSsO.png"
                        },
                        {
                            "id": 299457,
                            "question_id": 114452,
                            "option_text": "",
                            "option_image": "t74yOOzNg6jWaewXQDMPEu9QiHkXRiojpBph9K7fDm99w1jZa0.png",
                            "score": "3.000",
                            "is_correct": 1,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134650,
                            "option_image_url": "app/option_images/t74yOOzNg6jWaewXQDMPEu9QiHkXRiojpBph9K7fDm99w1jZa0.png"
                        },
                        {
                            "id": 299458,
                            "question_id": 114452,
                            "option_text": "",
                            "option_image": "8SFMUtNU9byQ7M3WHR4FeGGLz4SSGoXnfMdME7hXhKxMOINol1.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134651,
                            "option_image_url": "app/option_images/8SFMUtNU9byQ7M3WHR4FeGGLz4SSGoXnfMdME7hXhKxMOINol1.png"
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 114453,
                    "exam_id": 1,
                    "question_paper_id": 366,
                    "question_number": 105,
                    "question_text_1": null,
                    "question_image_1": "ATbYhycERCmQFFWM3h9RYGuoTK1qaOlqXVmhZWrAUkQkN06gzq.png",
                    "question_type": "MCQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-11-16T14:11:38.000000Z",
                    "updated_at": "2025-11-16T14:11:38.000000Z",
                    "question_num_long": 6406531534584,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "e91de155cd85f3fa955e38e083e05596",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "dac225bb-5ed7-4f67-9555-5a963eb9efc5",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/ATbYhycERCmQFFWM3h9RYGuoTK1qaOlqXVmhZWrAUkQkN06gzq.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [
                        {
                            "id": 299459,
                            "question_id": 114453,
                            "option_text": "",
                            "option_image": "xLYJmn4gix2pFIrzeY4UUOfpIvV3agrBAT02FuUtDaiBNkMcHV.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134652,
                            "option_image_url": "app/option_images/xLYJmn4gix2pFIrzeY4UUOfpIvV3agrBAT02FuUtDaiBNkMcHV.png"
                        },
                        {
                            "id": 299460,
                            "question_id": 114453,
                            "option_text": "",
                            "option_image": "yj67lnZp6tfTmTp0CXLCeIDjnfXAmsybxIbW7o3f4Ld2Hn4wFM.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134653,
                            "option_image_url": "app/option_images/yj67lnZp6tfTmTp0CXLCeIDjnfXAmsybxIbW7o3f4Ld2Hn4wFM.png"
                        },
                        {
                            "id": 299461,
                            "question_id": 114453,
                            "option_text": "",
                            "option_image": "r4VckCUXFA979RJPlqDY30NvnCmsMkBNrYVKAIxqGpNLNWYOzt.png",
                            "score": "3.000",
                            "is_correct": 1,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134654,
                            "option_image_url": "app/option_images/r4VckCUXFA979RJPlqDY30NvnCmsMkBNrYVKAIxqGpNLNWYOzt.png"
                        },
                        {
                            "id": 299462,
                            "question_id": 114453,
                            "option_text": "",
                            "option_image": "Ld8XRqdjeMbMwRwbzWlXQ2Jq7Z8y0VaflYj3h6TsMHTizxYEHc.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134655,
                            "option_image_url": "app/option_images/Ld8XRqdjeMbMwRwbzWlXQ2Jq7Z8y0VaflYj3h6TsMHTizxYEHc.png"
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 114454,
                    "exam_id": 1,
                    "question_paper_id": 366,
                    "question_number": 106,
                    "question_text_1": "What is a key implication of using a Parameter-Efficient Fine-Tuning (PEFT) method like LoRA when adapting a large language model for a new task?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-11-16T14:11:38.000000Z",
                    "updated_at": "2025-11-16T14:11:38.000000Z",
                    "question_num_long": 6406531534585,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "3b8b119e91ee5db8b2bbe493be61414e",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "61b923b7-ad8e-4e6b-8fbf-b2dc9371f663",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "What is a key implication of using a Parameter-Efficient Fine-Tuning (PEFT) method like LoRA when adapting a large language model for a new task?"
                    ],
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [
                        {
                            "id": 299463,
                            "question_id": 114454,
                            "option_text": "Inference speed is 10x faster.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134656,
                            "option_image_url": null
                        },
                        {
                            "id": 299464,
                            "question_id": 114454,
                            "option_text": "Only a small number of new parameters are trained while freezing originalweights.",
                            "option_image": "",
                            "score": "3.000",
                            "is_correct": 1,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134657,
                            "option_image_url": null
                        },
                        {
                            "id": 299465,
                            "question_id": 114454,
                            "option_text": "It eliminates the need for labeled data.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134658,
                            "option_image_url": null
                        },
                        {
                            "id": 299466,
                            "question_id": 114454,
                            "option_text": "Model must be retrained from scratch.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134659,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 114455,
                    "exam_id": 1,
                    "question_paper_id": 366,
                    "question_number": 107,
                    "question_text_1": "The WordPiece tokenization algorithm, unlike BPE, does not merge the pair with the highest frequency. Instead, it merges the pair that maximizes a likelihood score. Which of the following statements accurately describes this score and its implication?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "4.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-11-16T14:11:38.000000Z",
                    "updated_at": "2025-11-16T14:11:38.000000Z",
                    "question_num_long": 6406531534586,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "72638261ad240fe5cf88114bc184a6e5",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "7d280755-fd56-4351-a951-763dc5c8c223",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "The WordPiece tokenization algorithm, unlike BPE, does not merge the pair with the highest frequency. Instead, it merges the pair that maximizes a likelihood score. Which of the following statements accurately describes this score and its implication?"
                    ],
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [
                        {
                            "id": 299467,
                            "question_id": 114455,
                            "option_text": "",
                            "option_image": "DQ3BeXq2BapgmGuuWXir3nLv6H5lphuKGrLuoY2h4dOUlQf7Hn.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134660,
                            "option_image_url": "app/option_images/DQ3BeXq2BapgmGuuWXir3nLv6H5lphuKGrLuoY2h4dOUlQf7Hn.png"
                        },
                        {
                            "id": 299468,
                            "question_id": 114455,
                            "option_text": "",
                            "option_image": "kZHPUEp9WrfydsauXgj8v36LZ2ZqA20ChszKUw31Jmx7dCFrzj.png",
                            "score": "4.000",
                            "is_correct": 1,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134661,
                            "option_image_url": "app/option_images/kZHPUEp9WrfydsauXgj8v36LZ2ZqA20ChszKUw31Jmx7dCFrzj.png"
                        },
                        {
                            "id": 299469,
                            "question_id": 114455,
                            "option_text": "",
                            "option_image": "EAc0QkiFXWOiL7pJtg8l0uVO3iUVEPOby8TLPyU8dzN2WnDVEr.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134662,
                            "option_image_url": "app/option_images/EAc0QkiFXWOiL7pJtg8l0uVO3iUVEPOby8TLPyU8dzN2WnDVEr.png"
                        },
                        {
                            "id": 299470,
                            "question_id": 114455,
                            "option_text": "",
                            "option_image": "JnczhygKfwY5tPaBBocRPKTx6vNGGkO4rySsKAA4XCT6s5E3J4.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134663,
                            "option_image_url": "app/option_images/JnczhygKfwY5tPaBBocRPKTx6vNGGkO4rySsKAA4XCT6s5E3J4.png"
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 114456,
                    "exam_id": 1,
                    "question_paper_id": 366,
                    "question_number": 108,
                    "question_text_1": "Which of the following statements accurately describes the Causal Language Modeling (CLM) objective used to pre-train models like GPT? (Select ALL that apply)",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "4.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-11-16T14:11:38.000000Z",
                    "updated_at": "2025-11-16T14:11:38.000000Z",
                    "question_num_long": 6406531534587,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "750353822a71fbef86ca2c519fe302b1",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "596a0deb-b603-4ffa-8abf-35d029656585",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following statements accurately describes the Causal Language Modeling (CLM) objective used to pre-train models like GPT? (Select ALL that apply)"
                    ],
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [
                        {
                            "id": 299471,
                            "question_id": 114456,
                            "option_text": "Predicting randomly masked tokens.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134664,
                            "option_image_url": null
                        },
                        {
                            "id": 299472,
                            "question_id": 114456,
                            "option_text": "Auto-regressive next-token prediction.",
                            "option_image": "",
                            "score": "1.333",
                            "is_correct": 1,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134665,
                            "option_image_url": null
                        },
                        {
                            "id": 299473,
                            "question_id": 114456,
                            "option_text": "Requires causal attention mask.",
                            "option_image": "",
                            "score": "1.333",
                            "is_correct": 1,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134666,
                            "option_image_url": null
                        },
                        {
                            "id": 299474,
                            "question_id": 114456,
                            "option_text": "Suited for encoder-only models.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134667,
                            "option_image_url": null
                        },
                        {
                            "id": 299475,
                            "question_id": 114456,
                            "option_text": "Maximizes joint probability of sequence.",
                            "option_image": "",
                            "score": "1.333",
                            "is_correct": 1,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134668,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 114457,
                    "exam_id": 1,
                    "question_paper_id": 366,
                    "question_number": 109,
                    "question_text_1": "A research lab has access to a powerful 175B parameter language model. They need to adapt it for a highly specialized legal text analysis task, but they only have about 500 labeled examples and limited access to high-end GPUs for fine-tuning. Which of the following are viable and computationally efficient adaptation strategies? (Select ALL that apply)",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "4.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-11-16T14:11:38.000000Z",
                    "updated_at": "2025-11-16T14:11:38.000000Z",
                    "question_num_long": 6406531534588,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "0b75b9d570bced2f6c9959b2431ed354",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "c2e2765f-bcf9-491d-b8ff-8780729617a0",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "A research lab has access to a powerful 175B parameter language model. They need to adapt it for a highly specialized legal text analysis task, but they only have about 500 labeled examples and limited access to high-end GPUs for fine-tuning. Which of the following are viable and computationally efficient adaptation strategies? (Select ALL that apply)"
                    ],
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [
                        {
                            "id": 299476,
                            "question_id": 114457,
                            "option_text": "Full fine-tuning",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134669,
                            "option_image_url": null
                        },
                        {
                            "id": 299477,
                            "question_id": 114457,
                            "option_text": "Zero-shot prompting",
                            "option_image": "",
                            "score": "1.333",
                            "is_correct": 1,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134670,
                            "option_image_url": null
                        },
                        {
                            "id": 299478,
                            "question_id": 114457,
                            "option_text": "Few-shot in-context learning",
                            "option_image": "",
                            "score": "1.333",
                            "is_correct": 1,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134671,
                            "option_image_url": null
                        },
                        {
                            "id": 299479,
                            "question_id": 114457,
                            "option_text": "LoRA (PEFT)",
                            "option_image": "",
                            "score": "1.333",
                            "is_correct": 1,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134672,
                            "option_image_url": null
                        },
                        {
                            "id": 299480,
                            "question_id": 114457,
                            "option_text": "Pre-training from scratch",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134673,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 114458,
                    "exam_id": 1,
                    "question_paper_id": 366,
                    "question_number": 110,
                    "question_text_1": "A team is fine-tuning a 7B parameter model on a single GPU with 24GB of memory. They are using the Adam optimizer (which stores 2 states per parameter) and 32-bit precision (4 bytes per parameter/ state/gradient). They find that they run out of memory even with a batch size of 1. Which of the following strategies could help them complete the fine-tuning process on this GPU? (Select ALL that apply)",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "4.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-11-16T14:11:38.000000Z",
                    "updated_at": "2025-11-16T14:11:38.000000Z",
                    "question_num_long": 6406531534589,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "63281ec86367c5cc1fede37ac394eb20",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "b30345ed-2d23-4d0d-920a-6dbcecab7be6",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "A team is fine-tuning a 7B parameter model on a single GPU with 24GB of memory. They are using the Adam optimizer (which stores 2 states per parameter) and 32-bit precision (4 bytes per parameter/ state/gradient). They find that they run out of memory even with a batch size of 1. Which of the following strategies could help them complete the fine-tuning process on this GPU? (Select ALL that apply)"
                    ],
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [
                        {
                            "id": 299481,
                            "question_id": 114458,
                            "option_text": "Increase learning rate",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134674,
                            "option_image_url": null
                        },
                        {
                            "id": 299482,
                            "question_id": 114458,
                            "option_text": "Use LoRA",
                            "option_image": "",
                            "score": "1.333",
                            "is_correct": 1,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134675,
                            "option_image_url": null
                        },
                        {
                            "id": 299483,
                            "question_id": 114458,
                            "option_text": "Use quantization (8/4-bit)",
                            "option_image": "",
                            "score": "1.333",
                            "is_correct": 1,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134676,
                            "option_image_url": null
                        },
                        {
                            "id": 299484,
                            "question_id": 114458,
                            "option_text": "Switch to SGD",
                            "option_image": "",
                            "score": "1.333",
                            "is_correct": 1,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134677,
                            "option_image_url": null
                        },
                        {
                            "id": 299485,
                            "question_id": 114458,
                            "option_text": "Gradient accumulation",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134678,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 114459,
                    "exam_id": 1,
                    "question_paper_id": 366,
                    "question_number": 111,
                    "question_text_1": "The evolution of NLP models shows a distinct shift from task-specific architectures to a \u201dpre-train, finetune\u201d paradigm, and now towards large-scale, general-purpose models. Which of the following accurately represents this evolution and the capabilities at each stage? (Select ALL that apply)",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "4.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-11-16T14:11:38.000000Z",
                    "updated_at": "2025-11-16T14:11:38.000000Z",
                    "question_num_long": 6406531534590,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "f5ce62b9ddcfc9c59fcd45eb85e164f5",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "fd37942f-c316-4d2d-947c-b80a2ef6515e",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "The evolution of NLP models shows a distinct shift from task-specific architectures to a \u201dpre-train, finetune\u201d paradigm, and now towards large-scale, general-purpose models. Which of the following accurately represents this evolution and the capabilities at each stage? (Select ALL that apply)"
                    ],
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [
                        {
                            "id": 299486,
                            "question_id": 114459,
                            "option_text": "The earliest models (e.g., n-grams) were statistical, required task-specificdesign, and had limited generalization capacity.",
                            "option_image": "",
                            "score": "1.333",
                            "is_correct": 1,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134679,
                            "option_image_url": null
                        },
                        {
                            "id": 299487,
                            "question_id": 114459,
                            "option_text": "The \u201dpre-train, fine-tune\u201d era (e.g., BERT, GPT) introduced transfer learning,where a model was first trained on a general language task and then fully adapted to a specific downstream task.",
                            "option_image": "",
                            "score": "1.333",
                            "is_correct": 1,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134680,
                            "option_image_url": null
                        },
                        {
                            "id": 299488,
                            "question_id": 114459,
                            "option_text": "Modern Large Language Models (LLMs like GPT-4) exhibit \u201demerging abilities,\u201dallowing them to perform new tasks with zero or few examples (in-context learning) without any weight updates.",
                            "option_image": "",
                            "score": "1.333",
                            "is_correct": 1,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134681,
                            "option_image_url": null
                        },
                        {
                            "id": 299489,
                            "question_id": 114459,
                            "option_text": "Word2vec was a complete language model capable of generating text, similarto GPT.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134682,
                            "option_image_url": null
                        },
                        {
                            "id": 299490,
                            "question_id": 114459,
                            "option_text": "The primary innovation of transformers over RNNs was the use of recurrentconnections, which made them more efficient to train on parallel hardware.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134683,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 114460,
                    "exam_id": 1,
                    "question_paper_id": 366,
                    "question_number": 112,
                    "question_text_1": "The three main families of Transformer-based models are Encoder-only (e.g., BERT), Decoder-only (e.g.,GPT), and Encoder-Decoder (e.g., T5, BART). Match the architecture to its most suitable pre-training objective and typical use case. (Select ALL that apply)",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "4.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2025-11-16T14:11:38.000000Z",
                    "updated_at": "2025-11-16T14:11:38.000000Z",
                    "question_num_long": 6406531534591,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "4a3bd774ed1973d9e2dabeab2192e998",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "16e6e15e-f5a5-46fb-b036-391885b0ed02",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "The three main families of Transformer-based models are Encoder-only (e.g., BERT), Decoder-only (e.g.,GPT), and Encoder-Decoder (e.g., T5, BART). Match the architecture to its most suitable pre-training objective and typical use case. (Select ALL that apply)"
                    ],
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [
                        {
                            "id": 299491,
                            "question_id": 114460,
                            "option_text": "Encoder-only models are best for natural language understanding tasks (likesentiment classification) and are often pre-trained with a Masked Language Modeling (MLM) objective.",
                            "option_image": "",
                            "score": "1.333",
                            "is_correct": 1,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134684,
                            "option_image_url": null
                        },
                        {
                            "id": 299492,
                            "question_id": 114460,
                            "option_text": "Decoder-only models are ideal for text generation tasks and are pre-trainedwith a Causal Language Modeling (CLM) objective.",
                            "option_image": "",
                            "score": "1.333",
                            "is_correct": 1,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134685,
                            "option_image_url": null
                        },
                        {
                            "id": 299493,
                            "question_id": 114460,
                            "option_text": "Encoder-Decoder models are most suitable for sequence-to-sequence taskslike translation or summarization.",
                            "option_image": "",
                            "score": "1.333",
                            "is_correct": 1,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134686,
                            "option_image_url": null
                        },
                        {
                            "id": 299494,
                            "question_id": 114460,
                            "option_text": "All three architectures are pre-trained using the same Causal LanguageModeling objective.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2025-11-16T14:11:38.000000Z",
                            "updated_at": "2025-11-16T14:11:38.000000Z",
                            "option_number": 6406535134687,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 114461,
                    "exam_id": 1,
                    "question_paper_id": 366,
                    "question_number": 113,
                    "question_text_1": null,
                    "question_image_1": "mNutCORRo3Ur58PyoXEbYY8Iaj72pkusNU2qTjczAqdWQz97GK.png",
                    "question_type": "SA",
                    "total_mark": "3.00",
                    "value_start": "4.8",
                    "value_end": null,
                    "created_at": "2025-11-16T14:11:38.000000Z",
                    "updated_at": "2025-11-16T14:11:38.000000Z",
                    "question_num_long": 6406531534592,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "df058a8525db68421071348abf77453e",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "e3a6d335-4549-430b-8709-0ecadcf9128e",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/mNutCORRo3Ur58PyoXEbYY8Iaj72pkusNU2qTjczAqdWQz97GK.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 114462,
                    "exam_id": 1,
                    "question_paper_id": 366,
                    "question_number": 114,
                    "question_text_1": "A single transformer block in a GPT-style model has the following configuration: embedding dimension (d model) = 1024, num attention heads = 16. Each attention head has a dimension of d model /num attention heads. Calculate the total number of parameters (weights and biases) for the self attention mechanism (specifically the Q, K, V, and Output projection layers) within this single block. Report the answer in millions, rounded to one decimal place.(in M)",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "4.2",
                    "value_end": null,
                    "created_at": "2025-11-16T14:11:38.000000Z",
                    "updated_at": "2025-11-16T14:11:38.000000Z",
                    "question_num_long": 6406531534593,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "21557725c5d691071ebe27a429a15fb6",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "33a31b4d-094a-4282-8fc2-c084e4ff5533",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "A single transformer block in a GPT-style model has the following configuration: embedding dimension (d model) = 1024, num attention heads = 16. Each attention head has a dimension of d model /num attention heads. Calculate the total number of parameters (weights and biases) for the self attention mechanism (specifically the Q, K, V, and Output projection layers) within this single block. Report the answer in millions, rounded to one decimal place.(in M)"
                    ],
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [],
                    "parent_question": null
                },
                {
                    "id": 114463,
                    "exam_id": 1,
                    "question_paper_id": 366,
                    "question_number": 115,
                    "question_text_1": "You are given a GPT-style model with a vocabulary size of 50,257, a context length of 1024, and an embedding dimension of 768. The model learns its positional embeddings rather than using fixed sinusoidal ones. Calculate the total number of parameters in the model\u2019s embedding layer, which includes both token embeddings and positional embeddings. Report your answer in millions, rounded to one decimal place.(in M)",
                    "question_image_1": null,
                    "question_type": "SA",
                    "total_mark": "4.00",
                    "value_start": "39.4",
                    "value_end": null,
                    "created_at": "2025-11-16T14:11:38.000000Z",
                    "updated_at": "2025-11-16T14:11:38.000000Z",
                    "question_num_long": 6406531534594,
                    "answer_type": "Equal",
                    "response_type": "Numeric",
                    "have_answers": 0,
                    "hash": "d137f8088015decbcd2dc7345ab3065e",
                    "course_id": 86,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "436c0aa3-5aa1-4961-9ffb-4b2ac6899154",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "You are given a GPT-style model with a vocabulary size of 50,257, a context length of 1024, and an embedding dimension of 768. The model learns its positional embeddings rather than using fixed sinusoidal ones. Calculate the total number of parameters in the model\u2019s embedding layer, which includes both token embeddings and positional embeddings. Report your answer in millions, rounded to one decimal place.(in M)"
                    ],
                    "course": {
                        "id": 86,
                        "course_name": "DLP",
                        "course_code": "DLP",
                        "created_at": "2024-10-29T12:29:17.000000Z",
                        "updated_at": "2024-10-29T12:29:17.000000Z",
                        "program_id": 1,
                        "uuid": "2be604f9-22b9-489c-a7c5-fc4a8ce37d9d"
                    },
                    "options": [],
                    "parent_question": null
                }
            ]
        },
        "summary": "",
        "total_score": "50.00"
    },
    "url": "/question-paper/practise/86/e45173cc-382",
    "version": "ee3d5d44299e610bd137ea6200db5ac2"
}