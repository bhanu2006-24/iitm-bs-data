{
    "component": "Quizpractise/PractiseQuestionPaper",
    "props": {
        "errors": {},
        "auth": {
            "user": null
        },
        "flash": {
            "error": []
        },
        "banner": null,
        "file_url": "https://saram.blr1.cdn.digitaloceanspaces.com",
        "file_do_url": "https://saram.blr1.cdn.digitaloceanspaces.com",
        "question_paper": {
            "id": 142,
            "group_id": 20,
            "exam_id": 2,
            "total_score": "1.00",
            "duration": 4,
            "created_at": "2024-11-26T13:58:46.000000Z",
            "updated_at": "2024-11-26T13:58:46.000000Z",
            "question_paper_name": "IIT M DEGREE AN3 EXAM QPE3 02 Apr 2023",
            "question_paper_description": "2023 Apr2: IIT M DEGREE AN3 EXAM QPE3",
            "uuid": "b55a6202-f31",
            "year": 2023,
            "is_new": 0,
            "exam": {
                "id": 2,
                "exam_name": "Quiz 2",
                "created_at": "2024-10-16T08:08:51.000000Z",
                "updated_at": "2024-10-16T08:08:51.000000Z",
                "uuid": "1948ee72-5c62-4816-97c8-7d662330a220",
                "en_id": "eyJpdiI6Im85aGF0M05GUFVjUXdkUkJha0E3Q2c9PSIsInZhbHVlIjoibkxMaDB2Vlk5ejdsMVBNekI5NHNJdz09IiwibWFjIjoiZjBmNWU0ODA0MTgzYzY3ZDQ4NzM5ZjNhYzRkZTRiYzQzMWJlZjM5MDA5M2YzMTY0YmU5MTlhODQ3MmZlNTAwYyIsInRhZyI6IiJ9"
            },
            "questions": [
                {
                    "id": 41325,
                    "exam_id": 2,
                    "question_paper_id": 142,
                    "question_number": 255,
                    "question_text_1": "THIS IS QUESTION PAPER FOR THE SUBJECT \"DEGREE LEVEL : INTRODUCTION TO BIG DATA\"  ARE YOU SURE YOU HAVE TO WRITE EXAM FOR THIS SUBJECT? CROSS CHECK YOUR HALL TICKET TO CONFIRM THE SUBJECTS TO BE WRITTEN.  (IF IT IS NOT THE CORRECT SUBJECT, PLS CHECK THE SECTION AT THE TOP FOR THE SUBJECTS REGISTERED BY YOU)",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "0.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-26T13:58:48.000000Z",
                    "updated_at": "2024-11-26T13:58:48.000000Z",
                    "question_num_long": 640653522399,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "177c5a3b93aa4f24e189762aad24b8e2",
                    "course_id": 44,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "cba48e2b-54ae-40df-9d25-827a62d76120",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "THIS IS QUESTION PAPER FOR THE SUBJECT \"DEGREE LEVEL : INTRODUCTION TO BIG DATA\"  ARE YOU SURE YOU HAVE TO WRITE EXAM FOR THIS SUBJECT? CROSS CHECK YOUR HALL TICKET TO CONFIRM THE SUBJECTS TO BE WRITTEN.  (IF IT IS NOT THE CORRECT SUBJECT, PLS CHECK THE SECTION AT THE TOP FOR THE SUBJECTS REGISTERED BY YOU)"
                    ],
                    "course": {
                        "id": 44,
                        "course_name": "Intro to BigData",
                        "course_code": "Intro to BigData",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "0a6ea890-ca63-49c6-a7b3-cc71e4a81ada"
                    },
                    "options": [
                        {
                            "id": 111307,
                            "question_id": 41325,
                            "option_text": "YES",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 1,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740951,
                            "option_image_url": null
                        },
                        {
                            "id": 111308,
                            "question_id": 41325,
                            "option_text": "NO",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740952,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 41326,
                    "exam_id": 2,
                    "question_paper_id": 142,
                    "question_number": 256,
                    "question_text_1": "What best describes \"big data\"?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-26T13:58:48.000000Z",
                    "updated_at": "2024-11-26T13:58:48.000000Z",
                    "question_num_long": 640653522400,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "f7ed8a2f5aac2960db6fe98854d30b3d",
                    "course_id": 44,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "7a0d9471-431a-4af0-92b2-60d7ec16d7cc",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "What best describes \"big data\"?"
                    ],
                    "course": {
                        "id": 44,
                        "course_name": "Intro to BigData",
                        "course_code": "Intro to BigData",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "0a6ea890-ca63-49c6-a7b3-cc71e4a81ada"
                    },
                    "options": [
                        {
                            "id": 111309,
                            "question_id": 41326,
                            "option_text": "Big data is used to refer to the set of technologies built around Hadoop",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740953,
                            "option_image_url": null
                        },
                        {
                            "id": 111310,
                            "question_id": 41326,
                            "option_text": "Big data refers to the cloud-native design principle",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740954,
                            "option_image_url": null
                        },
                        {
                            "id": 111311,
                            "question_id": 41326,
                            "option_text": "Big data is about All data, Any Time, Any Method",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740955,
                            "option_image_url": null
                        },
                        {
                            "id": 111312,
                            "question_id": 41326,
                            "option_text": "Big data is about volume, velocity, variety",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740956,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 41327,
                    "exam_id": 2,
                    "question_paper_id": 142,
                    "question_number": 257,
                    "question_text_1": "Which of these represent examples of divide-and-conquer?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-26T13:58:48.000000Z",
                    "updated_at": "2024-11-26T13:58:48.000000Z",
                    "question_num_long": 640653522401,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "21a9fd835738a7dd371b119c8e00098a",
                    "course_id": 44,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "536f082d-7857-4890-845a-7bcc93c8938b",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of these represent examples of divide-and-conquer?"
                    ],
                    "course": {
                        "id": 44,
                        "course_name": "Intro to BigData",
                        "course_code": "Intro to BigData",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "0a6ea890-ca63-49c6-a7b3-cc71e4a81ada"
                    },
                    "options": [
                        {
                            "id": 111313,
                            "question_id": 41327,
                            "option_text": "Spark and MapReduce",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740957,
                            "option_image_url": null
                        },
                        {
                            "id": 111314,
                            "question_id": 41327,
                            "option_text": "Map and Reduce",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740958,
                            "option_image_url": null
                        },
                        {
                            "id": 111315,
                            "question_id": 41327,
                            "option_text": "Hadoop and Spark",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740959,
                            "option_image_url": null
                        },
                        {
                            "id": 111316,
                            "question_id": 41327,
                            "option_text": "MapReduce and Hadoop",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740960,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 41328,
                    "exam_id": 2,
                    "question_paper_id": 142,
                    "question_number": 258,
                    "question_text_1": "Which of the following statements about Spark application architecture is correct?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-26T13:58:48.000000Z",
                    "updated_at": "2024-11-26T13:58:48.000000Z",
                    "question_num_long": 640653522403,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "4651b52db5be1cb593ffe0c1b6376e4f",
                    "course_id": 44,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "71f4ace0-54f8-4023-b899-54064bdab19e",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following statements about Spark application architecture is correct?"
                    ],
                    "course": {
                        "id": 44,
                        "course_name": "Intro to BigData",
                        "course_code": "Intro to BigData",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "0a6ea890-ca63-49c6-a7b3-cc71e4a81ada"
                    },
                    "options": [
                        {
                            "id": 111317,
                            "question_id": 41328,
                            "option_text": "A Spark program generates a set of tasks that are grouped into stages, each ofwhich executes concurrently with the driver being responsible for collecting results from eachstage for final output.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740966,
                            "option_image_url": null
                        },
                        {
                            "id": 111318,
                            "question_id": 41328,
                            "option_text": "A Spark action generates a job, with each job being broken down into multiplestages where a stage is a set of tasks that can be executed in parallel and stages themselves areinterdependent, with each task being the unit of work mapped to an executor.",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740967,
                            "option_image_url": null
                        },
                        {
                            "id": 111319,
                            "question_id": 41328,
                            "option_text": "A Spark program generates a job, with each job being broken down intomultiple stages where a stage is a set of tasks that can be executed in parallel and stagesthemselves are interdependent, with each task being the unit of work mapped to an executor.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740968,
                            "option_image_url": null
                        },
                        {
                            "id": 111320,
                            "question_id": 41328,
                            "option_text": "A Spark action generates a task that is further broken down into multiplestages where a stage is a set of jobs that can be executed in parallel and stages themselves areinterdependent, with each job being the unit of work mapped to an executor.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740969,
                            "option_image_url": null
                        },
                        {
                            "id": 111321,
                            "question_id": 41328,
                            "option_text": "A Spark program generates a task that is further broken down into multiplestages where a stage is a set of jobs that can be executed in parallel and stages themselves areinterdependent, with each job being the unit of work mapped to an executor.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740970,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 41329,
                    "exam_id": 2,
                    "question_paper_id": 142,
                    "question_number": 259,
                    "question_text_1": "Consider the problem of sorting a 1 petabyte file of numbers stored in a Hadoop cluster of 10 machines where the size of each HDFS block is 100MB. Which of the below methods is the most likely to finish soonest in practice?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-26T13:58:48.000000Z",
                    "updated_at": "2024-11-26T13:58:48.000000Z",
                    "question_num_long": 640653522404,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "630fb291132f2d5f91b3c3641d8ce2a4",
                    "course_id": 44,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "2a757ab2-458f-416e-8010-1f3f168c02fb",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Consider the problem of sorting a 1 petabyte file of numbers stored in a Hadoop cluster of 10 machines where the size of each HDFS block is 100MB. Which of the below methods is the most likely to finish soonest in practice?"
                    ],
                    "course": {
                        "id": 44,
                        "course_name": "Intro to BigData",
                        "course_code": "Intro to BigData",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "0a6ea890-ca63-49c6-a7b3-cc71e4a81ada"
                    },
                    "options": [
                        {
                            "id": 111322,
                            "question_id": 41329,
                            "option_text": "Use quicksort on each machine and then merge each machine's sorted data onthe master",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740971,
                            "option_image_url": null
                        },
                        {
                            "id": 111323,
                            "question_id": 41329,
                            "option_text": "Exploit duality of hashing vs sorting and write a hash function that assignseach line in the file to a distinct machine, and then sort within each machine",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740972,
                            "option_image_url": null
                        },
                        {
                            "id": 111324,
                            "question_id": 41329,
                            "option_text": "Write a general-purpose MapReduce / Spark program that picks the Nthhighest descending value from a set, invoke it iteratively from 1 to S (S=Number of lines in file),and create a new file of sorted data",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740973,
                            "option_image_url": null
                        },
                        {
                            "id": 111325,
                            "question_id": 41329,
                            "option_text": "Mergesort on each machine by limiting use of memory, and then between allpossible pairs of machines",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740974,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 41330,
                    "exam_id": 2,
                    "question_paper_id": 142,
                    "question_number": 260,
                    "question_text_1": "A website sees 1 Billion hits every month. The website owner wants to count average hits per customer in the latest month, where a customer is denoted by the IP address of the device. The owner has at his disposal a Hadoop cluster of 5 workers and 2 masters each with 1GB of RAM. Which of the following methods is the most likely to finish fastest?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-26T13:58:48.000000Z",
                    "updated_at": "2024-11-26T13:58:48.000000Z",
                    "question_num_long": 640653522405,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "8e212ce9051737dbd7f757e78d4123f0",
                    "course_id": 44,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "2b7a0ff2-7959-483c-8bf8-c57bf4dc997f",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "A website sees 1 Billion hits every month. The website owner wants to count average hits per customer in the latest month, where a customer is denoted by the IP address of the device. The owner has at his disposal a Hadoop cluster of 5 workers and 2 masters each with 1GB of RAM. Which of the following methods is the most likely to finish fastest?"
                    ],
                    "course": {
                        "id": 44,
                        "course_name": "Intro to BigData",
                        "course_code": "Intro to BigData",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "0a6ea890-ca63-49c6-a7b3-cc71e4a81ada"
                    },
                    "options": [
                        {
                            "id": 111326,
                            "question_id": 41330,
                            "option_text": "Write a Spark program that forms a Dataframe as grouping by IP address withcount as aggregate, followed by another stage that computes the avg on top of the Dataframe ofthe first stage",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740975,
                            "option_image_url": null
                        },
                        {
                            "id": 111327,
                            "question_id": 41330,
                            "option_text": "Write a MapReduce program where the Map does nothing useful, Combinecomputes the aggregated hits per customer, Shuffle combined data based on IP address acrossworkers, and in the Reduce, build hash table on each machine with hash key = IP address andhash value = counter, followed by another Reduce that finally computes the avg on top of all hashvalues.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740976,
                            "option_image_url": null
                        },
                        {
                            "id": 111328,
                            "question_id": 41330,
                            "option_text": "Write a Spark program that forms a Dataframe as grouping by IP address withcount as aggregate, followed by a take into a list in the Spark driver which further computes theaverage of all the individual counts in the list",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740977,
                            "option_image_url": null
                        },
                        {
                            "id": 111329,
                            "question_id": 41330,
                            "option_text": "Write a MapReduce program where the Map does nothing useful, Shuffle databased on IP address across workers, and in the Reduce, build hash table on each machine withhash key = IP address and hash value = counter, followed by another Reduce that finally computesavg on top of all hash values.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740978,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 41331,
                    "exam_id": 2,
                    "question_paper_id": 142,
                    "question_number": 261,
                    "question_text_1": "An enterprise software designer wants to leverage the best of cloud to minimize the number of administrative overheads associated with her big data pipeline while also getting on-demand scalability without sacrificing flexibility. What option should she choose to best serve these needs?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-26T13:58:48.000000Z",
                    "updated_at": "2024-11-26T13:58:48.000000Z",
                    "question_num_long": 640653522406,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "dda14c50ed3e40429595d766caf426fc",
                    "course_id": 44,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "0bb55889-bd0f-4e7e-9276-60d8a76185ac",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "An enterprise software designer wants to leverage the best of cloud to minimize the number of administrative overheads associated with her big data pipeline while also getting on-demand scalability without sacrificing flexibility. What option should she choose to best serve these needs?"
                    ],
                    "course": {
                        "id": 44,
                        "course_name": "Intro to BigData",
                        "course_code": "Intro to BigData",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "0a6ea890-ca63-49c6-a7b3-cc71e4a81ada"
                    },
                    "options": [
                        {
                            "id": 111330,
                            "question_id": 41331,
                            "option_text": "Build the data pipeline using Spark, data storage on HDFS, and deploy both onHadoop using IaaS",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740979,
                            "option_image_url": null
                        },
                        {
                            "id": 111331,
                            "question_id": 41331,
                            "option_text": "Build the data pipeline using Python run on Serverless where the data is storedon cloud storage",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740980,
                            "option_image_url": null
                        },
                        {
                            "id": 111332,
                            "question_id": 41331,
                            "option_text": "Build the data pipeline using Spark PaaS option on top of data stored on cloudstorage",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740981,
                            "option_image_url": null
                        },
                        {
                            "id": 111333,
                            "question_id": 41331,
                            "option_text": "Build the data pipeline using MapReduce, data storage on HDFS, and deployboth on Hadoop using IaaS",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740982,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 41332,
                    "exam_id": 2,
                    "question_paper_id": 142,
                    "question_number": 262,
                    "question_text_1": "Consider an application that can scale from handling 1000 users to handling 100 million users by simply making copies of itself, is able to seamlessly react to machines going offline by again making new copies of itself in new machines, and otherwise leaves behind no trace of its workings. Which of the following statements is true?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-26T13:58:48.000000Z",
                    "updated_at": "2024-11-26T13:58:48.000000Z",
                    "question_num_long": 640653522407,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "d7573e76d3468baeae5596caf1f7eadc",
                    "course_id": 44,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "61ad5cec-3f6b-4b21-8a34-0ca8630c5d0b",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Consider an application that can scale from handling 1000 users to handling 100 million users by simply making copies of itself, is able to seamlessly react to machines going offline by again making new copies of itself in new machines, and otherwise leaves behind no trace of its workings. Which of the following statements is true?"
                    ],
                    "course": {
                        "id": 44,
                        "course_name": "Intro to BigData",
                        "course_code": "Intro to BigData",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "0a6ea890-ca63-49c6-a7b3-cc71e4a81ada"
                    },
                    "options": [
                        {
                            "id": 111334,
                            "question_id": 41332,
                            "option_text": "This application has adopted cloud-native design",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740983,
                            "option_image_url": null
                        },
                        {
                            "id": 111335,
                            "question_id": 41332,
                            "option_text": "This application cannot be called as cloud-native since it is not observable at alltimes",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740984,
                            "option_image_url": null
                        },
                        {
                            "id": 111336,
                            "question_id": 41332,
                            "option_text": "This application cannot be called as cloud-native since it is not manageableeasily",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740985,
                            "option_image_url": null
                        },
                        {
                            "id": 111337,
                            "question_id": 41332,
                            "option_text": "This application cannot be called as cloud-native since it is not resilient",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740986,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 41333,
                    "exam_id": 2,
                    "question_paper_id": 142,
                    "question_number": 263,
                    "question_text_1": "Linux is an example of an operating system. Which of the following is considered as the \"operating system of a cluster of machines\" and why?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-26T13:58:48.000000Z",
                    "updated_at": "2024-11-26T13:58:48.000000Z",
                    "question_num_long": 640653522409,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "845824e9cee42ba8077fc9bffbdc479e",
                    "course_id": 44,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "ed5dbb43-249d-4397-abd8-dabea66396e4",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Linux is an example of an operating system. Which of the following is considered as the \"operating system of a cluster of machines\" and why?"
                    ],
                    "course": {
                        "id": 44,
                        "course_name": "Intro to BigData",
                        "course_code": "Intro to BigData",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "0a6ea890-ca63-49c6-a7b3-cc71e4a81ada"
                    },
                    "options": [
                        {
                            "id": 111338,
                            "question_id": 41333,
                            "option_text": "Hive, because it executes SQL queries without users having to worry aboutmemory and disk, much like Linux",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740992,
                            "option_image_url": null
                        },
                        {
                            "id": 111339,
                            "question_id": 41333,
                            "option_text": "Spark, because it executes Python jobs without users having to worry aboutmemory and disk, much like Linux",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740993,
                            "option_image_url": null
                        },
                        {
                            "id": 111340,
                            "question_id": 41333,
                            "option_text": "Zookeeper, because it ensures the consistency of state for all machines in thecluster",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740994,
                            "option_image_url": null
                        },
                        {
                            "id": 111341,
                            "question_id": 41333,
                            "option_text": "YARN, because it manages available resources of the cluster",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740995,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 41334,
                    "exam_id": 2,
                    "question_paper_id": 142,
                    "question_number": 264,
                    "question_text_1": null,
                    "question_image_1": "FAqkA7fqTFCsof8TQq7V9qsSABXQOb6dqWrT54rJmPb2Etf5EJ.png",
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-26T13:58:48.000000Z",
                    "updated_at": "2024-11-26T13:58:48.000000Z",
                    "question_num_long": 640653522410,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "8c63291586c8897cdddcbe285e68b6e8",
                    "course_id": 44,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "1833495a-525b-4304-8be6-0c8d75b128ce",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/FAqkA7fqTFCsof8TQq7V9qsSABXQOb6dqWrT54rJmPb2Etf5EJ.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 44,
                        "course_name": "Intro to BigData",
                        "course_code": "Intro to BigData",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "0a6ea890-ca63-49c6-a7b3-cc71e4a81ada"
                    },
                    "options": [
                        {
                            "id": 111342,
                            "question_id": 41334,
                            "option_text": "Set of lines one for each ID",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740996,
                            "option_image_url": null
                        },
                        {
                            "id": 111343,
                            "question_id": 41334,
                            "option_text": "Set of words one for each occurrence against each ID",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740997,
                            "option_image_url": null
                        },
                        {
                            "id": 111344,
                            "question_id": 41334,
                            "option_text": "Set of words one for each unique occurrence across IDs",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740998,
                            "option_image_url": null
                        },
                        {
                            "id": 111345,
                            "question_id": 41334,
                            "option_text": "Set of lists where each line becomes a list of words",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740999,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 41335,
                    "exam_id": 2,
                    "question_paper_id": 142,
                    "question_number": 265,
                    "question_text_1": null,
                    "question_image_1": "wwKXYB9XYGqkPzu1mWDElWmKkzobAaR3tEFOoMG1KRH4yJ5EGE.png",
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-26T13:58:48.000000Z",
                    "updated_at": "2024-11-26T13:58:48.000000Z",
                    "question_num_long": 640653522412,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "9c74022588fadcb1be5ab4761dffd833",
                    "course_id": 44,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "b0acee4b-bb49-4877-8b97-1ac000fb901b",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/wwKXYB9XYGqkPzu1mWDElWmKkzobAaR3tEFOoMG1KRH4yJ5EGE.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 44,
                        "course_name": "Intro to BigData",
                        "course_code": "Intro to BigData",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "0a6ea890-ca63-49c6-a7b3-cc71e4a81ada"
                    },
                    "options": [
                        {
                            "id": 111346,
                            "question_id": 41335,
                            "option_text": "Bucket name of the added file",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741004,
                            "option_image_url": null
                        },
                        {
                            "id": 111347,
                            "question_id": 41335,
                            "option_text": "Name of the added file",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741005,
                            "option_image_url": null
                        },
                        {
                            "id": 111348,
                            "question_id": 41335,
                            "option_text": "Time of creation of the file",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741006,
                            "option_image_url": null
                        },
                        {
                            "id": 111349,
                            "question_id": 41335,
                            "option_text": "Event type of the triggered event",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741007,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 41336,
                    "exam_id": 2,
                    "question_paper_id": 142,
                    "question_number": 266,
                    "question_text_1": null,
                    "question_image_1": "Kz9wCeRHv88coJbGe4M3sYcbWlqs8twjK6bMhHI81srwcKfaMI.png",
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-26T13:58:48.000000Z",
                    "updated_at": "2024-11-26T13:58:48.000000Z",
                    "question_num_long": 640653522413,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "6d90f8247926ae4d0321d0d76099e4eb",
                    "course_id": 44,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "b90797bb-67fd-4209-848f-8b40f57dd89b",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/Kz9wCeRHv88coJbGe4M3sYcbWlqs8twjK6bMhHI81srwcKfaMI.png"
                    ],
                    "question_texts": null,
                    "course": {
                        "id": 44,
                        "course_name": "Intro to BigData",
                        "course_code": "Intro to BigData",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "0a6ea890-ca63-49c6-a7b3-cc71e4a81ada"
                    },
                    "options": [
                        {
                            "id": 111350,
                            "question_id": 41336,
                            "option_text": "All odd numbers are computed",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741008,
                            "option_image_url": null
                        },
                        {
                            "id": 111351,
                            "question_id": 41336,
                            "option_text": "The program throws an error",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741009,
                            "option_image_url": null
                        },
                        {
                            "id": 111352,
                            "question_id": 41336,
                            "option_text": "Nothing is computed",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741010,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 41337,
                    "exam_id": 2,
                    "question_paper_id": 142,
                    "question_number": 267,
                    "question_text_1": "Consider a file \u201cdata.bin\u201d which is formatted as follows: every data record is in the form of pairs of values of the form \u201ccolumn name,column value\u201d, with each pair in its own line. You are asked to write a data processing script using Python that scales with big data. Which of the following represents your approach?",
                    "question_image_1": null,
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-26T13:58:48.000000Z",
                    "updated_at": "2024-11-26T13:58:48.000000Z",
                    "question_num_long": 640653522414,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "c371e01b4c2fcd59cc3c231fd3286e19",
                    "course_id": 44,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "9c023ca4-a418-4a7d-a1ad-b5a529e3dbb1",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Consider a file \u201cdata.bin\u201d which is formatted as follows: every data record is in the form of pairs of values of the form \u201ccolumn name,column value\u201d, with each pair in its own line. You are asked to write a data processing script using Python that scales with big data. Which of the following represents your approach?"
                    ],
                    "course": {
                        "id": 44,
                        "course_name": "Intro to BigData",
                        "course_code": "Intro to BigData",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "0a6ea890-ca63-49c6-a7b3-cc71e4a81ada"
                    },
                    "options": [
                        {
                            "id": 111353,
                            "question_id": 41337,
                            "option_text": "Since data.bin is compliant with the RFC 4180, use PySpark\u2019s read_csv() to readthe data as is.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741011,
                            "option_image_url": null
                        },
                        {
                            "id": 111354,
                            "question_id": 41337,
                            "option_text": "Rename the file data.bin to data.csv to make it compliant with RFC 4180 andthen use PySpark\u2019s read_csv() to read the data",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741012,
                            "option_image_url": null
                        },
                        {
                            "id": 111355,
                            "question_id": 41337,
                            "option_text": "The problem cannot be solved since the file cannot be converted to a validformat for reading consistently without additional information",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741013,
                            "option_image_url": null
                        },
                        {
                            "id": 111356,
                            "question_id": 41337,
                            "option_text": "Write PySpark code to read all lines in data.bin, use string split on \u201c,\u201d asdelimiter, and then collect all column names and corresponding values into a RDD for furtherprocessing",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741014,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 41338,
                    "exam_id": 2,
                    "question_paper_id": 142,
                    "question_number": 268,
                    "question_text_1": "  Consider the below mutually-exclusive characterisations about the program: i. Program will not run since RDD transformation operation map() runs on Executors that is referencing a variable train_master which is declared in the Spark driver ii. Program will run successfully and produce the count of bookings that match for trains present in the train_master  For either of the 2 characterizations, consider the following (one or more) actions you could carry out in order to improve on the characterizations: 1. Program will need to be changed to bring the train_master into the Closure for executors to pick it up 2. Program will perform more poorly as the number of executors per worker node increases. Broadcast of train_master will need to be used to make it perform better. 3. Program will perform more poorly as the number of worker nodes increases (keeping number of executors per worker node constant). Broadcast of train_master will need to be used to make it perform better.  Which of the following combinations of statements are correct?",
                    "question_image_1": "ByX8DggHQAVLwdE6mGs0vvvS6lEuc33LqwrU779kktD9wgHGZo.png",
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-26T13:58:48.000000Z",
                    "updated_at": "2024-11-26T13:58:48.000000Z",
                    "question_num_long": 640653522415,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "abe38f3c626dd922a40b227d535bf793",
                    "course_id": 44,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "62126091-e6bd-4ed1-867b-f4dd123e4df5",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/ByX8DggHQAVLwdE6mGs0vvvS6lEuc33LqwrU779kktD9wgHGZo.png"
                    ],
                    "question_texts": [
                        "  Consider the below mutually-exclusive characterisations about the program: i. Program will not run since RDD transformation operation map() runs on Executors that is referencing a variable train_master which is declared in the Spark driver ii. Program will run successfully and produce the count of bookings that match for trains present in the train_master  For either of the 2 characterizations, consider the following (one or more) actions you could carry out in order to improve on the characterizations: 1. Program will need to be changed to bring the train_master into the Closure for executors to pick it up 2. Program will perform more poorly as the number of executors per worker node increases. Broadcast of train_master will need to be used to make it perform better. 3. Program will perform more poorly as the number of worker nodes increases (keeping number of executors per worker node constant). Broadcast of train_master will need to be used to make it perform better.  Which of the following combinations of statements are correct?"
                    ],
                    "course": {
                        "id": 44,
                        "course_name": "Intro to BigData",
                        "course_code": "Intro to BigData",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "0a6ea890-ca63-49c6-a7b3-cc71e4a81ada"
                    },
                    "options": [
                        {
                            "id": 111357,
                            "question_id": 41338,
                            "option_text": "i & 1",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741015,
                            "option_image_url": null
                        },
                        {
                            "id": 111358,
                            "question_id": 41338,
                            "option_text": "i & 1 followed by 2",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741016,
                            "option_image_url": null
                        },
                        {
                            "id": 111359,
                            "question_id": 41338,
                            "option_text": "i & 1 followed by 2 & 3",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741017,
                            "option_image_url": null
                        },
                        {
                            "id": 111360,
                            "question_id": 41338,
                            "option_text": "ii & 2",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741018,
                            "option_image_url": null
                        },
                        {
                            "id": 111361,
                            "question_id": 41338,
                            "option_text": "ii & 2 & 3",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741019,
                            "option_image_url": null
                        },
                        {
                            "id": 111362,
                            "question_id": 41338,
                            "option_text": "ii & 3",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741020,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 41339,
                    "exam_id": 2,
                    "question_paper_id": 142,
                    "question_number": 269,
                    "question_text_1": "What is the output of the following code?  ",
                    "question_image_1": "cbk096jfNXv0jiumVAh3IfFUkPSUL4hNF2z753XxafLwPyuKCi.png",
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-26T13:58:48.000000Z",
                    "updated_at": "2024-11-26T13:58:48.000000Z",
                    "question_num_long": 640653522416,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "a5ca5d861ff6ca4954fed621bda4a003",
                    "course_id": 44,
                    "is_markdown": 0,
                    "question_text_2": "What is the output of the following code?  ",
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "2c89d15c-b50c-4af9-88d2-f733c220a5c7",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/cbk096jfNXv0jiumVAh3IfFUkPSUL4hNF2z753XxafLwPyuKCi.png"
                    ],
                    "question_texts": [
                        "What is the output of the following code?  ",
                        "What is the output of the following code?  "
                    ],
                    "course": {
                        "id": 44,
                        "course_name": "Intro to BigData",
                        "course_code": "Intro to BigData",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "0a6ea890-ca63-49c6-a7b3-cc71e4a81ada"
                    },
                    "options": [
                        {
                            "id": 111363,
                            "question_id": 41339,
                            "option_text": "1",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741021,
                            "option_image_url": null
                        },
                        {
                            "id": 111364,
                            "question_id": 41339,
                            "option_text": "5",
                            "option_image": "",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741022,
                            "option_image_url": null
                        },
                        {
                            "id": 111365,
                            "question_id": 41339,
                            "option_text": "3",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741023,
                            "option_image_url": null
                        },
                        {
                            "id": 111366,
                            "question_id": 41339,
                            "option_text": "4",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741024,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 41340,
                    "exam_id": 2,
                    "question_paper_id": 142,
                    "question_number": 270,
                    "question_text_1": "What is the output of the following code when deployed on a spark cluster?  ",
                    "question_image_1": "iNQ8zYo1TSvwZXULg8uzrl7sAFmOP5YyKuw8mLHWYz7dXACtOD.png",
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-26T13:58:48.000000Z",
                    "updated_at": "2024-11-26T13:58:48.000000Z",
                    "question_num_long": 640653522417,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "6d5566e02323b16100640758a0400ffd",
                    "course_id": 44,
                    "is_markdown": 0,
                    "question_text_2": "What is the output of the following code when deployed on a spark cluster?  ",
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "de822653-2223-498c-97b0-fedfe1a02e4c",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/iNQ8zYo1TSvwZXULg8uzrl7sAFmOP5YyKuw8mLHWYz7dXACtOD.png"
                    ],
                    "question_texts": [
                        "What is the output of the following code when deployed on a spark cluster?  ",
                        "What is the output of the following code when deployed on a spark cluster?  "
                    ],
                    "course": {
                        "id": 44,
                        "course_name": "Intro to BigData",
                        "course_code": "Intro to BigData",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "0a6ea890-ca63-49c6-a7b3-cc71e4a81ada"
                    },
                    "options": [
                        {
                            "id": 111367,
                            "question_id": 41340,
                            "option_text": "",
                            "option_image": "3nlwlLKpxIMY9NYyFvhPwsG4ytl3NFYVW22gTTRNk4I5zNaVuD.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741025,
                            "option_image_url": "app/option_images/3nlwlLKpxIMY9NYyFvhPwsG4ytl3NFYVW22gTTRNk4I5zNaVuD.png"
                        },
                        {
                            "id": 111368,
                            "question_id": 41340,
                            "option_text": "",
                            "option_image": "yzYPxyqpGehkAmBlYPMmiuB9TniAlA5HrXcto802Y4bTCB253j.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741026,
                            "option_image_url": "app/option_images/yzYPxyqpGehkAmBlYPMmiuB9TniAlA5HrXcto802Y4bTCB253j.png"
                        },
                        {
                            "id": 111369,
                            "question_id": 41340,
                            "option_text": "",
                            "option_image": "V4W1Y8eCoG9rkLshnp6l3cdfynHxRioA5CBMExN0AbQPGcP3dQ.png",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741027,
                            "option_image_url": "app/option_images/V4W1Y8eCoG9rkLshnp6l3cdfynHxRioA5CBMExN0AbQPGcP3dQ.png"
                        },
                        {
                            "id": 111370,
                            "question_id": 41340,
                            "option_text": "",
                            "option_image": "bbYRGc6oXdqGBi00Ad6BU95kJp57KRDPRDhqtAyL6WBBl1Fq1m.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741028,
                            "option_image_url": "app/option_images/bbYRGc6oXdqGBi00Ad6BU95kJp57KRDPRDhqtAyL6WBBl1Fq1m.png"
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 41341,
                    "exam_id": 2,
                    "question_paper_id": 142,
                    "question_number": 271,
                    "question_text_1": "What is the output of the following code?  ",
                    "question_image_1": "4JkT6J1ivJl03CudU3q1i3PW0PnR3yHlvCOAWRXp8OqdMGlYSY.png",
                    "question_type": "MCQ",
                    "total_mark": "2.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-26T13:58:48.000000Z",
                    "updated_at": "2024-11-26T13:58:48.000000Z",
                    "question_num_long": 640653522418,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "0a6663c15465ef3a4afb0dfc8f69d5eb",
                    "course_id": 44,
                    "is_markdown": 0,
                    "question_text_2": "What is the output of the following code?  ",
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "be73d9d9-f74c-4099-a47c-4509246f8b71",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": [
                        "/question_images/4JkT6J1ivJl03CudU3q1i3PW0PnR3yHlvCOAWRXp8OqdMGlYSY.png"
                    ],
                    "question_texts": [
                        "What is the output of the following code?  ",
                        "What is the output of the following code?  "
                    ],
                    "course": {
                        "id": 44,
                        "course_name": "Intro to BigData",
                        "course_code": "Intro to BigData",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "0a6ea890-ca63-49c6-a7b3-cc71e4a81ada"
                    },
                    "options": [
                        {
                            "id": 111371,
                            "question_id": 41341,
                            "option_text": "",
                            "option_image": "SeZ9cbbV5xHX0oyDMgLBKuEzeaptX25UfIXooSPOUPlWBLArug.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741029,
                            "option_image_url": "app/option_images/SeZ9cbbV5xHX0oyDMgLBKuEzeaptX25UfIXooSPOUPlWBLArug.png"
                        },
                        {
                            "id": 111372,
                            "question_id": 41341,
                            "option_text": "",
                            "option_image": "MJhEnRau37XAlKodTOIwRtpxHUABdMZzWPQCG9fo1jzzab76bi.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741030,
                            "option_image_url": "app/option_images/MJhEnRau37XAlKodTOIwRtpxHUABdMZzWPQCG9fo1jzzab76bi.png"
                        },
                        {
                            "id": 111373,
                            "question_id": 41341,
                            "option_text": "",
                            "option_image": "ElM4gHQIrrxe3wvfplXYxew5nP4NFJWfXtYAIcJLx5NwF7wQXk.png",
                            "score": "2.000",
                            "is_correct": 1,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741031,
                            "option_image_url": "app/option_images/ElM4gHQIrrxe3wvfplXYxew5nP4NFJWfXtYAIcJLx5NwF7wQXk.png"
                        },
                        {
                            "id": 111374,
                            "question_id": 41341,
                            "option_text": "",
                            "option_image": "nM4483T8VYnzzZSpQrIompJ0kvyb1kCA61Nc7yMrHVcZKhjVdC.png",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741032,
                            "option_image_url": "app/option_images/nM4483T8VYnzzZSpQrIompJ0kvyb1kCA61Nc7yMrHVcZKhjVdC.png"
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 41342,
                    "exam_id": 2,
                    "question_paper_id": 142,
                    "question_number": 272,
                    "question_text_1": "What option(s) best describe the differences between MapReduce and Spark?",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-26T13:58:48.000000Z",
                    "updated_at": "2024-11-26T13:58:48.000000Z",
                    "question_num_long": 640653522402,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "40ad28bf3c2b928fa2341f483cca6097",
                    "course_id": 44,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "2f17e4a1-55f2-4c56-9558-9907f636f7d7",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "What option(s) best describe the differences between MapReduce and Spark?"
                    ],
                    "course": {
                        "id": 44,
                        "course_name": "Intro to BigData",
                        "course_code": "Intro to BigData",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "0a6ea890-ca63-49c6-a7b3-cc71e4a81ada"
                    },
                    "options": [
                        {
                            "id": 111375,
                            "question_id": 41342,
                            "option_text": "MapReduce forces barrier synchronization after every step, while Spark'sexecution is gated on Actions",
                            "option_image": "",
                            "score": "1.500",
                            "is_correct": 1,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740961,
                            "option_image_url": null
                        },
                        {
                            "id": 111376,
                            "question_id": 41342,
                            "option_text": "MapReduce leverages memory heavily, while Spark optimizes for disk-basedcomputations",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740962,
                            "option_image_url": null
                        },
                        {
                            "id": 111377,
                            "question_id": 41342,
                            "option_text": "MapReduce leverages disk heavily, while Spark optimizes for memory-basedcomputations",
                            "option_image": "",
                            "score": "1.500",
                            "is_correct": 1,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740963,
                            "option_image_url": null
                        },
                        {
                            "id": 111378,
                            "question_id": 41342,
                            "option_text": "MapReduce executes linearly without parallelization, while Spark executes inparallel using Directed Acyclic Graphs",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740964,
                            "option_image_url": null
                        },
                        {
                            "id": 111379,
                            "question_id": 41342,
                            "option_text": "MapReduce enables massively parallel computation, while Spark's driverprogram sequentially executes each worker",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740965,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 41343,
                    "exam_id": 2,
                    "question_paper_id": 142,
                    "question_number": 273,
                    "question_text_1": "Would IRCTC's railway ticket booking application be suitable for a serverless implementation?",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-26T13:58:48.000000Z",
                    "updated_at": "2024-11-26T13:58:48.000000Z",
                    "question_num_long": 640653522408,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "c4dd1e99cba6f67147f0539474c665f6",
                    "course_id": 44,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "077eb81c-683c-4402-8e70-6333333e176c",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Would IRCTC's railway ticket booking application be suitable for a serverless implementation?"
                    ],
                    "course": {
                        "id": 44,
                        "course_name": "Intro to BigData",
                        "course_code": "Intro to BigData",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "0a6ea890-ca63-49c6-a7b3-cc71e4a81ada"
                    },
                    "options": [
                        {
                            "id": 111380,
                            "question_id": 41343,
                            "option_text": "No, because each use of the application by a prospective passenger for ticketsearch, date choosing, ticket seat blocking and ticket purchase is together a high complexityoperation",
                            "option_image": "",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740987,
                            "option_image_url": null
                        },
                        {
                            "id": 111381,
                            "question_id": 41343,
                            "option_text": "No, because each use of the application by a prospective passenger for ticketsearch, date choosing, ticket seat blocking and ticket purchase will take a long time",
                            "option_image": "",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740988,
                            "option_image_url": null
                        },
                        {
                            "id": 111382,
                            "question_id": 41343,
                            "option_text": "No, because a failed step in the use of the application can result in duplicatepayments",
                            "option_image": "",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740989,
                            "option_image_url": null
                        },
                        {
                            "id": 111383,
                            "question_id": 41343,
                            "option_text": "No, because the number of ticket searches cannot be scaled by simply runningthe application in multiple machines",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740990,
                            "option_image_url": null
                        },
                        {
                            "id": 111384,
                            "question_id": 41343,
                            "option_text": "No, because multiple prospective passengers have to use the application onthe single machine (i.e. no embarrassingly parallel computation)",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531740991,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 41344,
                    "exam_id": 2,
                    "question_paper_id": 142,
                    "question_number": 274,
                    "question_text_1": "You are provided with a Spark program that picks out a list of suspicious transactions based on the amount of the transaction being higher than a threshold and the geographic location of the transaction matching a known set of suspected locations provided in a small file. The Spark program is written to pull all the transactions from the Workers to the Driver and then apply the logic of threshold filtering and geographic location matching. Which of the following changes will you make to the program to improve performance? (Choose any two)",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-26T13:58:48.000000Z",
                    "updated_at": "2024-11-26T13:58:48.000000Z",
                    "question_num_long": 640653522411,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "49d8e2531f6ab69e26db729daa78067f",
                    "course_id": 44,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "a4be3b2a-b452-49c1-8f2a-8fa6a6181fb3",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "You are provided with a Spark program that picks out a list of suspicious transactions based on the amount of the transaction being higher than a threshold and the geographic location of the transaction matching a known set of suspected locations provided in a small file. The Spark program is written to pull all the transactions from the Workers to the Driver and then apply the logic of threshold filtering and geographic location matching. Which of the following changes will you make to the program to improve performance? (Choose any two)"
                    ],
                    "course": {
                        "id": 44,
                        "course_name": "Intro to BigData",
                        "course_code": "Intro to BigData",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "0a6ea890-ca63-49c6-a7b3-cc71e4a81ada"
                    },
                    "options": [
                        {
                            "id": 111385,
                            "question_id": 41344,
                            "option_text": "Use broadcast variables",
                            "option_image": "",
                            "score": "1.500",
                            "is_correct": 1,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741000,
                            "option_image_url": null
                        },
                        {
                            "id": 111386,
                            "question_id": 41344,
                            "option_text": "Hardcode threshold value as a filter condition in the Driver program",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741001,
                            "option_image_url": null
                        },
                        {
                            "id": 111387,
                            "question_id": 41344,
                            "option_text": "Filter for transactions in the Workers before bringing to the Driver",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741002,
                            "option_image_url": null
                        },
                        {
                            "id": 111388,
                            "question_id": 41344,
                            "option_text": "Hardcode threshold value as a filter condition in the Workers itself",
                            "option_image": "",
                            "score": "1.500",
                            "is_correct": 1,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741003,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 41345,
                    "exam_id": 2,
                    "question_paper_id": 142,
                    "question_number": 275,
                    "question_text_1": "Which of the following types of data sources can you read successfully without missing data using a program that extracts once every day? If no data is missed, then all data in source will match data extracted successfully.",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-26T13:58:48.000000Z",
                    "updated_at": "2024-11-26T13:58:48.000000Z",
                    "question_num_long": 640653522419,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "d2a5b33ccfcbdaf988b27dbe4569245a",
                    "course_id": 44,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "07203356-f5d3-475c-a253-c0a18f2f3c6c",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following types of data sources can you read successfully without missing data using a program that extracts once every day? If no data is missed, then all data in source will match data extracted successfully."
                    ],
                    "course": {
                        "id": 44,
                        "course_name": "Intro to BigData",
                        "course_code": "Intro to BigData",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "0a6ea890-ca63-49c6-a7b3-cc71e4a81ada"
                    },
                    "options": [
                        {
                            "id": 111389,
                            "question_id": 41345,
                            "option_text": "A MySQL table where all Creates are new rows and all Updates are in-place",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741033,
                            "option_image_url": null
                        },
                        {
                            "id": 111390,
                            "question_id": 41345,
                            "option_text": "A Linux machine\u2019s system.log file into which all processes append their events",
                            "option_image": "",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741034,
                            "option_image_url": null
                        },
                        {
                            "id": 111391,
                            "question_id": 41345,
                            "option_text": "Share transactions stored as facts & share prices stored as SCD Type IIdimension tables in a PostgreSQL database",
                            "option_image": "",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741035,
                            "option_image_url": null
                        },
                        {
                            "id": 111392,
                            "question_id": 41345,
                            "option_text": "A weather API that provides the temperature & rainfall readings for all itsweather stations in India at the point of querying",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741036,
                            "option_image_url": null
                        },
                        {
                            "id": 111393,
                            "question_id": 41345,
                            "option_text": "Google drive account that stores all historical census data for India",
                            "option_image": "",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741037,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 41346,
                    "exam_id": 2,
                    "question_paper_id": 142,
                    "question_number": 276,
                    "question_text_1": "Which of the following is true?",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-26T13:58:48.000000Z",
                    "updated_at": "2024-11-26T13:58:48.000000Z",
                    "question_num_long": 640653522420,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "57b100e4f1320db7d072ef67effee7f4",
                    "course_id": 44,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "ba13e4da-15c6-4a41-8d6a-2cf403f236b1",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following is true?"
                    ],
                    "course": {
                        "id": 44,
                        "course_name": "Intro to BigData",
                        "course_code": "Intro to BigData",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "0a6ea890-ca63-49c6-a7b3-cc71e4a81ada"
                    },
                    "options": [
                        {
                            "id": 111394,
                            "question_id": 41346,
                            "option_text": "Snapshots of source systems can be created using an event capture tool likeCDC and then replaying the events in sequence for that time period.",
                            "option_image": "",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741038,
                            "option_image_url": null
                        },
                        {
                            "id": 111395,
                            "question_id": 41346,
                            "option_text": "A data lake is a collection of data to be provided as input for data sciencealgorithms.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741039,
                            "option_image_url": null
                        },
                        {
                            "id": 111396,
                            "question_id": 41346,
                            "option_text": "Zookeeper is a library for ensuring all services used in big data are monitored,administered and cleaned at appropriate intervals.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741040,
                            "option_image_url": null
                        },
                        {
                            "id": 111397,
                            "question_id": 41346,
                            "option_text": "A single Spark cluster can have multiple \u201cleader\u201d master nodes.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741041,
                            "option_image_url": null
                        },
                        {
                            "id": 111398,
                            "question_id": 41346,
                            "option_text": "Spark is optimized for in-memory computation.",
                            "option_image": "",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741042,
                            "option_image_url": null
                        },
                        {
                            "id": 111399,
                            "question_id": 41346,
                            "option_text": "Given the RDD underlying a Dataframe, you can recreate the same Dataframeprovided you know the schema",
                            "option_image": "",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741043,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                },
                {
                    "id": 41347,
                    "exam_id": 2,
                    "question_paper_id": 142,
                    "question_number": 277,
                    "question_text_1": "Which of the following statements is/ are true for Google Cloud Functions?",
                    "question_image_1": null,
                    "question_type": "MSQ",
                    "total_mark": "3.00",
                    "value_start": null,
                    "value_end": null,
                    "created_at": "2024-11-26T13:58:48.000000Z",
                    "updated_at": "2024-11-26T13:58:48.000000Z",
                    "question_num_long": 640653522421,
                    "answer_type": null,
                    "response_type": null,
                    "have_answers": 1,
                    "hash": "21eb7ccd2b66fe118b500760f6044492",
                    "course_id": 44,
                    "is_markdown": 0,
                    "question_text_2": null,
                    "question_image_2": null,
                    "question_image_3": null,
                    "question_image_4": null,
                    "question_image_5": null,
                    "question_image_7": null,
                    "question_image_8": null,
                    "question_image_9": null,
                    "question_image_10": null,
                    "parent_question_id": null,
                    "question_text_3": null,
                    "question_text_4": null,
                    "question_text_5": null,
                    "uuid": "cb758bab-a8d6-4e2c-b1fe-f346253d56d3",
                    "solutions_count": 0,
                    "comments_count": 0,
                    "question_image_url": null,
                    "question_texts": [
                        "Which of the following statements is/ are true for Google Cloud Functions?"
                    ],
                    "course": {
                        "id": 44,
                        "course_name": "Intro to BigData",
                        "course_code": "Intro to BigData",
                        "created_at": "2024-10-16T08:15:00.000000Z",
                        "updated_at": "2024-10-16T08:15:00.000000Z",
                        "program_id": 1,
                        "uuid": "0a6ea890-ca63-49c6-a7b3-cc71e4a81ada"
                    },
                    "options": [
                        {
                            "id": 111400,
                            "question_id": 41347,
                            "option_text": "Google Cloud functions work on stateless paradigm - one function invocationdoesn\u2019t depend on the previous function invocations..",
                            "option_image": "",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741044,
                            "option_image_url": null
                        },
                        {
                            "id": 111401,
                            "question_id": 41347,
                            "option_text": "Google cloud functions can be triggered by deletion of an object in GCS.",
                            "option_image": "",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741045,
                            "option_image_url": null
                        },
                        {
                            "id": 111402,
                            "question_id": 41347,
                            "option_text": "Google Cloud Functions can automatically scale-up compute in case of highload.",
                            "option_image": "",
                            "score": "1.000",
                            "is_correct": 1,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741046,
                            "option_image_url": null
                        },
                        {
                            "id": 111403,
                            "question_id": 41347,
                            "option_text": "A single execution of a google cloud function is timed indefinitely till theoperation finishes.",
                            "option_image": "",
                            "score": "0.000",
                            "is_correct": 0,
                            "created_at": "2024-11-26T13:58:48.000000Z",
                            "updated_at": "2024-11-26T13:58:48.000000Z",
                            "option_number": 6406531741047,
                            "option_image_url": null
                        }
                    ],
                    "parent_question": null
                }
            ]
        },
        "summary": "### Summary of Core Topics, Concepts, Principles, and Equations\n\n#### Core Topics and Concepts\n\n1. **Big Data Fundamentals**\n   - Definition and Characteristics: Volume, Velocity, Variety\n   - Technologies: Hadoop, Spark, MapReduce\n\n2. **Hadoop Ecosystem**\n   - HDFS (Hadoop Distributed File System)\n   - YARN (Yet Another Resource Negotiator)\n   - MapReduce Programming Model\n\n3. **Apache Spark**\n   - Architecture: Driver, Executors, Tasks, Stages, Jobs\n   - RDDs (Resilient Distributed Datasets)\n   - Transformations and Actions: `map`, `filter`, `reduce`, `collect`, `count`\n   - DataFrames and Spark SQL\n   - Broadcast Variables and Accumulators\n\n4. **Cloud Computing and Serverless**\n   - Cloud-Native Design Principles\n   - Serverless Computing: Google Cloud Functions, AWS Lambda\n   - Scalability and Fault Tolerance\n\n5. **Data Processing and Storage**\n   - Data Lakes and Data Warehouses\n   - Data Formats: CSV, JSON, Parquet\n   - Data Partitioning and Shuffling\n\n6. **Distributed Computing Concepts**\n   - Parallel Processing and Partitioning\n   - Lazy Evaluation\n   - Fault Tolerance and Data Recovery\n\n7. **Performance Optimization**\n   - Broadcast Variables\n   - Data Locality\n   - Resource Management\n\n#### Important Principles\n\n1. **Divide-and-Conquer**\n   - Examples: Spark and MapReduce\n\n2. **Cloud-Native Design**\n   - Scalability, Resilience, Observability, Manageability\n\n3. **Data Locality**\n   - Minimizing Data Movement in Distributed Systems\n\n4. **Lazy Evaluation**\n   - Spark's Approach to Optimizing Data Processing\n\n5. **Fault Tolerance**\n   - Handling Node Failures in Distributed Systems\n\n#### Key Equations and Code Snippets\n\n1. **Spark Transformations and Actions**\n   ```python\n   rdd = sc.parallelize(data)\n   filtered_rdd = rdd.filter(lambda x: x % 2 != 0)\n   count = filtered_rdd.count()\n   ```\n\n2. **Broadcast Variables**\n   ```python\n   broadcast_var = sc.broadcast(value)\n   ```\n\n3. **DataFrame Operations**\n   ```python\n   df = spark.read.csv(\"data.csv\")\n   grouped_df = df.groupBy(\"column_name\").count()\n   ```\n\n4. **MapReduce Example**\n   ```python\n   # Mapper\n   def mapper(key, value):\n       for word in value.split():\n           emit_intermediate(word, 1)\n\n   # Reducer\n   def reducer(key, values):\n       emit((key, sum(values)))\n   ```\n\n### Mermaid Knowledge Graph\n\n```mermaid\ngraph TD;\n    A[Big Data] --> B[Hadoop]\n    A --> C[Spark]\n    A --> D[MapReduce]\n    B --> E[HDFS]\n    B --> F[YARN]\n    C --> G[RDDs]\n    C --> H[DataFrames]\n    C --> I[Transformations and Actions]\n    D --> J[Mapper]\n    D --> K[Reducer]\n    A --> L[Cloud Computing]\n    L --> M[Serverless]\n    L --> N[Cloud-Native Design]\n    A --> O[Data Processing]\n    O --> P[Data Lakes]\n    O --> Q[Data Warehouses]\n    A --> R[Distributed Computing]\n    R --> S[Parallel Processing]\n    R --> T[Fault Tolerance]\n```\n\n```mermaid\ngraph TD;\n    C[Spark] --> U[Broadcast Variables]\n    C --> V[Data Locality]\n    C --> W[Lazy Evaluation]\n    I --> X[map]\n    I --> Y[filter]\n    I --> Z[reduce]\n    I --> AA[collect]\n    I --> AB[count]\n```\n\n```mermaid\ngraph TD;\n    L[Cloud Computing] --> AC[Google Cloud Functions]\n    L --> AD[AWS Lambda]\n    N --> AE[Scalability]\n    N --> AF[Resilience]\n    N --> AG[Observability]\n    N --> AH[Manageability]\n```\n\nThese graphs and summaries should help you understand the core topics, concepts, principles, and key equations necessary for the exam.",
        "total_score": "50.00"
    },
    "url": "/question-paper/practise/44/b55a6202-f31",
    "version": "ee3d5d44299e610bd137ea6200db5ac2"
}